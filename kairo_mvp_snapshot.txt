# Kairo Project Code Dump (v1.0 MVP)# Generated: 2025-08-06 11:11:35

================================================================================ðŸ“„ .gitignore================================================================================
# --- START OF FILE .gitignore ---
# --- Python ---
# Virtual environments
venv/
.venv/
env/
ENV/

# Compiled files
__pycache__/
*.pyc

# Packaging
*.egg-info/
*.egg
build/
dist/
*.manifest
*.spec
MANIFEST

# PyInstaller logs
pip-log.txt
pip-delete-this-directory.txt

# Testing and coverage
.tox/
.nox/
.pytest_cache/
.hypothesis/
.coverage*
.cache
nosetests.xml
coverage.xml
htmlcov/
*.cover
*.py,cover
cover/

# Jupyter
.ipynb_checkpoints

# --- Node.js ---
node_modules/
jspm_packages/
web_modules/

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

# Diagnostic reports
report.*.json

# Build outputs
build/
dist/
*.tgz

# TypeScript / Lint
*.tsbuildinfo
.eslintcache
.stylelintcache

# --- WhatsApp Web JS ---
.wwebjs_auth/
.wwebjs_cache/

# --- Project-Specific ---
.env
data/
logs/
startup_error.log
mock_output.txt
*.dump*.txt
viewer_messages.db
*.tmp
project_v0.8_dump.txt

# --- Editors/IDE ---
# VS Code
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json

# JetBrains / PyCharm
.idea/
*.iml
.history/

# --- OS ---
.DS_Store
Thumbs.db
ehthumbs.db
Desktop.ini
last_*.txt
project_v0.8_dump.txt
project_v0.8_dump.txt
env.example
*.csv
*.txt
*.jsonl
old/
# --- END OF FILE .gitignore ---


================================================================================ðŸ“„ .sql================================================================================
# --- START OF FILE .sql ---
SELECT * FROM system_logs ORDER BY timestamp DESC LIMIT 100;
SELECT * FROM messages ORDER BY timestamp DESC LIMIT 100;
SELECT * FROM users_tasks ORDER BY timestamp DESC LIMIT 100;
SELECT * FROM llm_activity ORDER BY timestamp DESC LIMIT 100;

# --- END OF FILE .sql ---


================================================================================ðŸ“„ README.md================================================================================
# --- START OF FILE README.md ---

# Kairo - Internal Project Handbook

This document contains all the essential information for setting up, running, and managing the Kairo application. It is designed to be a quick reference to get you up to speed.

---

## ðŸš€ Quick Reference

| Item                  | Value                                         |
| --------------------- | --------------------------------------------- |
| **Project Path on VPS** | `/home/whatstasker/kairo/`                    |
| **Primary User**        | `whatstasker`                                 |
| **Python Backend Port** | `8001`                                        |
| **WhatsApp Number**     | `[Your Linked WhatsApp Number]`               |
| **Process Manager**     | **PM2** (Process Manager 2 for Node.js)       |

---

## 1. Project Overview

Kairo is an AI productivity coach that communicates with users via WhatsApp. The system is composed of two main services that must run simultaneously:

1.  **Python Backend (`main.py`):** A FastAPI application that contains all the business logic, agent intelligence (LLM calls), and data management (SQLite database).
2.  **Node.js WA Bridge (`WA/wa_bridge.js`):** A Node.js script that uses the `whatsapp-web.js` library to connect to a WhatsApp account and act as a bridge, relaying messages to and from the Python backend.

---

## 2. Project Structure

The project is organized into logical directories:

-   `agents/`: Contains the AI agent logic and tool definitions.
-   `bridge/`: Contains the FastAPI interface code for different communication channels (CLI, WhatsApp, Twilio).
-   `config/`: All prompts and user-facing messages are stored in `.yaml` files here.
-   `data/`: Stores the SQLite database (`kairo_activity_*.db`) and user preference JSON files.
-   `logs/`: PM2 and the Node.js script will write log files here.
-   `services/`: Core application services like the scheduler and task manager.
-   `tools/`: Utilities like the database connector (`activity_db.py`) and logger.
-   `users/`: Manages user preferences.
-   `WA/`: Contains the isolated Node.js WhatsApp bridge script and its dependencies.

---

## 3. Setup and Installation

This guide assumes a fresh clone of the repository.

### a. Python Backend

1.  **Navigate to the project root:**
    ```bash
    cd ~/kairo
    ```

2.  **Set up and activate the virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

### b. Node.js WhatsApp Bridge

1.  **Navigate to the bridge directory:**
    ```bash
    cd ~/kairo/WA
    ```

2.  **Install Node.js dependencies:**
    ```bash
    npm install
    ```

### c. Environment Variables

1.  From the project root (`~/kairo`), copy the example environment file:
    ```bash
    cp .env.example .env
    ```

2.  **Edit the `.env` file** and fill in your `OPENAI_API_KEY`. The most important variable for testing is `BRIDGE_TYPE`.
    -   `BRIDGE_TYPE=whatsapp`: For connecting to the live WhatsApp bridge.
    -   `BRIDGE_TYPE=cli`: For testing with the command-line mock chat client.

---

## 4. Running the Application with PM2 (Production)

We use **PM2** to run both services in the background, ensuring they are stable and restart automatically on crashes or server reboots.

### a. One-Time Setup

1.  **Install PM2 globally:**
    ```bash
    sudo npm install pm2 -g
    ```

2.  **Start both services with PM2:** (Run from the project root `~/kairo`)
    ```bash
    # Start the Python backend
    pm2 start "python main.py" --name kairo-backend

    # Start the Node.js WhatsApp bridge
    pm2 start WA/wa_bridge.js --name kairo-wa-bridge
    ```

3.  **Scan the QR Code:** View the bridge logs to get the QR code for the initial link.
    ```bash
    pm2 logs kairo-wa-bridge
    ```
    Scan the code with your phone. You only need to do this once.

4.  **Save the process list and enable startup on boot:**
    ```bash
    # Save the current list of apps
    pm2 save

    # Create a startup script for your system
    pm2 startup
    # (This will give you a command to copy and paste, run it)
    ```

### b. Daily Management with PM2

-   **List all running processes:**
    ```bash
    pm2 list
    ```
-   **View live logs for a specific service:**
    ```bash
    pm2 logs kairo-backend
    pm2 logs kairo-wa-bridge
    ```
-   **Restart a service (e.g., after a code change):**
    ```bash
    pm2 restart kairo-backend
    ```
-   **Stop a service:**
    ```bash
    pm2 stop all
    ```

---

## 5. Manual Testing & Debugging

For development, it's often easier to run the services manually in separate terminals.

**Terminal 1: Start the Python Backend**
```bash
cd ~/kairo
source venv/bin/activate
python main.py
```

**Terminal 2: Start the WhatsApp Bridge**
```bash
cd ~/kairo/WA
node wa_bridge.js
```

### Viewing a User's Session

To debug a specific user's interaction, use the `session_viewer.py` script. It reads the database and prints a clean, chronological log of messages and tool calls.

```bash
cd ~/kairo
source venv/bin/activate

# For WhatsApp users:
python session_viewer.py [USER_PHONE_NUMBER] --mode prod

# For CLI testing users:
python session_viewer.py [USER_ID] --mode cli
```

---

## 6. Git and Version Control

The `.gitignore` file is configured to keep the repository clean by ignoring:
-   Python virtual environments (`venv/`)
-   Node.js dependencies (`WA/node_modules/`)
-   WhatsApp session data (`WA/.wwebjs_auth/`)
-   Log files (`logs/`)
-   Database files (`data/*.db`)
-   Environment files (`.env`)

Always commit changes from the project root (`~/kairo`).

```
# --- END OF FILE README.md ---


================================================================================ðŸ“„ WA/package-lock.json================================================================================
# --- START OF FILE WA/package-lock.json ---
{
  "name": "WA",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "dependencies": {
        "axios": "^1.8.4",
        "qrcode-terminal": "^0.12.0",
        "whatsapp-web.js": "^1.27.0",
        "winston": "^3.13.0"
      }
    },
    "node_modules/@colors/colors": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/@colors/colors/-/colors-1.6.0.tgz",
      "integrity": "sha512-Ir+AOibqzrIsL6ajt3Rz3LskB7OiMVHqltZmspbW/TJuTVuyOMirVqAkjfY6JISiLHgyNqicAC8AyHHGzNd/dA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.1.90"
      }
    },
    "node_modules/@dabh/diagnostics": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@dabh/diagnostics/-/diagnostics-2.0.3.tgz",
      "integrity": "sha512-hrlQOIi7hAfzsMqlGSFyVucrx38O+j6wiGOf//H2ecvIEqYN4ADBSS2iLMh5UFyDunCNniUIPk/q3riFv45xRA==",
      "license": "MIT",
      "dependencies": {
        "colorspace": "1.1.x",
        "enabled": "2.0.x",
        "kuler": "^2.0.0"
      }
    },
    "node_modules/@pedroslopez/moduleraid": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/@pedroslopez/moduleraid/-/moduleraid-5.0.2.tgz",
      "integrity": "sha512-wtnBAETBVYZ9GvcbgdswRVSLkFkYAGv1KzwBBTeRXvGT9sb9cPllOgFFWXCn9PyARQ0H+Ijz6mmoRrGateUDxQ==",
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "24.0.12",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-24.0.12.tgz",
      "integrity": "sha512-LtOrbvDf5ndC9Xi+4QZjVL0woFymF/xSTKZKPgrrl7H7XoeDvnD+E2IclKVDyaK9UM756W/3BXqSU+JEHopA9g==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "undici-types": "~7.8.0"
      }
    },
    "node_modules/@types/triple-beam": {
      "version": "1.3.5",
      "resolved": "https://registry.npmjs.org/@types/triple-beam/-/triple-beam-1.3.5.tgz",
      "integrity": "sha512-6WaYesThRMCl19iryMYP7/x2OVgCtbIVflDGFpWnb9irXI3UjYE4AzmYuiUKY1AJstGijoY+MgUszMgRxIYTYw==",
      "license": "MIT"
    },
    "node_modules/@types/yauzl": {
      "version": "2.10.3",
      "resolved": "https://registry.npmjs.org/@types/yauzl/-/yauzl-2.10.3.tgz",
      "integrity": "sha512-oJoftv0LSuaDZE3Le4DbKX+KS9G36NzOeSap90UIK0yMA/NhKJhqlSGtNDORNRaIbQfzjXDrQa0ytJ6mNRGz/Q==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "@types/node": "*"
      }
    },
    "node_modules/agent-base": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz",
      "integrity": "sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==",
      "license": "MIT",
      "dependencies": {
        "debug": "4"
      },
      "engines": {
        "node": ">= 6.0.0"
      }
    },
    "node_modules/archiver": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/archiver/-/archiver-5.3.2.tgz",
      "integrity": "sha512-+25nxyyznAXF7Nef3y0EbBeqmGZgeN/BxHX29Rs39djAfaFalmQ89SE6CWyDCHzGL0yt/ycBtNOmGTW0FyGWNw==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "archiver-utils": "^2.1.0",
        "async": "^3.2.4",
        "buffer-crc32": "^0.2.1",
        "readable-stream": "^3.6.0",
        "readdir-glob": "^1.1.2",
        "tar-stream": "^2.2.0",
        "zip-stream": "^4.1.0"
      },
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/archiver-utils": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/archiver-utils/-/archiver-utils-2.1.0.tgz",
      "integrity": "sha512-bEL/yUb/fNNiNTuUz979Z0Yg5L+LzLxGJz8x79lYmR54fmTIb6ob/hNQgkQnIUDWIFjZVQwl9Xs356I6BAMHfw==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "glob": "^7.1.4",
        "graceful-fs": "^4.2.0",
        "lazystream": "^1.0.0",
        "lodash.defaults": "^4.2.0",
        "lodash.difference": "^4.5.0",
        "lodash.flatten": "^4.4.0",
        "lodash.isplainobject": "^4.0.6",
        "lodash.union": "^4.6.0",
        "normalize-path": "^3.0.0",
        "readable-stream": "^2.0.0"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/archiver-utils/node_modules/readable-stream": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.8.tgz",
      "integrity": "sha512-8p0AUk4XODgIewSi0l8Epjs+EVnWiK7NoDIEGU0HhE7+ZyY8D1IMY7odu5lRrFXGg71L15KG8QrPmum45RTtdA==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "node_modules/archiver-utils/node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/archiver-utils/node_modules/string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "safe-buffer": "~5.1.0"
      }
    },
    "node_modules/async": {
      "version": "3.2.6",
      "resolved": "https://registry.npmjs.org/async/-/async-3.2.6.tgz",
      "integrity": "sha512-htCUDlxyyCLMgaM3xXg0C0LW2xqfuQ6p05pCEIsXuyQ+a1koYKTuBMzRNwmybfLgvJDMd0r1LTn4+E0Ti6C2AA==",
      "license": "MIT"
    },
    "node_modules/asynckit": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
      "integrity": "sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==",
      "license": "MIT"
    },
    "node_modules/axios": {
      "version": "1.10.0",
      "resolved": "https://registry.npmjs.org/axios/-/axios-1.10.0.tgz",
      "integrity": "sha512-/1xYAC4MP/HEG+3duIhFr4ZQXR4sQXOIe+o6sdqzeykGLx6Upp/1p8MHqhINOvGeP7xyNHe7tsiJByc4SSVUxw==",
      "license": "MIT",
      "dependencies": {
        "follow-redirects": "^1.15.6",
        "form-data": "^4.0.0",
        "proxy-from-env": "^1.1.0"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "license": "MIT"
    },
    "node_modules/base64-js": {
      "version": "1.5.1",
      "resolved": "https://registry.npmjs.org/base64-js/-/base64-js-1.5.1.tgz",
      "integrity": "sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/big-integer": {
      "version": "1.6.52",
      "resolved": "https://registry.npmjs.org/big-integer/-/big-integer-1.6.52.tgz",
      "integrity": "sha512-QxD8cf2eVqJOOz63z6JIN9BzvVs/dlySa5HGSBH5xtR8dPteIRQnBxxKqkNTiT6jbDTF6jAfrd4oMcND9RGbQg==",
      "license": "Unlicense",
      "optional": true,
      "engines": {
        "node": ">=0.6"
      }
    },
    "node_modules/binary": {
      "version": "0.3.0",
      "resolved": "https://registry.npmjs.org/binary/-/binary-0.3.0.tgz",
      "integrity": "sha512-D4H1y5KYwpJgK8wk1Cue5LLPgmwHKYSChkbspQg5JtVuR5ulGckxfR62H3AE9UDkdMC8yyXlqYihuz3Aqg2XZg==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "buffers": "~0.1.1",
        "chainsaw": "~0.1.0"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/bl": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/bl/-/bl-4.1.0.tgz",
      "integrity": "sha512-1W07cM9gS6DcLperZfFSj+bWLtaPGSOHWhPiGzXmvVJbRLdG82sH/Kn8EtW1VqWVA54AKf2h5k5BbnIbwF3h6w==",
      "license": "MIT",
      "dependencies": {
        "buffer": "^5.5.0",
        "inherits": "^2.0.4",
        "readable-stream": "^3.4.0"
      }
    },
    "node_modules/bluebird": {
      "version": "3.4.7",
      "resolved": "https://registry.npmjs.org/bluebird/-/bluebird-3.4.7.tgz",
      "integrity": "sha512-iD3898SR7sWVRHbiQv+sHUtHnMvC1o3nW5rAcqnq3uOn07DSAppZYUkIGslDz6gXC7HfunPe7YVBgoEJASPcHA==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/brace-expansion": {
      "version": "1.1.12",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.12.tgz",
      "integrity": "sha512-9T9UjW3r0UW5c1Q7GTwllptXwhvYmEzFhzMfZ9H7FQWt+uZePjZPjBP/W1ZEyZ1twGWom5/56TF4lPcqjnDHcg==",
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/buffer": {
      "version": "5.7.1",
      "resolved": "https://registry.npmjs.org/buffer/-/buffer-5.7.1.tgz",
      "integrity": "sha512-EHcyIPBQ4BSGlvjB16k5KgAJ27CIsHY/2JBmCRReo48y9rQ3MaUzWX3KVlBa4U7MyX02HdVj0K7C3WaB3ju7FQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "base64-js": "^1.3.1",
        "ieee754": "^1.1.13"
      }
    },
    "node_modules/buffer-crc32": {
      "version": "0.2.13",
      "resolved": "https://registry.npmjs.org/buffer-crc32/-/buffer-crc32-0.2.13.tgz",
      "integrity": "sha512-VO9Ht/+p3SN7SKWqcrgEzjGbRSJYTx+Q1pTQC0wrWqHx0vpJraQ6GtHx8tvcg1rlK1byhU5gccxgOgj7B0TDkQ==",
      "license": "MIT",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/buffer-indexof-polyfill": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/buffer-indexof-polyfill/-/buffer-indexof-polyfill-1.0.2.tgz",
      "integrity": "sha512-I7wzHwA3t1/lwXQh+A5PbNvJxgfo5r3xulgpYDB5zckTu/Z9oUK9biouBKQUjEqzaz3HnAT6TYoovmE+GqSf7A==",
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/buffers": {
      "version": "0.1.1",
      "resolved": "https://registry.npmjs.org/buffers/-/buffers-0.1.1.tgz",
      "integrity": "sha512-9q/rDEGSb/Qsvv2qvzIzdluL5k7AaJOTrw23z9reQthrbF7is4CtlT0DXyO1oei2DCp4uojjzQ7igaSHp1kAEQ==",
      "optional": true,
      "engines": {
        "node": ">=0.2.0"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/chainsaw": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/chainsaw/-/chainsaw-0.1.0.tgz",
      "integrity": "sha512-75kWfWt6MEKNC8xYXIdRpDehRYY/tNSgwKaJq+dbbDcxORuVrrQ+SEHoWsniVn9XPYfP4gmdWIeDk/4YNp1rNQ==",
      "license": "MIT/X11",
      "optional": true,
      "dependencies": {
        "traverse": ">=0.3.0 <0.4"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/chownr": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/chownr/-/chownr-1.1.4.tgz",
      "integrity": "sha512-jJ0bqzaylmJtVnNgzTeSOs8DPavpbYgEr/b0YL8/2GO3xJEhInFmhKMUnEJQjZumK7KXGFhUy89PrsJWlakBVg==",
      "license": "ISC"
    },
    "node_modules/color": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/color/-/color-3.2.1.tgz",
      "integrity": "sha512-aBl7dZI9ENN6fUGC7mWpMTPNHmWUSNan9tuWN6ahh5ZLNk9baLJOnSMlrQkHcrfFgz2/RigjUVAjdx36VcemKA==",
      "license": "MIT",
      "dependencies": {
        "color-convert": "^1.9.3",
        "color-string": "^1.6.0"
      }
    },
    "node_modules/color-convert": {
      "version": "1.9.3",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-1.9.3.tgz",
      "integrity": "sha512-QfAUtd+vFdAtFQcC8CCyYt1fYWxSqAiK2cSD6zDB8N3cpsEBAvRxp9zOGg6G/SHHJYAT88/az/IuDGALsNVbGg==",
      "license": "MIT",
      "dependencies": {
        "color-name": "1.1.3"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.3.tgz",
      "integrity": "sha512-72fSenhMw2HZMTVHeCA9KCmpEIbzWiQsjN+BHcBbS9vr1mtt+vJjPdksIBNUmKAW8TFUDPJK5SUU3QhE9NEXDw==",
      "license": "MIT"
    },
    "node_modules/color-string": {
      "version": "1.9.1",
      "resolved": "https://registry.npmjs.org/color-string/-/color-string-1.9.1.tgz",
      "integrity": "sha512-shrVawQFojnZv6xM40anx4CkoDP+fZsw/ZerEMsW/pyzsRbElpsL/DBVW7q3ExxwusdNXI3lXpuhEZkzs8p5Eg==",
      "license": "MIT",
      "dependencies": {
        "color-name": "^1.0.0",
        "simple-swizzle": "^0.2.2"
      }
    },
    "node_modules/colorspace": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/colorspace/-/colorspace-1.1.4.tgz",
      "integrity": "sha512-BgvKJiuVu1igBUF2kEjRCZXol6wiiGbY5ipL/oVPwm0BL9sIpMIzM8IK7vwuxIIzOXMV3Ey5w+vxhm0rR/TN8w==",
      "license": "MIT",
      "dependencies": {
        "color": "^3.1.3",
        "text-hex": "1.0.x"
      }
    },
    "node_modules/combined-stream": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz",
      "integrity": "sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==",
      "license": "MIT",
      "dependencies": {
        "delayed-stream": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/compress-commons": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/compress-commons/-/compress-commons-4.1.2.tgz",
      "integrity": "sha512-D3uMHtGc/fcO1Gt1/L7i1e33VOvD4A9hfQLP+6ewd+BvG/gQ84Yh4oftEhAdjSMgBgwGL+jsppT7JYNpo6MHHg==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "buffer-crc32": "^0.2.13",
        "crc32-stream": "^4.0.2",
        "normalize-path": "^3.0.0",
        "readable-stream": "^3.6.0"
      },
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "license": "MIT"
    },
    "node_modules/core-util-is": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/core-util-is/-/core-util-is-1.0.3.tgz",
      "integrity": "sha512-ZQBvi1DcpJ4GDqanjucZ2Hj3wEO5pZDS89BWbkcrvdxksJorwUDDZamX9ldFkp9aw2lmBDLgkObEA4DWNJ9FYQ==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/crc-32": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/crc-32/-/crc-32-1.2.2.tgz",
      "integrity": "sha512-ROmzCKrTnOwybPcJApAA6WBWij23HVfGVNKqqrZpuyZOHqK2CwHSvpGuyt/UNNvaIjEd8X5IFGp4Mh+Ie1IHJQ==",
      "license": "Apache-2.0",
      "optional": true,
      "bin": {
        "crc32": "bin/crc32.njs"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/crc32-stream": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/crc32-stream/-/crc32-stream-4.0.3.tgz",
      "integrity": "sha512-NT7w2JVU7DFroFdYkeq8cywxrgjPHWkdX1wjpRQXPX5Asews3tA+Ght6lddQO5Mkumffp3X7GEqku3epj2toIw==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "crc-32": "^1.2.0",
        "readable-stream": "^3.4.0"
      },
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/cross-fetch": {
      "version": "3.1.5",
      "resolved": "https://registry.npmjs.org/cross-fetch/-/cross-fetch-3.1.5.tgz",
      "integrity": "sha512-lvb1SBsI0Z7GDwmuid+mU3kWVBwTVUbe7S0H52yaaAdQOXq2YktTCZdlAcNKFzE6QtRz0snpw9bNiPeOIkkQvw==",
      "license": "MIT",
      "dependencies": {
        "node-fetch": "2.6.7"
      }
    },
    "node_modules/cross-fetch/node_modules/node-fetch": {
      "version": "2.6.7",
      "resolved": "https://registry.npmjs.org/node-fetch/-/node-fetch-2.6.7.tgz",
      "integrity": "sha512-ZjMPFEfVx5j+y2yF35Kzx5sF7kDzxuDj6ziH4FFbOp87zKDZNx8yExJIb05OGF4Nlt9IHFIMBkRl41VdvcNdbQ==",
      "license": "MIT",
      "dependencies": {
        "whatwg-url": "^5.0.0"
      },
      "engines": {
        "node": "4.x || >=6.0.0"
      },
      "peerDependencies": {
        "encoding": "^0.1.0"
      },
      "peerDependenciesMeta": {
        "encoding": {
          "optional": true
        }
      }
    },
    "node_modules/debug": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.1.tgz",
      "integrity": "sha512-KcKCqiftBJcZr++7ykoDIEwSa3XWowTfNPo92BYxjXiyYEVrUQh2aLyhxBCwww+heortUFxEJYcRzosstTEBYQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/delayed-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
      "integrity": "sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/devtools-protocol": {
      "version": "0.0.1045489",
      "resolved": "https://registry.npmjs.org/devtools-protocol/-/devtools-protocol-0.0.1045489.tgz",
      "integrity": "sha512-D+PTmWulkuQW4D1NTiCRCFxF7pQPn0hgp4YyX4wAQ6xYXKOadSWPR3ENGDQ47MW/Ewc9v2rpC/UEEGahgBYpSQ==",
      "license": "BSD-3-Clause"
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/duplexer2": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/duplexer2/-/duplexer2-0.1.4.tgz",
      "integrity": "sha512-asLFVfWWtJ90ZyOUHMqk7/S2w2guQKxUI2itj3d92ADHhxUSbCMGi1f1cBcJ7xM1To+pE/Khbwo1yuNbMEPKeA==",
      "license": "BSD-3-Clause",
      "optional": true,
      "dependencies": {
        "readable-stream": "^2.0.2"
      }
    },
    "node_modules/duplexer2/node_modules/readable-stream": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.8.tgz",
      "integrity": "sha512-8p0AUk4XODgIewSi0l8Epjs+EVnWiK7NoDIEGU0HhE7+ZyY8D1IMY7odu5lRrFXGg71L15KG8QrPmum45RTtdA==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "node_modules/duplexer2/node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/duplexer2/node_modules/string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "safe-buffer": "~5.1.0"
      }
    },
    "node_modules/enabled": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/enabled/-/enabled-2.0.0.tgz",
      "integrity": "sha512-AKrN98kuwOzMIdAizXGI86UFBoo26CL21UM763y1h/GMSJ4/OHU9k2YlsmBpyScFo/wbLzWQJBMCW4+IO3/+OQ==",
      "license": "MIT"
    },
    "node_modules/end-of-stream": {
      "version": "1.4.5",
      "resolved": "https://registry.npmjs.org/end-of-stream/-/end-of-stream-1.4.5.tgz",
      "integrity": "sha512-ooEGc6HP26xXq/N+GCGOT0JKCLDGrq2bQUZrQ7gyrJiZANJ/8YDTxTpQBXGMn+WbIQXNVpyWymm7KYVICQnyOg==",
      "license": "MIT",
      "dependencies": {
        "once": "^1.4.0"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/extract-zip": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/extract-zip/-/extract-zip-2.0.1.tgz",
      "integrity": "sha512-GDhU9ntwuKyGXdZBUgTIe+vXnWj0fppUEtMDL0+idd5Sta8TGpHssn/eusA9mrPr9qNDym6SxAYZjNvCn/9RBg==",
      "license": "BSD-2-Clause",
      "dependencies": {
        "debug": "^4.1.1",
        "get-stream": "^5.1.0",
        "yauzl": "^2.10.0"
      },
      "bin": {
        "extract-zip": "cli.js"
      },
      "engines": {
        "node": ">= 10.17.0"
      },
      "optionalDependencies": {
        "@types/yauzl": "^2.9.1"
      }
    },
    "node_modules/fd-slicer": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/fd-slicer/-/fd-slicer-1.1.0.tgz",
      "integrity": "sha512-cE1qsB/VwyQozZ+q1dGxR8LBYNZeofhEdUNGSMbQD3Gw2lAzX9Zb3uIU6Ebc/Fmyjo9AWWfnn0AUCHqtevs/8g==",
      "license": "MIT",
      "dependencies": {
        "pend": "~1.2.0"
      }
    },
    "node_modules/fecha": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/fecha/-/fecha-4.2.3.tgz",
      "integrity": "sha512-OP2IUU6HeYKJi3i0z4A19kHMQoLVs4Hc+DPqqxI2h/DPZHTm/vjsfC6P0b4jCMy14XizLBqvndQ+UilD7707Jw==",
      "license": "MIT"
    },
    "node_modules/fluent-ffmpeg": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/fluent-ffmpeg/-/fluent-ffmpeg-2.1.3.tgz",
      "integrity": "sha512-Be3narBNt2s6bsaqP6Jzq91heDgOEaDCJAXcE3qcma/EJBSy5FB4cvO31XBInuAuKBx8Kptf8dkhjK0IOru39Q==",
      "deprecated": "Package no longer supported. Contact Support at https://www.npmjs.com/support for more info.",
      "license": "MIT",
      "dependencies": {
        "async": "^0.2.9",
        "which": "^1.1.1"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/fluent-ffmpeg/node_modules/async": {
      "version": "0.2.10",
      "resolved": "https://registry.npmjs.org/async/-/async-0.2.10.tgz",
      "integrity": "sha512-eAkdoKxU6/LkKDBzLpT+t6Ff5EtfSF4wx1WfJiPEEV7WNLnDaRXk0oVysiEPm262roaachGexwUv94WhSgN5TQ=="
    },
    "node_modules/fn.name": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/fn.name/-/fn.name-1.1.0.tgz",
      "integrity": "sha512-GRnmB5gPyJpAhTQdSZTSp9uaPSvl09KoYcMQtsB9rQoOmzs9dH6ffeccH+Z+cv6P68Hu5bC6JjRh4Ah/mHSNRw==",
      "license": "MIT"
    },
    "node_modules/follow-redirects": {
      "version": "1.15.9",
      "resolved": "https://registry.npmjs.org/follow-redirects/-/follow-redirects-1.15.9.tgz",
      "integrity": "sha512-gew4GsXizNgdoRyqmyfMHyAmXsZDk6mHkSxZFCzW9gwlbtOW44CDtYavM+y+72qD/Vq2l550kMF52DT8fOLJqQ==",
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/RubenVerborgh"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=4.0"
      },
      "peerDependenciesMeta": {
        "debug": {
          "optional": true
        }
      }
    },
    "node_modules/form-data": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/form-data/-/form-data-4.0.3.tgz",
      "integrity": "sha512-qsITQPfmvMOSAdeyZ+12I1c+CKSstAFAwu+97zrnWAbIr5u8wfsExUzCesVLC8NgHuRUqNN4Zy6UPWUTRGslcA==",
      "license": "MIT",
      "dependencies": {
        "asynckit": "^0.4.0",
        "combined-stream": "^1.0.8",
        "es-set-tostringtag": "^2.1.0",
        "hasown": "^2.0.2",
        "mime-types": "^2.1.12"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fs-constants": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs-constants/-/fs-constants-1.0.0.tgz",
      "integrity": "sha512-y6OAwoSIf7FyjMIv94u+b5rdheZEjzR63GTyZJm5qh4Bi+2YgwLCcI/fPFZkL5PSixOt6ZNKm+w+Hfp/Bciwow==",
      "license": "MIT"
    },
    "node_modules/fs-extra": {
      "version": "10.1.0",
      "resolved": "https://registry.npmjs.org/fs-extra/-/fs-extra-10.1.0.tgz",
      "integrity": "sha512-oRXApq54ETRj4eMiFzGnHWGy+zo5raudjuxN0b8H7s/RU2oW0Wvsx9O0ACRN/kRq9E8Vu/ReskGB5o3ji+FzHQ==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "graceful-fs": "^4.2.0",
        "jsonfile": "^6.0.1",
        "universalify": "^2.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "license": "ISC"
    },
    "node_modules/fstream": {
      "version": "1.0.12",
      "resolved": "https://registry.npmjs.org/fstream/-/fstream-1.0.12.tgz",
      "integrity": "sha512-WvJ193OHa0GHPEL+AycEJgxvBEwyfRkN1vhjca23OaPVMCaLCXTd5qAu82AjTcgP1UJmytkOKb63Ypde7raDIg==",
      "deprecated": "This package is no longer supported.",
      "license": "ISC",
      "optional": true,
      "dependencies": {
        "graceful-fs": "^4.1.2",
        "inherits": "~2.0.0",
        "mkdirp": ">=0.5 0",
        "rimraf": "2"
      },
      "engines": {
        "node": ">=0.6"
      }
    },
    "node_modules/fstream/node_modules/rimraf": {
      "version": "2.7.1",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-2.7.1.tgz",
      "integrity": "sha512-uWjbaKIK3T1OSVptzX7Nl6PvQ3qAGtKEtVRjRuazjfL3Bx5eI409VZSqgND+4UNnmzLVdPj9FqFJNPqBZFve4w==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "license": "ISC",
      "optional": true,
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-stream": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-5.2.0.tgz",
      "integrity": "sha512-nBF+F1rAZVCu/p7rjzgA+Yb4lfYXrpl7a6VmJrU8wF9I1CKvP/QwPNZHnOlwbTkY6dvtFIzFMSyQXbLoTQPRpA==",
      "license": "MIT",
      "dependencies": {
        "pump": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "license": "ISC",
      "optional": true
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/https-proxy-agent": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz",
      "integrity": "sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==",
      "license": "MIT",
      "dependencies": {
        "agent-base": "6",
        "debug": "4"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/ieee754": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/ieee754/-/ieee754-1.2.1.tgz",
      "integrity": "sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "BSD-3-Clause"
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "license": "ISC"
    },
    "node_modules/is-arrayish": {
      "version": "0.3.2",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.3.2.tgz",
      "integrity": "sha512-eVRqCvVlZbuw3GrM63ovNSNAeA1K16kaR/LRY/92w0zxQ5/1YzwblUX652i4Xs9RwAGjW9d9y6X88t8OaAJfWQ==",
      "license": "MIT"
    },
    "node_modules/is-stream": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-stream/-/is-stream-2.0.1.tgz",
      "integrity": "sha512-hFoiJiTl63nn+kstHGBtewWSKnQLpyb155KHheA1l39uvtO9nWIop1p3udqPcUd/xbF1VLMO4n7OI6p7RbngDg==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/isarray": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-1.0.0.tgz",
      "integrity": "sha512-VLghIWNM6ELQzo7zwmcg0NmTVyWKYjvIeM83yjp0wRDTmUnrM678fQbcKBo6n2CJEF0szoG//ytg+TKla89ALQ==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "license": "ISC"
    },
    "node_modules/jsonfile": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/jsonfile/-/jsonfile-6.1.0.tgz",
      "integrity": "sha512-5dgndWOriYSm5cnYaJNhalLNDKOqFwyDB/rr1E9ZsGciGvKPs8R2xYGCacuf3z6K1YKDz182fd+fY3cn3pMqXQ==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "universalify": "^2.0.0"
      },
      "optionalDependencies": {
        "graceful-fs": "^4.1.6"
      }
    },
    "node_modules/kuler": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/kuler/-/kuler-2.0.0.tgz",
      "integrity": "sha512-Xq9nH7KlWZmXAtodXDDRE7vs6DU1gTU8zYDHDiWLSip45Egwq3plLHzPn27NgvzL2r1LMPC1vdqh98sQxtqj4A==",
      "license": "MIT"
    },
    "node_modules/lazystream": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/lazystream/-/lazystream-1.0.1.tgz",
      "integrity": "sha512-b94GiNHQNy6JNTrt5w6zNyffMrNkXZb3KTkCZJb2V1xaEGCk093vkZ2jk3tpaeP33/OiXC+WvK9AxUebnf5nbw==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "readable-stream": "^2.0.5"
      },
      "engines": {
        "node": ">= 0.6.3"
      }
    },
    "node_modules/lazystream/node_modules/readable-stream": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.8.tgz",
      "integrity": "sha512-8p0AUk4XODgIewSi0l8Epjs+EVnWiK7NoDIEGU0HhE7+ZyY8D1IMY7odu5lRrFXGg71L15KG8QrPmum45RTtdA==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "node_modules/lazystream/node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/lazystream/node_modules/string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "safe-buffer": "~5.1.0"
      }
    },
    "node_modules/listenercount": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/listenercount/-/listenercount-1.0.1.tgz",
      "integrity": "sha512-3mk/Zag0+IJxeDrxSgaDPy4zZ3w05PRZeJNnlWhzFz5OkX49J4krc+A8X2d2M69vGMBEX0uyl8M+W+8gH+kBqQ==",
      "license": "ISC",
      "optional": true
    },
    "node_modules/lodash.defaults": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/lodash.defaults/-/lodash.defaults-4.2.0.tgz",
      "integrity": "sha512-qjxPLHd3r5DnsdGacqOMU6pb/avJzdh9tFX2ymgoZE27BmjXrNy/y4LoaiTeAb+O3gL8AfpJGtqfX/ae2leYYQ==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/lodash.difference": {
      "version": "4.5.0",
      "resolved": "https://registry.npmjs.org/lodash.difference/-/lodash.difference-4.5.0.tgz",
      "integrity": "sha512-dS2j+W26TQ7taQBGN8Lbbq04ssV3emRw4NY58WErlTO29pIqS0HmoT5aJ9+TUQ1N3G+JOZSji4eugsWwGp9yPA==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/lodash.flatten": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/lodash.flatten/-/lodash.flatten-4.4.0.tgz",
      "integrity": "sha512-C5N2Z3DgnnKr0LOpv/hKCgKdb7ZZwafIrsesve6lmzvZIRZRGaZ/l6Q8+2W7NaT+ZwO3fFlSCzCzrDCFdJfZ4g==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/lodash.isplainobject": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/lodash.isplainobject/-/lodash.isplainobject-4.0.6.tgz",
      "integrity": "sha512-oSXzaWypCMHkPC3NvBEaPHf0KsA5mvPrOPgQWDsbg8n7orZ290M0BmC/jgRZ4vcJ6DTAhjrsSYgdsW/F+MFOBA==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/lodash.union": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/lodash.union/-/lodash.union-4.6.0.tgz",
      "integrity": "sha512-c4pB2CdGrGdjMKYLA+XiRDO7Y0PRQbm/Gzg8qMj+QH+pFVAoTp5sBpO0odL3FjoPCGjK96p6qsP+yQoiLoOBcw==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/logform": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/logform/-/logform-2.7.0.tgz",
      "integrity": "sha512-TFYA4jnP7PVbmlBIfhlSe+WKxs9dklXMTEGcBCIvLhE/Tn3H6Gk1norupVW7m5Cnd4bLcr08AytbyV/xj7f/kQ==",
      "license": "MIT",
      "dependencies": {
        "@colors/colors": "1.6.0",
        "@types/triple-beam": "^1.3.2",
        "fecha": "^4.2.0",
        "ms": "^2.1.1",
        "safe-stable-stringify": "^2.3.1",
        "triple-beam": "^1.3.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/mime": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/mime/-/mime-3.0.0.tgz",
      "integrity": "sha512-jSCU7/VB1loIWBZe14aEYHU/+1UMEHoaO7qxCOVJOw9GgH72VAWppxNcjU+x9a2k3GSIBXNKxXQFqRvvZ7vr3A==",
      "license": "MIT",
      "bin": {
        "mime": "cli.js"
      },
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "license": "MIT",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz",
      "integrity": "sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==",
      "license": "MIT",
      "optional": true,
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/mkdirp": {
      "version": "0.5.6",
      "resolved": "https://registry.npmjs.org/mkdirp/-/mkdirp-0.5.6.tgz",
      "integrity": "sha512-FP+p8RB8OWpF3YZBCrP5gtADmtXApB5AMLn+vdyA+PyxCjrCs00mjyUozssO33cwDeT3wNGdLxJ5M//YqtHAJw==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "minimist": "^1.2.6"
      },
      "bin": {
        "mkdirp": "bin/cmd.js"
      }
    },
    "node_modules/mkdirp-classic": {
      "version": "0.5.3",
      "resolved": "https://registry.npmjs.org/mkdirp-classic/-/mkdirp-classic-0.5.3.tgz",
      "integrity": "sha512-gKLcREMhtuZRwRAfqP3RFW+TK4JqApVBtOIftVgjuABpAtpxhPGaDcfvbhNvD0B8iD1oUr/txX35NjcaY6Ns/A==",
      "license": "MIT"
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/node-fetch": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/node-fetch/-/node-fetch-2.7.0.tgz",
      "integrity": "sha512-c4FRfUm/dbcWZ7U+1Wq0AwCyFL+3nt2bEw05wfxSz+DWpWsitgmSgYmy2dQdWyKC1694ELPqMs/YzUSNozLt8A==",
      "license": "MIT",
      "dependencies": {
        "whatwg-url": "^5.0.0"
      },
      "engines": {
        "node": "4.x || >=6.0.0"
      },
      "peerDependencies": {
        "encoding": "^0.1.0"
      },
      "peerDependenciesMeta": {
        "encoding": {
          "optional": true
        }
      }
    },
    "node_modules/node-webpmux": {
      "version": "3.1.7",
      "resolved": "https://registry.npmjs.org/node-webpmux/-/node-webpmux-3.1.7.tgz",
      "integrity": "sha512-ySkL4lBCto86OyQ0blAGzylWSECcn5I0lM3bYEhe75T8Zxt/BFUMHa8ktUguR7zwXNdS/Hms31VfSsYKN1383g==",
      "license": "ISC"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/one-time": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/one-time/-/one-time-1.0.0.tgz",
      "integrity": "sha512-5DXOiRKwuSEcQ/l0kGCF6Q3jcADFv5tSmRaJck/OqkVFcOzutB134KRSfF0xDrL39MNnqxbHBbUUcjZIhTgb2g==",
      "license": "MIT",
      "dependencies": {
        "fn.name": "1.x.x"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pend": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/pend/-/pend-1.2.0.tgz",
      "integrity": "sha512-F3asv42UuXchdzt+xXqfW1OGlVBe+mxa2mqI0pg5yAHZPvFmY3Y6drSf/GQ1A86WgWEN9Kzh/WrgKa6iGcHXLg==",
      "license": "MIT"
    },
    "node_modules/process-nextick-args": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/process-nextick-args/-/process-nextick-args-2.0.1.tgz",
      "integrity": "sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/progress": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/progress/-/progress-2.0.3.tgz",
      "integrity": "sha512-7PiHtLll5LdnKIMw100I+8xJXR5gW2QwWYkT6iJva0bXitZKa/XMrSbdmg3r2Xnaidz9Qumd0VPaMrZlF9V9sA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/proxy-from-env": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/proxy-from-env/-/proxy-from-env-1.1.0.tgz",
      "integrity": "sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg==",
      "license": "MIT"
    },
    "node_modules/pump": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/pump/-/pump-3.0.3.tgz",
      "integrity": "sha512-todwxLMY7/heScKmntwQG8CXVkWUOdYxIvY2s0VWAAMh/nd8SoYiRaKjlr7+iCs984f2P8zvrfWcDDYVb73NfA==",
      "license": "MIT",
      "dependencies": {
        "end-of-stream": "^1.1.0",
        "once": "^1.3.1"
      }
    },
    "node_modules/puppeteer": {
      "version": "18.2.1",
      "resolved": "https://registry.npmjs.org/puppeteer/-/puppeteer-18.2.1.tgz",
      "integrity": "sha512-7+UhmYa7wxPh2oMRwA++k8UGVDxh3YdWFB52r9C3tM81T6BU7cuusUSxImz0GEYSOYUKk/YzIhkQ6+vc0gHbxQ==",
      "deprecated": "< 22.8.2 is no longer supported",
      "hasInstallScript": true,
      "license": "Apache-2.0",
      "dependencies": {
        "https-proxy-agent": "5.0.1",
        "progress": "2.0.3",
        "proxy-from-env": "1.1.0",
        "puppeteer-core": "18.2.1"
      },
      "engines": {
        "node": ">=14.1.0"
      }
    },
    "node_modules/puppeteer-core": {
      "version": "18.2.1",
      "resolved": "https://registry.npmjs.org/puppeteer-core/-/puppeteer-core-18.2.1.tgz",
      "integrity": "sha512-MRtTAZfQTluz3U2oU/X2VqVWPcR1+94nbA2V6ZrSZRVEwLqZ8eclZ551qGFQD/vD2PYqHJwWOW/fpC721uznVw==",
      "license": "Apache-2.0",
      "dependencies": {
        "cross-fetch": "3.1.5",
        "debug": "4.3.4",
        "devtools-protocol": "0.0.1045489",
        "extract-zip": "2.0.1",
        "https-proxy-agent": "5.0.1",
        "proxy-from-env": "1.1.0",
        "rimraf": "3.0.2",
        "tar-fs": "2.1.1",
        "unbzip2-stream": "1.4.3",
        "ws": "8.9.0"
      },
      "engines": {
        "node": ">=14.1.0"
      }
    },
    "node_modules/puppeteer-core/node_modules/debug": {
      "version": "4.3.4",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.3.4.tgz",
      "integrity": "sha512-PRWFHuSU3eDtQJPvnNY7Jcket1j0t5OuOsFzPPzsekD52Zl8qUfFIPEiswXqIvHWGVHOgX+7G/vCNNhehwxfkQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "2.1.2"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/puppeteer-core/node_modules/ms": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.2.tgz",
      "integrity": "sha512-sGkPx+VjMtmA6MX27oA4FBFELFCZZ4S4XqeGOXCv68tT+jb3vk/RyaKWP0PTKyWtmLSM0b+adUTEvbs1PEaH2w==",
      "license": "MIT"
    },
    "node_modules/qrcode-terminal": {
      "version": "0.12.0",
      "resolved": "https://registry.npmjs.org/qrcode-terminal/-/qrcode-terminal-0.12.0.tgz",
      "integrity": "sha512-EXtzRZmC+YGmGlDFbXKxQiMZNwCLEO6BANKXG4iCtSIM0yqc/pappSx3RIKr4r0uh5JsBckOXeKrB3Iz7mdQpQ==",
      "bin": {
        "qrcode-terminal": "bin/qrcode-terminal.js"
      }
    },
    "node_modules/readable-stream": {
      "version": "3.6.2",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-3.6.2.tgz",
      "integrity": "sha512-9u/sniCrY3D5WdsERHzHE4G2YCXqoG5FTHUiCC4SIbr6XcLZBY05ya9EKjYek9O5xOAwjGq+1JdGBAS7Q9ScoA==",
      "license": "MIT",
      "dependencies": {
        "inherits": "^2.0.3",
        "string_decoder": "^1.1.1",
        "util-deprecate": "^1.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/readdir-glob": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/readdir-glob/-/readdir-glob-1.1.3.tgz",
      "integrity": "sha512-v05I2k7xN8zXvPD9N+z/uhXPaj0sUFCe2rcWZIpBsqxfP7xXFQ0tipAd/wjj1YxWyWtUS5IDJpOG82JKt2EAVA==",
      "license": "Apache-2.0",
      "optional": true,
      "dependencies": {
        "minimatch": "^5.1.0"
      }
    },
    "node_modules/readdir-glob/node_modules/brace-expansion": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.2.tgz",
      "integrity": "sha512-Jt0vHyM+jmUBqojB7E1NIYadt0vI0Qxjxd2TErW94wDz+E2LAm5vKMXXwg6ZZBTHPuUlDgQHKXvjGBdfcF1ZDQ==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/readdir-glob/node_modules/minimatch": {
      "version": "5.1.6",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-5.1.6.tgz",
      "integrity": "sha512-lKwV/1brpG6mBUFHtb7NUmtABCb2WZZmm2wNiOA5hAb8VdCS4B3dtMWyvcoViccwAW/COERjXLt0zP1zXUN26g==",
      "license": "ISC",
      "optional": true,
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "license": "ISC",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/safe-buffer": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.2.1.tgz",
      "integrity": "sha512-rp3So07KcdmmKbGvgaNxQSJr7bGVSVk5S9Eq1F+ppbRo70+YeaDxkw5Dd8NPN+GD6bjnYm2VuPuCXmpuYvmCXQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/safe-stable-stringify": {
      "version": "2.5.0",
      "resolved": "https://registry.npmjs.org/safe-stable-stringify/-/safe-stable-stringify-2.5.0.tgz",
      "integrity": "sha512-b3rppTKm9T+PsVCBEOUR46GWI7fdOs00VKZ1+9c1EWDaDMvjQc6tUwuFyIprgGgTcWoVHSKrU8H31ZHA2e0RHA==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/setimmediate": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/setimmediate/-/setimmediate-1.0.5.tgz",
      "integrity": "sha512-MATJdZp8sLqDl/68LfQmbP8zKPLQNV6BIZoIgrscFDQ+RsvK/BxeDQOgyxKKoh0y/8h3BqVFnCqQ/gd+reiIXA==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/simple-swizzle": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/simple-swizzle/-/simple-swizzle-0.2.2.tgz",
      "integrity": "sha512-JA//kQgZtbuY83m+xT+tXJkmJncGMTFT+C+g2h2R9uxkYIrE2yy9sgmcLhCnw57/WSD+Eh3J97FPEDFnbXnDUg==",
      "license": "MIT",
      "dependencies": {
        "is-arrayish": "^0.3.1"
      }
    },
    "node_modules/stack-trace": {
      "version": "0.0.10",
      "resolved": "https://registry.npmjs.org/stack-trace/-/stack-trace-0.0.10.tgz",
      "integrity": "sha512-KGzahc7puUKkzyMt+IqAep+TVNbKP+k2Lmwhub39m1AsTSkaDutx56aDCo+HLDzf/D26BIHTJWNiTG1KAJiQCg==",
      "license": "MIT",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/string_decoder": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.3.0.tgz",
      "integrity": "sha512-hkRX8U1WjJFd8LsDJ2yQ/wWWxaopEsABU1XfkM8A+j0+85JAGppt16cr1Whg6KIbb4okU6Mql6BOj+uup/wKeA==",
      "license": "MIT",
      "dependencies": {
        "safe-buffer": "~5.2.0"
      }
    },
    "node_modules/tar-fs": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/tar-fs/-/tar-fs-2.1.1.tgz",
      "integrity": "sha512-V0r2Y9scmbDRLCNex/+hYzvp/zyYjvFbHPNgVTKfQvVrb6guiE/fxP+XblDNR011utopbkex2nM4dHNV6GDsng==",
      "license": "MIT",
      "dependencies": {
        "chownr": "^1.1.1",
        "mkdirp-classic": "^0.5.2",
        "pump": "^3.0.0",
        "tar-stream": "^2.1.4"
      }
    },
    "node_modules/tar-stream": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/tar-stream/-/tar-stream-2.2.0.tgz",
      "integrity": "sha512-ujeqbceABgwMZxEJnk2HDY2DlnUZ+9oEcb1KzTVfYHio0UE6dG71n60d8D2I4qNvleWrrXpmjpt7vZeF1LnMZQ==",
      "license": "MIT",
      "dependencies": {
        "bl": "^4.0.3",
        "end-of-stream": "^1.4.1",
        "fs-constants": "^1.0.0",
        "inherits": "^2.0.3",
        "readable-stream": "^3.1.1"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/text-hex": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/text-hex/-/text-hex-1.0.0.tgz",
      "integrity": "sha512-uuVGNWzgJ4yhRaNSiubPY7OjISw4sw4E5Uv0wbjp+OzcbmVU/rsT8ujgcXJhn9ypzsgr5vlzpPqP+MBBKcGvbg==",
      "license": "MIT"
    },
    "node_modules/through": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/through/-/through-2.3.8.tgz",
      "integrity": "sha512-w89qg7PI8wAdvX60bMDP+bFoD5Dvhm9oLheFp5O4a2QF0cSBGsBX4qZmadPMvVqlLJBBci+WqGGOAPvcDeNSVg==",
      "license": "MIT"
    },
    "node_modules/tr46": {
      "version": "0.0.3",
      "resolved": "https://registry.npmjs.org/tr46/-/tr46-0.0.3.tgz",
      "integrity": "sha512-N3WMsuqV66lT30CrXNbEjx4GEwlow3v6rr4mCcv6prnfwhS01rkgyFdjPNBYd9br7LpXV1+Emh01fHnq2Gdgrw==",
      "license": "MIT"
    },
    "node_modules/traverse": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/traverse/-/traverse-0.3.9.tgz",
      "integrity": "sha512-iawgk0hLP3SxGKDfnDJf8wTz4p2qImnyihM5Hh/sGvQ3K37dPi/w8sRhdNIxYA1TwFwc5mDhIJq+O0RsvXBKdQ==",
      "license": "MIT/X11",
      "optional": true,
      "engines": {
        "node": "*"
      }
    },
    "node_modules/triple-beam": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/triple-beam/-/triple-beam-1.4.1.tgz",
      "integrity": "sha512-aZbgViZrg1QNcG+LULa7nhZpJTZSLm/mXnHXnbAbjmN5aSa0y7V+wvv6+4WaBtpISJzThKy+PIPxc1Nq1EJ9mg==",
      "license": "MIT",
      "engines": {
        "node": ">= 14.0.0"
      }
    },
    "node_modules/unbzip2-stream": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/unbzip2-stream/-/unbzip2-stream-1.4.3.tgz",
      "integrity": "sha512-mlExGW4w71ebDJviH16lQLtZS32VKqsSfk80GCfUlwT/4/hNRFsoscrF/c++9xinkMzECL1uL9DDwXqFWkruPg==",
      "license": "MIT",
      "dependencies": {
        "buffer": "^5.2.1",
        "through": "^2.3.8"
      }
    },
    "node_modules/undici-types": {
      "version": "7.8.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-7.8.0.tgz",
      "integrity": "sha512-9UJ2xGDvQ43tYyVMpuHlsgApydB8ZKfVYTsLDhXkFL/6gfkp+U8xTGdh8pMJv1SpZna0zxG1DwsKZsreLbXBxw==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/universalify": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/universalify/-/universalify-2.0.1.tgz",
      "integrity": "sha512-gptHNQghINnc/vTGIk0SOFGFNXw7JVrlRUtConJRlvaw6DuX0wO5Jeko9sWrMBhh+PsYAZ7oXAiOnf/UKogyiw==",
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">= 10.0.0"
      }
    },
    "node_modules/unzipper": {
      "version": "0.10.14",
      "resolved": "https://registry.npmjs.org/unzipper/-/unzipper-0.10.14.tgz",
      "integrity": "sha512-ti4wZj+0bQTiX2KmKWuwj7lhV+2n//uXEotUmGuQqrbVZSEGFMbI68+c6JCQ8aAmUWYvtHEz2A8K6wXvueR/6g==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "big-integer": "^1.6.17",
        "binary": "~0.3.0",
        "bluebird": "~3.4.1",
        "buffer-indexof-polyfill": "~1.0.0",
        "duplexer2": "~0.1.4",
        "fstream": "^1.0.12",
        "graceful-fs": "^4.2.2",
        "listenercount": "~1.0.1",
        "readable-stream": "~2.3.6",
        "setimmediate": "~1.0.4"
      }
    },
    "node_modules/unzipper/node_modules/readable-stream": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.3.8.tgz",
      "integrity": "sha512-8p0AUk4XODgIewSi0l8Epjs+EVnWiK7NoDIEGU0HhE7+ZyY8D1IMY7odu5lRrFXGg71L15KG8QrPmum45RTtdA==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "core-util-is": "~1.0.0",
        "inherits": "~2.0.3",
        "isarray": "~1.0.0",
        "process-nextick-args": "~2.0.0",
        "safe-buffer": "~5.1.1",
        "string_decoder": "~1.1.1",
        "util-deprecate": "~1.0.1"
      }
    },
    "node_modules/unzipper/node_modules/safe-buffer": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/safe-buffer/-/safe-buffer-5.1.2.tgz",
      "integrity": "sha512-Gd2UZBJDkXlY7GbJxfsE8/nvKkUEU1G38c1siN6QP6a9PT9MmHB8GnpscSmMJSoF8LOIrt8ud/wPtojys4G6+g==",
      "license": "MIT",
      "optional": true
    },
    "node_modules/unzipper/node_modules/string_decoder": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/string_decoder/-/string_decoder-1.1.1.tgz",
      "integrity": "sha512-n/ShnvDi6FHbbVfviro+WojiFzv+s8MPMHBczVePfUpDJLwoLT0ht1l4YwBCbi8pJAveEEdnkHyPyTP/mzRfwg==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "safe-buffer": "~5.1.0"
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "license": "MIT"
    },
    "node_modules/webidl-conversions": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-3.0.1.tgz",
      "integrity": "sha512-2JAn3z8AR6rjK8Sm8orRC0h/bcl/DqL7tRPdGZ4I1CjdF+EaMLmYxBHyXuKL849eucPFhvBoxMsflfOb8kxaeQ==",
      "license": "BSD-2-Clause"
    },
    "node_modules/whatsapp-web.js": {
      "version": "1.31.0",
      "resolved": "https://registry.npmjs.org/whatsapp-web.js/-/whatsapp-web.js-1.31.0.tgz",
      "integrity": "sha512-oUfrgSx7s906flFmATA0Hqb8DJYv0tdB28KMQ7dWiua8NqcO1+8IFHE278YvSuFkBqRqH+fSfQrGmwh/4Mx/LQ==",
      "license": "Apache-2.0",
      "dependencies": {
        "@pedroslopez/moduleraid": "^5.0.2",
        "fluent-ffmpeg": "2.1.3",
        "mime": "^3.0.0",
        "node-fetch": "^2.6.9",
        "node-webpmux": "3.1.7",
        "puppeteer": "^18.2.1"
      },
      "engines": {
        "node": ">=18.0.0"
      },
      "optionalDependencies": {
        "archiver": "^5.3.1",
        "fs-extra": "^10.1.0",
        "unzipper": "^0.10.11"
      }
    },
    "node_modules/whatwg-url": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-5.0.0.tgz",
      "integrity": "sha512-saE57nupxk6v3HY35+jzBwYa0rKSy0XR8JSxZPwgLr7ys0IBzhGviA1/TUGJLmSVqs8pb9AnvICXEuOHLprYTw==",
      "license": "MIT",
      "dependencies": {
        "tr46": "~0.0.3",
        "webidl-conversions": "^3.0.0"
      }
    },
    "node_modules/which": {
      "version": "1.3.1",
      "resolved": "https://registry.npmjs.org/which/-/which-1.3.1.tgz",
      "integrity": "sha512-HxJdYWq1MTIQbJ3nw0cqssHoTNU267KlrDuGZ1WYlxDStUtKUhOaJmh112/TZmHxxUfuJqPXSOm7tDyas0OSIQ==",
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "which": "bin/which"
      }
    },
    "node_modules/winston": {
      "version": "3.17.0",
      "resolved": "https://registry.npmjs.org/winston/-/winston-3.17.0.tgz",
      "integrity": "sha512-DLiFIXYC5fMPxaRg832S6F5mJYvePtmO5G9v9IgUFPhXm9/GkXarH/TUrBAVzhTCzAj9anE/+GjrgXp/54nOgw==",
      "license": "MIT",
      "dependencies": {
        "@colors/colors": "^1.6.0",
        "@dabh/diagnostics": "^2.0.2",
        "async": "^3.2.3",
        "is-stream": "^2.0.0",
        "logform": "^2.7.0",
        "one-time": "^1.0.0",
        "readable-stream": "^3.4.0",
        "safe-stable-stringify": "^2.3.1",
        "stack-trace": "0.0.x",
        "triple-beam": "^1.3.0",
        "winston-transport": "^4.9.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/winston-transport": {
      "version": "4.9.0",
      "resolved": "https://registry.npmjs.org/winston-transport/-/winston-transport-4.9.0.tgz",
      "integrity": "sha512-8drMJ4rkgaPo1Me4zD/3WLfI/zPdA9o2IipKODunnGDcuqbHwjsbB79ylv04LCGGzU0xQ6vTznOMpQGaLhhm6A==",
      "license": "MIT",
      "dependencies": {
        "logform": "^2.7.0",
        "readable-stream": "^3.6.2",
        "triple-beam": "^1.3.0"
      },
      "engines": {
        "node": ">= 12.0.0"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "license": "ISC"
    },
    "node_modules/ws": {
      "version": "8.9.0",
      "resolved": "https://registry.npmjs.org/ws/-/ws-8.9.0.tgz",
      "integrity": "sha512-Ja7nszREasGaYUYCI2k4lCKIRTt+y7XuqVoHR44YpI49TtryyqbqvDMn5eqfW7e6HzTukDRIsXqzVHScqRcafg==",
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      },
      "peerDependencies": {
        "bufferutil": "^4.0.1",
        "utf-8-validate": "^5.0.2"
      },
      "peerDependenciesMeta": {
        "bufferutil": {
          "optional": true
        },
        "utf-8-validate": {
          "optional": true
        }
      }
    },
    "node_modules/yauzl": {
      "version": "2.10.0",
      "resolved": "https://registry.npmjs.org/yauzl/-/yauzl-2.10.0.tgz",
      "integrity": "sha512-p4a9I6X6nu6IhoGmBqAcbJy1mlC4j27vEPZX9F4L4/vZT3Lyq1VkFHw/V/PUcB9Buo+DG3iHkT0x3Qya58zc3g==",
      "license": "MIT",
      "dependencies": {
        "buffer-crc32": "~0.2.3",
        "fd-slicer": "~1.1.0"
      }
    },
    "node_modules/zip-stream": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/zip-stream/-/zip-stream-4.1.1.tgz",
      "integrity": "sha512-9qv4rlDiopXg4E69k+vMHjNN63YFMe9sZMrdlvKnCjlCRWeCBswPPMPUfx+ipsAWq1LXHe70RcbaHdJJpS6hyQ==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "archiver-utils": "^3.0.4",
        "compress-commons": "^4.1.2",
        "readable-stream": "^3.6.0"
      },
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/zip-stream/node_modules/archiver-utils": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/archiver-utils/-/archiver-utils-3.0.4.tgz",
      "integrity": "sha512-KVgf4XQVrTjhyWmx6cte4RxonPLR9onExufI1jhvw/MQ4BB6IsZD5gT8Lq+u/+pRkWna/6JoHpiQioaqFP5Rzw==",
      "license": "MIT",
      "optional": true,
      "dependencies": {
        "glob": "^7.2.3",
        "graceful-fs": "^4.2.0",
        "lazystream": "^1.0.0",
        "lodash.defaults": "^4.2.0",
        "lodash.difference": "^4.5.0",
        "lodash.flatten": "^4.4.0",
        "lodash.isplainobject": "^4.0.6",
        "lodash.union": "^4.6.0",
        "normalize-path": "^3.0.0",
        "readable-stream": "^3.6.0"
      },
      "engines": {
        "node": ">= 10"
      }
    }
  }
}

# --- END OF FILE WA/package-lock.json ---


================================================================================ðŸ“„ WA/package.json================================================================================
# --- START OF FILE WA/package.json ---
{
  "dependencies": {
    "axios": "^1.8.4",
    "qrcode-terminal": "^0.12.0",
    "whatsapp-web.js": "^1.27.0",
    "winston": "^3.13.0"
  }
}

# --- END OF FILE WA/package.json ---


================================================================================ðŸ“„ WA/wa_bridge.js================================================================================
# --- START OF FILE WA/wa_bridge.js ---
// wa_bridge.js

// --- Dependencies ---
const { Client, LocalAuth } = require('whatsapp-web.js');
const qrcode = require('qrcode-terminal');
const axios = require('axios');
const winston = require('winston');

// --- Configuration ---
const FASTAPI_BASE_URL = process.env.FASTAPI_BASE_URL || 'http://localhost:8001';
const FAST_POLLING_INTERVAL_MS = 1500; // Poll quickly when connected
const SLOW_POLLING_INTERVAL_MS = 10000; // Poll slowly when backend is down
const MAX_SEND_RETRIES = 3;
const SEND_RETRY_DELAY_MS = 2000;
const MAX_ACK_RETRIES = 3;
const ACK_RETRY_DELAY_MS = 3000;

// --- Winston Logger ---
const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.printf(({ timestamp, level, message }) => `${timestamp} [${level.toUpperCase()}] [wa_bridge] ${message}`)
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'logs/kairo_wa_bridge_error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/kairo_wa_bridge_combined.log' }),
  ],
});

// --- State Variables ---
let isClientReady = false;
let clientInstance;
let _stopPollingFlag = false;
let isBackendConnected = true;
const processedMessageIDs = new Set(); // In-memory set to prevent double-sends in a session

// --- Utility: Sleep Function ---
function sleep(ms) { return new Promise(resolve => setTimeout(resolve, ms)); }

// --- Initialize the WhatsApp client ---
const client = new Client({
    authStrategy: new LocalAuth({ dataPath: '.wwebjs_auth' }),
    puppeteer: {
        headless: true,
        args: ['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
    }
});
clientInstance = client;

// --- Event Handlers ---
client.on('qr', qr => { qrcode.generate(qr, { small: true }); });
client.on('ready', () => {
    logger.info('WhatsApp client is ready!');
    isClientReady = true;
    pollForOutgoingMessages();
});
client.on('auth_failure', msg => {
    logger.error(`AUTHENTICATION FAILURE: ${msg}. Shutting down.`);
    shutdownBridge('AUTH_FAILURE', 1);
});
client.on('disconnected', reason => {
    logger.error(`Client disconnected: ${reason}. Shutting down.`);
    shutdownBridge('DISCONNECTED', 1);
});
client.on('error', err => {
    logger.error(`Unhandled WhatsApp client error: ${err.message}`);
});

client.on('message', async (message) => {
    const chat = await message.getChat();
    if (message.isStatus || chat.isGroup) return; // Ignore status updates and group chats

    logger.info(`Received message from ${message.from}: "${message.body.substring(0, 50)}..." (ID: ${message.id._serialized})`);
    try {
        // --- THIS IS THE FIX ---
        // Include the unique message ID in the payload to the backend.
        await axios.post(`${FASTAPI_BASE_URL}/incoming`, {
            user_id: message.from,
            message: message.body,
            message_id: message.id._serialized // Pass the unique ID
        }, { timeout: 10000 });
        // --- END OF FIX ---
    } catch (error) {
        logger.error(`Failed to send incoming message to backend: ${error.message}`);
    }
});

// --- Main Polling Function ---
async function pollForOutgoingMessages() {
    if (_stopPollingFlag) return;
    if (!isClientReady) {
        setTimeout(pollForOutgoingMessages, 5000);
        return;
    }

    try {
        const response = await axios.get(`${FASTAPI_BASE_URL}/outgoing`, { timeout: 5000 });
        if (!isBackendConnected) {
            logger.info('Connection to Kairo backend RESTORED. Resuming normal polling.');
            isBackendConnected = true;
        }

        const messages = response.data.messages;
        if (messages && messages.length > 0) {
            for (const msg of messages) {
                if (processedMessageIDs.has(msg.message_id)) continue;
                processedMessageIDs.add(msg.message_id);

                let sentSuccessfully = false;
                for (let attempt = 1; attempt <= MAX_SEND_RETRIES; attempt++) {
                    try {
                        await client.sendMessage(msg.user_id, msg.message);
                        sentSuccessfully = true;
                        logger.info(`Message sent to ${msg.user_id} (ID: ${msg.message_id})`);
                        break;
                    } catch (sendError) {
                        logger.error(`Send attempt ${attempt} failed for ID ${msg.message_id}: ${sendError.message}`);
                        if (attempt < MAX_SEND_RETRIES) await sleep(SEND_RETRY_DELAY_MS);
                    }
                }

                if (sentSuccessfully) {
                    let ackSentSuccessfully = false;
                    for (let ackAttempt = 1; ackAttempt <= MAX_ACK_RETRIES; ackAttempt++) {
                        try {
                            await axios.post(`${FASTAPI_BASE_URL}/ack`, { message_id: msg.message_id }, { timeout: 3000 });
                            ackSentSuccessfully = true;
                            break;
                        } catch (ackError) {
                            logger.error(`ACK attempt ${ackAttempt} failed for ID ${msg.message_id}: ${ackError.message}`);
                            if (ackAttempt < MAX_ACK_RETRIES) await sleep(ACK_RETRY_DELAY_MS);
                        }
                    }
                    if (!ackSentSuccessfully) {
                        logger.error(`All ACK attempts failed for message ID: ${msg.message_id}. It will be retried later.`);
                        processedMessageIDs.delete(msg.message_id);
                    }
                } else {
                    processedMessageIDs.delete(msg.message_id);
                }
            }
        }
    } catch (error) {
        if (isBackendConnected) {
            logger.error(`Connection to Kairo backend LOST. Switching to slow poll mode.`);
            isBackendConnected = false;
        }
    } finally {
        if (!_stopPollingFlag) {
            const nextPollDelay = isBackendConnected ? FAST_POLLING_INTERVAL_MS : SLOW_POLLING_INTERVAL_MS;
            setTimeout(pollForOutgoingMessages, nextPollDelay);
        }
    }
}

// --- Shutdown and Initialization ---
async function shutdownBridge(signal, exitCode = 0) {
    if (_stopPollingFlag) return;
    _stopPollingFlag = true;
    logger.warn(`Received ${signal}, initiating graceful shutdown...`);
    if (clientInstance) {
        try { await clientInstance.destroy(); logger.info('WhatsApp client destroyed.'); }
        catch (e) { logger.error(`Error destroying client: ${e.message}`); }
    }
    logger.warn('Bridge shutdown complete.');
    process.exit(exitCode);
}

process.on('SIGINT', () => shutdownBridge('SIGINT'));
process.on('SIGTERM', () => shutdownBridge('SIGTERM'));

client.initialize().catch(err => {
    logger.error(`CRITICAL: Client initialization failed: ${err.message}. Exiting.`);
    process.exit(1);
});
# --- END OF FILE WA/wa_bridge.js ---


================================================================================ðŸ“„ agents/kairo_agent.py================================================================================
# --- START OF FILE agents/kairo_agent.py ---
# agents/kairo_agent.py
import json
from typing import Dict, List, Any

# Core application imports
from services.llm_interface import get_instructor_client
from .tool_definitions import AVAILABLE_TOOLS, TOOL_PARAM_MODELS
from tools.logger import log_info, log_error
from services.shared_resources import get_prompt, get_message_templates
from users.user_manager import add_message_to_user_history
import tools.activity_db as db

ERROR_TEMPLATES = get_message_templates("generic_error_message") or {}
GENERIC_ERROR_MSG = ERROR_TEMPLATES.get("en", "Sorry, an error occurred.")

def handle_user_request(user_id: str, message: str, full_context: Dict) -> str:
    """Handles all incoming requests (user messages & system triggers) for Kairo."""
    fn_name = "handle_user_request"
    client = get_instructor_client()
    if not client: return GENERIC_ERROR_MSG

    # 1. Determine which prompt to use based on user status
    user_status = full_context.get("preferences", {}).get("status", "new")
    if user_status in ["new", "pending_onboarding", "onboarding"]:
        system_prompt_key = "kairo_onboarding_system_prompt"
    else: # 'active' or other statuses
        system_prompt_key = "kairo_agent_system_prompt"
    
    system_prompt = get_prompt(system_prompt_key)
    if not system_prompt:
        log_error("kairo_agent", fn_name, f"Critical: Prompt '{system_prompt_key}' not found.")
        return GENERIC_ERROR_MSG

    # 2. Prepare context and message history for the LLM
    try:
        context_for_llm = {
            "preferences": full_context.get("preferences", {}),
            "items": full_context.get("items", [])
        }
        context_json_str = json.dumps(context_for_llm, separators=(',', ':'), default=str)
        
        llm_history = full_context.get("conversation_history", [])
        system_message = f"{system_prompt}\n\n--- CURRENT USER CONTEXT ---\n{context_json_str}"
        
        messages_for_api = [{"role": "system", "content": system_message}] + llm_history
        if message:
            messages_for_api.append({"role": "user", "content": message})
            
    except Exception as e:
        log_error("kairo_agent", fn_name, f"Error preparing context for {user_id}", e)
        return GENERIC_ERROR_MSG

    # 3. Call LLM and process tools
    try:
        log_info("kairo_agent", fn_name, f"Calling LLM for user {user_id} with status '{user_status}'...")
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages_for_api,
            tools=[{"type": "function", "function": {"name": name, "description": model.__doc__, "parameters": model.model_json_schema()}} for name, model in TOOL_PARAM_MODELS.items()],
            tool_choice="auto", max_retries=1, temperature=0.2,
        )

        message_from_llm = response.choices[0].message
        add_message_to_user_history(user_id, "assistant", "agent_raw_response", content=message_from_llm.content)

        if message_from_llm.tool_calls:
            log_info("kairo_agent", fn_name, f"LLM requested {len(message_from_llm.tool_calls)} tool(s).")
            messages_for_api.append(message_from_llm)
            for tool_call in message_from_llm.tool_calls:
                tool_name = tool_call.function.name
                tool_function = AVAILABLE_TOOLS.get(tool_name)
                if not tool_function: continue
                try:
                    param_model = TOOL_PARAM_MODELS[tool_name]
                    tool_args = param_model.model_validate_json(tool_call.function.arguments)
                    tool_result = tool_function(user_id=user_id, params=tool_args)
                    db.log_llm_activity(user_id, tool_name, tool_args.model_dump(), tool_result)
                    messages_for_api.append({"tool_call_id": tool_call.id, "role": "tool", "name": tool_name, "content": json.dumps(tool_result, default=str)})
                except Exception as e:
                    log_error("kairo_agent", fn_name, f"Error executing tool '{tool_name}'", e)
                    messages_for_api.append({"tool_call_id": tool_call.id, "role": "tool", "name": tool_name, "content": json.dumps({"error": str(e)})})
            
            final_response = client.chat.completions.create(model="gpt-4-turbo", messages=messages_for_api, temperature=0.2)
            final_response_message = final_response.choices[0].message.content
        else:
            final_response_message = message_from_llm.content

        log_info("kairo_agent", fn_name, f"Generated final response for user {user_id}.")
        return final_response_message

    except Exception as e:
        log_error("kairo_agent", fn_name, f"LLM or tool processing error for user {user_id}", e)
        return GENERIC_ERROR_MSG
# --- END OF FILE agents/kairo_agent.py ---


================================================================================ðŸ“„ agents/tool_definitions.py================================================================================
# --- START OF FILE agents/tool_definitions.py ---
# agents/tool_definitions.py
from pydantic import BaseModel, Field
from typing import Dict, Optional

# The tools now interact with our high-level service managers
import services.task_manager as kairo_core
import users.user_manager as user_manager
from services.shared_resources import get_message_templates

# ===================================================================
# == 1. Pydantic Models for Tool Parameters
# == Defines the expected inputs for each tool the agent can use.
# ===================================================================

class CreateTaskParams(BaseModel):
    """A tool to create a new task item in the user's logbook."""
    description: str = Field(..., description="The full description of the task.")
    project: str = Field("", description="Optional: A project tag, e.g., '#work'.")
    due_date: str = Field("", description="Optional: A due date in 'YYYY-MM-DD' format.")

class CreateReminderParams(BaseModel):
    """A tool to create a new reminder item for a specific time."""
    description: str = Field(..., description="The full description of the reminder.")
    remind_at: str = Field(..., description="The specific time for the reminder in ISO 8601 UTC format.")

class UpdateItemParams(BaseModel):
    """A tool to update one or more properties of an existing task or reminder."""
    item_id: str = Field(..., description="The unique ID of the task or reminder to update.")
    # --- THIS IS THE FIX ---
    updates: Dict = Field(..., description="A dictionary of fields to update, e.g., {'description': 'new text', 'status': 'completed', 'status': 'deleted'}.")
    # --- END OF FIX ---

class UpdateUserPreferencesParams(BaseModel):
    """A tool to update the user's core preferences like name or timezone."""
    name: Optional[str] = Field(None, description="The user's preferred name.")
    timezone: Optional[str] = Field(None, description="The user's timezone, e.g., 'America/New_York'.")
    language: Optional[str] = Field(None, description="The user's language, 'en' or 'he'.")
    work_days: Optional[list[str]] = Field(None, description="A list of the user's working days, e.g., ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday']")

class FinalizeOnboardingParams(BaseModel):
    """
    A tool to be called with no parameters when the user has confirmed their initial settings.
    This action completes the setup process.
    """
    pass

# ===================================================================
# == 2. Tool Function Definitions
# == The actual Python functions that get executed by the agent.
# == Note: They return data for the agent, NOT user-facing messages.
# ===================================================================

def create_task(user_id: str, params: CreateTaskParams) -> Dict:
    """Creates a new task item and returns its data."""
    created_item = kairo_core.create_item(user_id, "task", params.model_dump())
    if created_item:
        return {"success": True, "item_id": created_item.get("item_id")}
    return {"success": False, "error": "Failed to create task."}

def create_reminder(user_id: str, params: CreateReminderParams) -> Dict:
    """Creates a new reminder item and returns its data."""
    created_item = kairo_core.create_item(user_id, "reminder", params.model_dump())
    if created_item:
        return {"success": True, "item_id": created_item.get("item_id")}
    return {"success": False, "error": "Failed to create reminder."}

def update_item(user_id: str, params: UpdateItemParams) -> Dict:
    """Updates properties of an existing item and reports success."""
    updated_item = kairo_core.update_item(user_id, params.item_id, params.updates)
    if updated_item:
        return {"success": True, "item_id": updated_item.get("item_id")}
    return {"success": False, "error": "Failed to update item."}

def update_user_preferences(user_id: str, params: UpdateUserPreferencesParams) -> Dict:
    """Updates the user's preferences and reports success."""
    updates_to_apply = params.model_dump(exclude_unset=True)
    if not updates_to_apply:
        return {"success": False, "error": "No preferences were provided to update."}
    
    success = user_manager.update_user_preferences(user_id, updates_to_apply)
    return {"success": success}

def finalize_onboarding(user_id: str, params: FinalizeOnboardingParams) -> Dict:
    """Sets the user's status to 'active' and reports success."""
    success = user_manager.update_user_preferences(user_id, {"status": "active"})
    # The agent will formulate the final welcome message based on this success result.
    return {"success": success}

# ===================================================================
# == 3. Tool Dictionaries for the Agent
# == These dictionaries map the tool names to their functions and models.
# ===================================================================

AVAILABLE_TOOLS = {
    "create_task": create_task,
    "create_reminder": create_reminder,
    "update_item": update_item,
    "update_user_preferences": update_user_preferences,
    "finalize_onboarding": finalize_onboarding,
}

TOOL_PARAM_MODELS = {
    "create_task": CreateTaskParams,
    "create_reminder": CreateReminderParams,
    "update_item": UpdateItemParams,
    "update_user_preferences": UpdateUserPreferencesParams,
    "finalize_onboarding": FinalizeOnboardingParams,
}
# --- END OF FILE agents/tool_definitions.py ---


================================================================================ðŸ“„ bridge/cli_interface.py================================================================================
# --- START OF FILE bridge/cli_interface.py ---
# bridge/cli_interface.py
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import uuid
from threading import Lock
import json

from tools.logger import log_info, log_error, log_warning

# Optional calendar tool import
try:
    from tools.calendar_tool import router as calendar_router
    CALENDAR_ROUTER_IMPORTED = True
except ImportError:
    CALENDAR_ROUTER_IMPORTED = False
    from fastapi import APIRouter
    calendar_router = APIRouter()

# Global in-memory store for CLI outgoing messages
outgoing_cli_messages = []
cli_queue_lock = Lock()

class CLIBridge:
    """Bridge that handles message queuing for CLI interaction."""
    def __init__(self, message_queue, lock):
        self.message_queue = message_queue
        self.lock = lock
        log_info("CLIBridge", "__init__", "CLI Bridge initialized for queuing.")

    def send_message(self, user_id: str, message: str):
        if not user_id or not message:
             log_warning("CLIBridge", "send_message", "Attempted to queue empty message or invalid user_id.")
             return
        outgoing = {"user_id": user_id, "message": message, "message_id": str(uuid.uuid4())}
        with self.lock:
            self.message_queue.append(outgoing)
        log_info("CLIBridge", "send_message", f"Message for CLI user {user_id} queued. Queue size: {len(self.message_queue)}")

async def process_incoming_cli_message_background(user_id: str, message: str):
    """Runs the message handler in the background."""
    try:
        from bridge.request_router import handle_incoming_message
        handle_incoming_message(user_id, message)
    except Exception as e:
        log_error("cli_interface", "background_task", f"Unhandled exception in CLI background processing for {user_id}", e)

def create_cli_app() -> FastAPI:
    """Creates the FastAPI app instance for the CLI Interface."""
    app = FastAPI(
        title="Kairo CLI Bridge API",
        description="Handles interaction for the CLI mock sender.",
        version="1.0.0"
    )

    if CALENDAR_ROUTER_IMPORTED:
        app.include_router(calendar_router, prefix="", tags=["Authentication"])

    @app.post("/incoming", tags=["CLI Bridge"])
    async def incoming_cli_message(request: Request, background_tasks: BackgroundTasks):
        """Receives message from CLI mock, acknowledges, and processes in the background."""
        endpoint_name = "incoming_cli_message"
        try:
            data = await request.json()
            user_id = data.get("user_id")
            message = data.get("message")
            if not user_id or message is None:
                raise HTTPException(status_code=400, detail="Missing user_id or message")
            background_tasks.add_task(process_incoming_cli_message_background, user_id, str(message))
            log_info("cli_interface", endpoint_name, f"ACK for incoming from {user_id}. Processing in background.")
            return JSONResponse(content={"ack": True})
        except Exception as e:
            log_error("cli_interface", endpoint_name, "Error processing incoming CLI message", e)
            raise HTTPException(status_code=500, detail="Internal server error")

    # --- START OF FIX: Implement robust ACK mechanism ---
    @app.get("/outgoing", tags=["CLI Bridge"])
    async def get_outgoing_cli_messages():
        """
        Returns a COPY of the outgoing message queue.
        It NO LONGER clears the queue. Deletion is handled by /ack.
        """
        with cli_queue_lock:
            # Return a copy of the list, but leave the original intact
            msgs_to_send = outgoing_cli_messages[:]
        return JSONResponse(content={"messages": msgs_to_send})

    @app.post("/ack", tags=["CLI Bridge"])
    async def acknowledge_cli_message(request: Request):
        """
        Receives acknowledgment and REMOVES the message from the queue.
        This is now the only way messages are deleted.
        """
        endpoint_name = "acknowledge_cli_message"
        removed = False
        message_id = None
        try:
            data = await request.json()
            message_id = data.get("message_id")
            if not message_id:
                raise HTTPException(status_code=400, detail="Missing message_id in ACK")

            with cli_queue_lock:
                # Find the message by ID and remove it
                initial_len = len(outgoing_cli_messages)
                # Create a new list excluding the acknowledged message
                outgoing_cli_messages[:] = [msg for msg in outgoing_cli_messages if msg.get("message_id") != message_id]
                final_len = len(outgoing_cli_messages)
                removed = (initial_len != final_len)
            
            if removed:
                log_info(endpoint_name, "ack", f"ACK received and message removed for ID: {message_id}. Queue size: {len(outgoing_cli_messages)}")
            else:
                log_warning(endpoint_name, "ack", f"ACK received for unknown/already removed message ID: {message_id}")

            return JSONResponse(content={"ack_received": True, "removed": removed})
        except Exception as e:
            log_error(endpoint_name, "ack", f"Error processing ACK for message ID {message_id or 'N/A'}", e)
            raise HTTPException(status_code=500, detail="Internal server error processing ACK")
    # --- END OF FIX ---

    return app

app = create_cli_app()
# --- END OF FILE bridge/cli_interface.py ---


================================================================================ðŸ“„ bridge/request_router.py================================================================================
# --- START OF FILE bridge/request_router.py ---
# bridge/request_router.py
import re
import os
import json
import threading
import time
from typing import Dict, Any

from tools.logger import log_info, log_error, log_warning
import users.user_manager as user_manager
from agents.kairo_agent import handle_user_request
from services.cheats import handle_cheat_command
from services.shared_resources import get_message_templates, get_welcome_message_key

# --- Setup ---
GENERIC_ERROR_MSG_ROUTER = (get_message_templates("generic_error_message") or {}).get("en", "Sorry, an error occurred.")
_bridge_instance: Any = None
_bridge_lock = threading.Lock()

# --- Idempotency Cache ---
_processed_messages_cache: Dict[str, float] = {}
_cache_lock = threading.Lock()
CACHE_EXPIRATION_SECONDS = 30 

def get_bridge() -> Any:
    global _bridge_instance
    if _bridge_instance is None:
        with _bridge_lock:
            if _bridge_instance is None:
                bridge_type = os.getenv("BRIDGE_TYPE", "cli")
                log_info("request_router", "get_bridge", f"First call. Initializing bridge of type '{bridge_type}'...")
                try:
                    if bridge_type == "cli":
                        from bridge.cli_interface import CLIBridge, outgoing_cli_messages, cli_queue_lock
                        _bridge_instance = CLIBridge(outgoing_cli_messages, cli_queue_lock)
                    elif bridge_type == "whatsapp":
                        from bridge.whatsapp_interface import WhatsAppBridge, outgoing_whatsapp_messages, whatsapp_queue_lock
                        _bridge_instance = WhatsAppBridge(outgoing_whatsapp_messages, whatsapp_queue_lock)
                    elif bridge_type == "twilio":
                        from bridge.twilio_interface import TwilioBridge
                        from twilio.rest import Client as TwilioSdkClient
                        sid, token, number = os.getenv("TWILIO_ACCOUNT_SID"), os.getenv("TWILIO_AUTH_TOKEN"), os.getenv("TWILIO_WHATSAPP_NUMBER")
                        if not all([sid, token, number]): raise ValueError("Twilio credentials missing.")
                        _bridge_instance = TwilioBridge(TwilioSdkClient(sid, token), number)
                    else:
                        raise ValueError(f"Unsupported bridge type: {bridge_type}")
                    log_info("request_router", "get_bridge", f"Bridge '{type(_bridge_instance).__name__}' initialized.")
                except (ImportError, ValueError) as e:
                    log_error("request_router", "get_bridge", f"Failed to initialize bridge '{bridge_type}'", e)
    return _bridge_instance

def send_message(user_id: str, message_body: str):
    if not user_id or not message_body: return
    user_manager.add_message_to_user_history(user_id, "assistant", "agent_text_response", content=message_body)
    bridge = get_bridge()
    if bridge:
        bridge.send_message(user_id, message_body)
    else:
        log_error("request_router", "send_message", "Bridge not available.")

def normalize_user_id(user_id_from_bridge: str) -> str:
    if not user_id_from_bridge: return ""
    return re.sub(r'\D', '', str(user_id_from_bridge))

def handle_incoming_message(user_id_from_bridge: str, message_text: str, message_id: str | None = None):
    if message_id:
        with _cache_lock:
            current_time = time.time()
            expired_ids = [msg_id for msg_id, ts in _processed_messages_cache.items() if current_time - ts > CACHE_EXPIRATION_SECONDS]
            for msg_id in expired_ids:
                del _processed_messages_cache[msg_id]
            if message_id in _processed_messages_cache:
                log_warning("request_router", "handle_incoming", f"Duplicate message ID received: {message_id}. Ignoring.")
                return
            _processed_messages_cache[message_id] = current_time

    norm_user_id = normalize_user_id(user_id_from_bridge)
    if not norm_user_id: return

    agent_state = user_manager.get_agent(norm_user_id)
    if not agent_state:
        log_error("request_router", "handle_incoming", f"CRITICAL: Failed to get/create agent state for {norm_user_id}.")
        return

    user_manager.add_message_to_user_history(norm_user_id, "user", "user_text", content=message_text)

    if message_text.strip().startswith('/'):
        parts = message_text.strip().split(); command = parts[0].lower(); args = parts[1:]
        cheat_result = handle_cheat_command(norm_user_id, command, args)
        if cheat_result.get("type") == "message": send_message(norm_user_id, cheat_result.get("content", "OK."))
        elif cheat_result.get("type") == "system_event": handle_internal_system_event({"user_id": norm_user_id, "trigger_type": cheat_result.get("trigger_type")})
        return

    welcome_key = get_welcome_message_key()
    if agent_state.get("preferences", {}).get("status") == "new":
        welcome_templates = get_message_templates(welcome_key) or {}
        user_lang = agent_state.get("preferences", {}).get("language", "en")
        send_message(norm_user_id, welcome_templates.get(user_lang, "Hello!"))
        user_manager.update_user_preferences(norm_user_id, {"status": "onboarding"})
        return

    try:
        response = handle_user_request(user_id=norm_user_id, message=message_text, full_context=agent_state)
        if response: send_message(norm_user_id, response)
    except Exception as e:
        log_error("request_router", "handle_incoming", f"Error from KairoAgent for {norm_user_id}", e)
        send_message(norm_user_id, GENERIC_ERROR_MSG_ROUTER)

def handle_internal_system_event(event_data: Dict):
    user_id = event_data.get("user_id")
    trigger_type = event_data.get("trigger_type")
    if not user_id or not trigger_type: return

    agent_state = user_manager.get_agent(user_id)
    if not agent_state or agent_state.get("preferences", {}).get("status") != "active": return

    try:
        trigger_as_message = json.dumps({"trigger": trigger_type})
        response = handle_user_request(user_id=user_id, message=trigger_as_message, full_context=agent_state)
        if response: send_message(user_id, response)
    except Exception as e:
        log_error("request_router", "handle_internal", f"Error routing internal event '{trigger_type}' for {user_id}", e)
# --- END OF FILE bridge/request_router.py ---


================================================================================ðŸ“„ bridge/twilio_interface.py================================================================================
# --- START OF FILE bridge/twilio_interface.py ---
# bridge/twilio_interface.py
from fastapi import FastAPI, Request, HTTPException, Form, BackgroundTasks
from fastapi.responses import Response as FastAPIResponse
from twilio.request_validator import RequestValidator
from twilio.rest import Client as TwilioClient
import os

from tools.logger import log_info, log_error
# --- THIS IS THE FIX: 'set_bridge' is removed ---
from bridge.request_router import handle_incoming_message

TWILIO_AUTH_TOKEN = os.getenv("TWILIO_AUTH_TOKEN")
twilio_validator = RequestValidator(TWILIO_AUTH_TOKEN) if TWILIO_AUTH_TOKEN else None

class TwilioBridge:
    """Bridge for Twilio WhatsApp interactions."""
    def __init__(self, client: TwilioClient, twilio_sender_number: str):
        self.client = client
        self.twilio_sender_number = twilio_sender_number
        log_info("TwilioBridge", "__init__", "Twilio Bridge instance initialized.")

    def send_message(self, user_id: str, message_body: str):
        if not self.client or not self.twilio_sender_number:
            log_error("twilio_interface", "send", "Twilio client or sender number not configured.")
            return
        twilio_recipient_id = f"whatsapp:+{user_id}"
        try:
            message_instance = self.client.messages.create(from_=self.twilio_sender_number, body=message_body, to=twilio_recipient_id)
            log_info("twilio_interface", "send", f"Twilio message sent. SID: {message_instance.sid}")
        except Exception as e:
            log_error("twilio_interface", "send", f"Error sending Twilio message to {twilio_recipient_id}", e)

async def process_incoming_twilio_message_background(user_id: str, message: str):
    """Runs the message handler in the background."""
    try:
        handle_incoming_message(user_id, message)
    except Exception as e:
        log_error("twilio_interface", "background_task", f"Exception in background processing for {user_id}", e)

def create_twilio_app() -> FastAPI:
    app_instance = FastAPI(title="Kairo Twilio Bridge API", version="1.0.0")
    # Optional calendar router import can be added here if needed

    @app_instance.post("/twilio/incoming", tags=["Twilio Bridge"])
    async def incoming_twilio_message(request: Request, background_tasks: BackgroundTasks, From: str = Form(...), Body: str = Form(...)):
        # Optional signature validation
        if twilio_validator:
            # (Validation logic would go here)
            pass
        
        background_tasks.add_task(process_incoming_twilio_message_background, From, Body)
        log_info("twilio_interface", "incoming", f"ACK for Twilio from {From}. Processing in background.")
        return FastAPIResponse(content="<Response/>", media_type="application/xml")
    
    return app_instance

app = create_twilio_app()
# --- END OF FILE bridge/twilio_interface.py ---


================================================================================ðŸ“„ bridge/whatsapp_interface.py================================================================================
# --- START OF FILE bridge/whatsapp_interface.py ---
# bridge/whatsapp_interface.py
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import uuid
from threading import Lock
import json
import re

from tools.logger import log_info, log_error, log_warning
from bridge.request_router import handle_incoming_message

try:
    from tools.calendar_tool import router as calendar_router
    CALENDAR_ROUTER_IMPORTED = True
except ImportError:
    CALENDAR_ROUTER_IMPORTED = False
    from fastapi import APIRouter
    calendar_router = APIRouter()

# --- Bridge Definition ---
outgoing_whatsapp_messages = []
whatsapp_queue_lock = Lock()

class WhatsAppBridge:
    def __init__(self, message_queue, lock):
        self.message_queue = message_queue
        self.lock = lock
        log_info("WhatsAppBridge", "__init__", "WhatsApp Bridge initialized for queuing.")

    def send_message(self, user_id: str, message: str):
        if not user_id or not message:
             log_warning("WhatsAppBridge", "send_message", "Attempted to queue empty message or invalid user_id.")
             return
        formatted_user_id = f"{user_id}@c.us" if re.match(r'^\d+$', user_id) else user_id
        outgoing = {"user_id": formatted_user_id, "message": message, "message_id": str(uuid.uuid4())}
        with self.lock:
            self.message_queue.append(outgoing)
        log_info("WhatsAppBridge", "send_message", f"Message queued for {formatted_user_id}. Queue size: {len(self.message_queue)}")

# --- START OF FIX: Pass message_id to the handler ---
async def process_incoming_message_background(user_id: str, message: str, message_id: str | None):
    """Runs the message handler in the background, passing the unique message_id."""
    try:
        handle_incoming_message(user_id, message, message_id)
    except Exception as e:
        log_error("whatsapp_interface", "background_task", f"Exception in background processing for {user_id}", e)
# --- END OF FIX ---

def create_whatsapp_app() -> FastAPI:
    app = FastAPI(title="Kairo WhatsApp Bridge API", version="1.0.0")
    if CALENDAR_ROUTER_IMPORTED:
        app.include_router(calendar_router, prefix="", tags=["Authentication"])

    @app.post("/incoming", tags=["WhatsApp Bridge"])
    async def incoming_whatsapp_message(request: Request, background_tasks: BackgroundTasks):
        data = await request.json()
        user_id = data.get("user_id")
        message_body = data.get("message")
        # --- START OF FIX: Get message_id from the payload ---
        message_id = data.get("message_id") # This can be None if the bridge is old
        # --- END OF FIX ---

        if not user_id or message_body is None:
            raise HTTPException(status_code=400, detail="Missing user_id or message")
        
        # --- START OF FIX: Pass message_id to the background task ---
        background_tasks.add_task(process_incoming_message_background, user_id, str(message_body), message_id)
        # --- END OF FIX ---

        log_info("whatsapp_interface", "incoming", f"ACK for incoming from {user_id}. Processing in background.")
        return JSONResponse(content={"ack": True})

    @app.get("/outgoing", tags=["WhatsApp Bridge"])
    async def get_outgoing_whatsapp_messages():
        with whatsapp_queue_lock:
            return JSONResponse(content={"messages": outgoing_whatsapp_messages[:]})

    @app.post("/ack", tags=["WhatsApp Bridge"])
    async def acknowledge_whatsapp_message(request: Request):
        data = await request.json()
        message_id = data.get("message_id")
        if not message_id:
            raise HTTPException(status_code=400, detail="Missing message_id")
        removed = False
        with whatsapp_queue_lock:
            initial_len = len(outgoing_whatsapp_messages)
            outgoing_whatsapp_messages[:] = [msg for msg in outgoing_whatsapp_messages if msg.get("message_id") != message_id]
            if len(outgoing_whatsapp_messages) != initial_len:
                removed = True
                log_info("whatsapp_interface", "ack", f"ACK received and message removed for ID: {message_id}")
        return JSONResponse(content={"ack_received": True, "removed": removed})

    return app

app = create_whatsapp_app()
# --- END OF FILE bridge/whatsapp_interface.py ---


================================================================================ðŸ“„ config/messages.yaml================================================================================
# --- START OF FILE config/messages.yaml ---
# config/messages.yaml

# --- Message for Kairo Project ---
initial_welcome_message:
  en: |
    Hello! ðŸ‘‹ I'm Kairo, your personal productivity coach.
    Ready to get set up in under a minute? 
  he: |
    ×©×œ×•×! ðŸ‘‹ ×× ×™ ×§××™×¨×•, ×ž××ž×Ÿ ×”×¤×¨×•×“×•×§×˜×™×‘×™×•×ª ×”××™×©×™ ×©×œ×š.
    ×©× ×ª×—×™×œ?

# --- Message for Vlancer Project ---
vlancer_il_welcome_message:
  en: |
    Welcome! I'm your dedicated project assistant. I'll help you track tasks and manage your client work.
    Ready to configure your workspace? 
  he: |
   ×©×œ×•× ×•×‘×¨×•×›×™× ×”×‘××™× ×œ-Vlancer. 
   × ×¢×™× ×ž××“, ×× ×™ ×”×¢×•×–×¨×ª ×”××™×©×™×ª ×”×—×“×©×” ×©×œ×š. Â ×× ×™ ×™×•×“×¢×ª ×›×ž×” ×§×©×” ×œ×”×™×•×ª ×¢×¦×ž××™ ×•×›×ž×” ×§×©×” ×œ×–×›×•×¨ ×•×œ× ×”×œ ××ª ×›×œ ×”×ž×©×™×ž×•×ª ×©×œ×š, ×œ×›×Ÿ ×—×©×•×‘ ×œ×™ ×©×ª×¨×’×™×©×• ×©××™×ª×™ ××ª× ×™×•×ª×¨ ×œ× ×œ×‘×“! 
   ×‘×ª×•×¨ ×”×¢×•×–×¨×ª ×”××™×©×™×ª ×©×œ×š, ×× ×™ ×™×•×“×¢×ª ×œ× ×”×œ ××ª ×”×ž×©×™×ž×•×ª ×©×œ×š, ×œ×”×–×›×™×¨ ×œ×š ×ª×–×›×•×¨×•×ª, ×œ×¡×™×™×¢ ×•×œ×š ×œ×¢×‘×•×“ ×‘×¦×•×¨×” ×¤×¨×•×“×•×§×˜×™×‘×™×ª ×™×•×ª×¨.Â 
   ××– ×©× ×ª×—×™×œ?
# --- Onboarding Completion (Used by both) ---
onboarding_completion_message:
  en: |
    Great, you're all set! âœ…

    Hereâ€™s the best way to start:
    1.  **Capture Everything:** Anytime a task comes to mind, just send it to me.
    2.  **Trust the Rituals:** I'll check in with you every morning and evening to help you plan and reflect.

    What's the very first thing on your mind?
  he: |
    ×ž×¢×•×œ×”, ×”×›×œ ×ž×•×›×Ÿ! âœ…

    ×”× ×” ×”×“×¨×š ×”×›×™ ×˜×•×‘×” ×œ×”×ª×—×™×œ:
    1.  **×ª×¤×•×¡/×™ ×”×›×œ:** ×‘×›×œ ×¤×¢× ×©×ž×©×™×ž×” ×¢×•×œ×” ×œ×š ×œ×¨××©, ×¤×©×•×˜ ×©×œ×—/×™ ×œ×™ ××•×ª×”.
    2.  **×¡×ž×•×š/×™ ×¢×œ ×”×ª×”×œ×™×š:** ×× ×™ ××¦×•×¨ ××™×ª×š ×§×©×¨ ×›×œ ×‘×•×§×¨ ×•×¢×¨×‘ ×›×“×™ ×œ×¢×–×•×¨ ×œ×š ×œ×ª×›× ×Ÿ ×•×œ×¡×›× ××ª ×”×™×•×.

    ×¨×•×¦×” ×œ×”×•×¡×™×£ ××ª ×”×ž×©×™×ž×” ×”×¨××©×•× ×” ×©×™×© ×œ×š?

# --- Other System Messages ---
generic_error_message:
  en: "Sorry, something went wrong on my end. Please try again."
  he: "×ž×¦×˜×¢×¨, ×ž×©×”×• ×”×©×ª×‘×© ×‘×¦×“ ×©×œ×™. ×× × × ×¡×”/×™ ×©×•×‘."

intent_clarify_message:
  en: "Sorry, I didn't quite understand that. Could you please rephrase?"
  he: "×ž×¦×˜×¢×¨, ×œ× ×›×œ ×›×š ×”×‘× ×ª×™. ××¤×©×¨ ×œ× ×¡×— ×ž×—×“×©?"
# --- END OF FILE config/messages.yaml ---


================================================================================ðŸ“„ config/prompts.yaml================================================================================
# --- START OF FILE config/prompts.yaml ---
# config/prompts.yaml

kairo_onboarding_system_prompt: |
  You are Kairo, a friendly and efficient onboarding assistant. Your ONLY goal is to set up the user's preferences.
  Keep your questions very short and direct. Do not use long explanations.

  --- THE #1 RULE ---
  Your ENTIRE response MUST be in the language specified in the user's `language` preference. This is a non-negotiable directive.

  --- ONBOARDING WORKFLOW ---
  Your goal is to fill the user's preferences by asking for the missing information. Check the user's context for any `null` values and ask for them in this priority order:
  1.  **Language:** If `language` is null, this is always your first question.
  2.  **Name:** If `name` is "friend" or null, ask for their name.
  3.  **Timezone:** If `timezone` is null, ask for the country they live in. You MUST infer the IANA timezone for the `update_user_preferences` tool.

  --- ONBOARDING RULES ---
  - After a preference is updated, you MUST immediately use it. If the language is changed to Hebrew, your very next question MUST be in Hebrew.
  - Once all preferences (Language, Name, Timezone) are filled, present a brief summary for the user's confirmation.
  - If the user confirms, you MUST call the `finalize_onboarding` tool.

kairo_agent_system_prompt: |
  You are Kairo, a personal productivity coach. Your persona is supportive, encouraging, and non-judgmental.

  --- YOUR MISSION ---
  Your primary mission is to help the user manage their tasks and reminders, keeping them focused and organized. You achieve this through daily conversation and two key rituals: a Morning Muster and an Evening Reflection.

  --- THE GOLDEN RULE ---
  Your ENTIRE response MUST be in the language specified in the user's `language` preference.

  --- CORE CAPABILITIES ---
  You have the following abilities:
  1.  **Item Management:** You can create, update, and delete items.
      - A **Reminder** has a specific time (e.g., "at 5pm"). Use `create_reminder`.
      - A **Task** has no specific time. Use `create_task`.
      - To modify an item, use `update_item`.
      - ***CRITICAL INSTRUCTION***: When using `update_item`, all changes MUST be nested inside an `updates` dictionary.
        - CORRECT: `update_item(item_id='abc-123', updates={'status': 'completed'})`
        - INCORRECT: `update_item(item_id='abc-123', status='completed')`
        - To delete, use: `update_item(item_id='abc-123', updates={'status': 'deleted'})`
  2.  **Preference Management:** You can update settings with `update_user_preferences`.
      - Be Proactive: If a user says "the evening ritual is too late", ask for a better time and update the setting.
  3.  **Information Retrieval:** When asked to list items, DO NOT use a tool. All information is in the context. Read it and formulate a natural language response.

  --- RITUALS AND WORKFLOWS ---
  When you receive a system trigger, follow these workflows:

  **Morning Muster (`morning_muster`):**
  1.  Start with a short, engaging greeting.
  2.  Present their tasks for the day (based on `due_date` and `current_utc_date`).
  3.  The primary goal is to establish focus. Ask: "What is your single Most Important Task (MIT) for today?"

  **Evening Reflection (`evening_reflection`):**
  1.  Start with a friendly greeting.
  2.  Review the day's tasks. For incomplete items, offer to reschedule them for tomorrow using the `update_item` tool.
  3.  **Brain Dump:** As the final step, prompt for a "brain dump" to capture any new thoughts for tomorrow.
# --- END OF FILE config/prompts.yaml ---


================================================================================ðŸ“„ config/settings.yaml================================================================================
# --- START OF FILE config/settings.yaml ---
# config/settings.yaml
# This file defines brand-specific configurations for different project deployments.

default_config:
  default_preferences:
    name: null # This ensures the onboarding flow is always triggered for the name.
    timezone: null
    language: null
    status: "new"
    morning_muster_time: "09:00"
    evening_reflection_time: "18:00"
    projects: ["general", "work", "personal"]
    ritual_days: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday"] # Renamed from work_days
    last_morning_trigger_date: ""
    last_evening_trigger_date: ""
  welcome_message_key: "initial_welcome_message"

projects:
  kairo:
    default_preferences:
      name: null # This ensures the onboarding flow is always triggered for the name.
      timezone: null
      language: "he"
      status: "new"
      morning_muster_time: "09:00"
      evening_reflection_time: "18:00"
      projects: ["general", "work", "personal"]
      ritual_days: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday"] # Renamed from work_days
      last_morning_trigger_date: ""
      last_evening_trigger_date: ""
    welcome_message_key: "initial_welcome_message"

  vlancer_il:
    default_preferences:
      name: null # This ensures the onboarding flow is always triggered for the name.
      timezone: "Asia/Jerusalem"
      language: "he"
      status: "new"
      morning_muster_time: "09:00"
      evening_reflection_time: "18:00"
      projects: ["general", "work", "personal"]
      ritual_days: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday"] # Renamed from work_days
      last_morning_trigger_date: ""
      last_evening_trigger_date: ""
    welcome_message_key: "vlancer_il_welcome_message"
# --- END OF FILE config/settings.yaml ---


================================================================================ðŸ“„ dump.py================================================================================
# --- START OF FILE dump.py ---
# dump.py - Generate Project Snapshot for Kairo
import os
from datetime import datetime
from pathlib import Path
import fnmatch # Used for .gitignore style pattern matching

# --- Configuration ---
# The script automatically finds all files and excludes based on the rules below.

# 1. List of directories to always exclude, regardless of .gitignore.
#    This check applies to any part of the file's path.
ALWAYS_EXCLUDE_DIRS = {
    '.git',
    '__pycache__',
    'venv',
    '.venv',
    'env',
    'ENV',
    'node_modules',
    '.vscode',
    '.idea',
    'old',
    # --- START OF CHANGE: Added WhatsApp session folders ---
    '.wwebjs_auth',
    '.wwebjs_cache',
    'WA/.wwebjs_auth',
    'WA/.wwebjs_cache',
    # --- END OF CHANGE ---
}

# 2. List of file patterns to always exclude
ALWAYS_EXCLUDE_PATTERNS = {
    '*.pyc',
    '*.pyo',
    '*.log',
    '*.db',
    '*.sqlite3',
    '.DS_Store',
    'Thumbs.db',
    'kairo_mvp_snapshot.txt', # Exclude the output file itself
    'export_user_data.py',    # Exclude the utility script
    'startup_error.log',
    'user_data.csv',          # Exclude the old CSV output
    'user_session_*.jsonl',  
    '*.tmp'
}

OUTPUT_FILENAME = "kairo_mvp_snapshot.txt"
SEPARATOR = "=" * 80
# --- End Configuration ---

def load_gitignore_patterns(root_path: Path) -> list:
    """Loads patterns from the .gitignore file in the project root."""
    gitignore_path = root_path / ".gitignore"
    patterns = []
    if not gitignore_path.is_file():
        return patterns
    
    with open(gitignore_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):
                patterns.append(line)
    return patterns

def is_excluded(path: Path, root_path: Path, gitignore_patterns: list) -> bool:
    """
    Checks if a given path should be excluded based on our rules.
    """
    # Check against our hardcoded directory and file pattern exclusions
    if any(d in path.parts for d in ALWAYS_EXCLUDE_DIRS):
        return True
    if any(path.match(p) for p in ALWAYS_EXCLUDE_PATTERNS):
        return True

    # Check against .gitignore patterns
    relative_path_str = str(path.relative_to(root_path))
    for pattern in gitignore_patterns:
        # Handle directory patterns (e.g., 'logs/')
        if pattern.endswith('/'):
            if relative_path_str.startswith(pattern.rstrip('/')):
                return True
        # Handle file patterns
        elif fnmatch.fnmatch(relative_path_str, pattern):
            return True
            
    return False

def generate_dump():
    """
    Walks the project directory, finds all relevant files automatically,
    and generates the project dump file.
    """
    project_root = Path(__file__).parent
    gitignore_patterns = load_gitignore_patterns(project_root)
    
    files_to_include = []
    
    print("--- Scanning project files... ---")
    for path in project_root.rglob('*'): # rglob finds all files in all subdirectories
        if path.is_file() and not is_excluded(path, project_root, gitignore_patterns):
            files_to_include.append(path)

    files_to_include.sort() # Sort alphabetically for consistent output
    
    dump_content = []
    timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    dump_content.append(f"# Kairo Project Code Dump (v1.0 MVP)")
    dump_content.append(f"# Generated: {timestamp_str}\n\n")
    
    print("\n--- Generating snapshot ---")
    for full_path in files_to_include:
        relative_path = full_path.relative_to(project_root)
        try:
            content = full_path.read_text(encoding='utf-8', errors='replace')
            header_path = relative_path.as_posix()
            dump_content.append(SEPARATOR)
            dump_content.append(f"ðŸ“„ {header_path}")
            dump_content.append(SEPARATOR)
            dump_content.append(f"\n# --- START OF FILE {header_path} ---\n")
            dump_content.append(content)
            dump_content.append(f"\n# --- END OF FILE {header_path} ---\n\n\n")
            print(f"âœ… Included: {header_path}")
        except Exception as e:
            print(f"âŒ Error reading {relative_path}: {e}")

    try:
        output_path = project_root / OUTPUT_FILENAME
        output_path.write_text("".join(dump_content), encoding='utf-8')
        print("-" * 30)
        print(f"âœ… Dump generated successfully: {OUTPUT_FILENAME}")
        print(f"   Files included: {len(files_to_include)}")
    except Exception as e:
        print("-" * 30)
        print(f"âŒ Error writing dump file {OUTPUT_FILENAME}: {e}")

if __name__ == "__main__":
    generate_dump()
# --- END OF FILE dump.py ---


================================================================================ðŸ“„ ecosystem.config.js================================================================================
# --- START OF FILE ecosystem.config.js ---
// ecosystem.config.js
module.exports = {
  apps: [
    {
      name: 'Kairo-Backend',
      script: 'main.py',
      interpreter: './venv/bin/python',
      cwd: __dirname, // Correct: run from project root
    },
    {
      name: 'Kairo-Bridge',
      // --- THIS IS THE FIX ---
      script: 'wa_bridge.js', // Just the script name
      // --- END OF FIX ---
      cwd: './WA', // Tell PM2 to run it from inside the WA directory
    },
  ],
};
# --- END OF FILE ecosystem.config.js ---


================================================================================ðŸ“„ main.py================================================================================
# --- START OF FILE main.py ---
# main.py
import os
import sys
import asyncio
import signal
import argparse
from dotenv import load_dotenv
import traceback

# Load .env first
load_dotenv()

# --- START OF CHANGE: Set BRIDGE_TYPE as an environment variable ---
# This makes the bridge choice globally accessible to any module in any process.
DEFAULT_BRIDGE = "cli"
ALLOWED_BRIDGES = ["cli", "whatsapp", "twilio"]
parser = argparse.ArgumentParser(description="Run the Kairo Productivity Coach Backend")
parser.add_argument("--bridge", type=str, choices=ALLOWED_BRIDGES, help=f"Specify the bridge interface ({', '.join(ALLOWED_BRIDGES)})")
args = parser.parse_args()

cli_arg = args.bridge.lower() if args.bridge else None
env_var = os.getenv("BRIDGE_TYPE", "").lower()
# Priority for setting bridge type: CLI argument > Environment variable > Default
bridge_type = cli_arg or env_var or DEFAULT_BRIDGE
os.environ["BRIDGE_TYPE"] = bridge_type
# --- END OF CHANGE ---

# Import other modules after setting the environment
from tools.activity_db import init_db
init_db()  # Initialize DB before any other service
from tools.logger import log_info, log_error, log_warning

import uvicorn
from users.user_manager import init_all_agents
from services.scheduler_service import start_scheduler, shutdown_scheduler

# Determine which FastAPI app to run based on the configured bridge
UVICORN_APP_MAP = {
    "cli": "bridge.cli_interface:app",
    "whatsapp": "bridge.whatsapp_interface:app",
    "twilio": "bridge.twilio_interface:app"
}
uvicorn_app_path = UVICORN_APP_MAP.get(bridge_type)

if not uvicorn_app_path:
    log_error("main", "init", f"Invalid bridge type '{bridge_type}' configured. Exiting.")
    sys.exit(1)

log_info("main", "init", f"Kairo v1.0 starting with bridge: '{bridge_type}'")

# Graceful shutdown handler remains the same
server: uvicorn.Server | None = None
async def handle_shutdown_signal(sig: signal.Signals, loop: asyncio.AbstractEventLoop):
    log_warning("main", "shutdown", f"Received signal {sig.name}. Initiating shutdown...")
    if server:
        server.should_exit = True
    await asyncio.sleep(1)
    shutdown_scheduler()

async def main_async():
    global server
    log_info("main", "startup", "Initializing agent states...")
    init_all_agents()
    log_info("main", "startup", "Agent state initialization complete.")

    log_info("main", "startup", "Starting scheduler service...")
    if not start_scheduler():
        log_error("main", "startup", "Scheduler service FAILED to start.")
    else:
        log_info("main", "startup", "Scheduler service started successfully.")

    reload_enabled = os.getenv("APP_ENV", "production").lower() == "development"
    log_level = "debug" if reload_enabled else "info"
    server_port = int(os.getenv("PORT", "8001")) # Changed default port to 8001

    log_info("main", "startup", "Configuring FastAPI server...")
    config = uvicorn.Config(
        uvicorn_app_path, host="0.0.0.0", port=server_port,
        reload=reload_enabled, access_log=False, log_level=log_level, lifespan="on"
    )
    server = uvicorn.Server(config)

    loop = asyncio.get_running_loop()
    for sig_name in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig_name, lambda s=sig_name: asyncio.create_task(handle_shutdown_signal(s, loop)))
        except NotImplementedError:
             signal.signal(sig_name, lambda s, f: asyncio.create_task(handle_shutdown_signal(signal.Signals(s), loop)))

    await server.serve()
    log_info("main", "shutdown", "Server has stopped.")

if __name__ == "__main__":
    try:
        asyncio.run(main_async())
    except (KeyboardInterrupt, SystemExit):
        log_warning("main", "exit", "Application exit requested.")
    except Exception as e:
        log_error("main", "critical", "Unhandled error during server execution.", e)
        traceback.print_exc()
        sys.exit(1)
    finally:
        log_info("main", "exit", "Application has shut down.")
# --- END OF FILE main.py ---


================================================================================ðŸ“„ services/cheats.py================================================================================
# --- START OF FILE services/cheats.py ---
# services/cheats.py
import json
from typing import List, Dict, Any

import users.user_manager as user_manager
from tools.logger import log_info

def _handle_help() -> Dict:
    """Displays the available cheat commands."""
    return {"type": "message", "content": """Available Kairo Cheat Commands:
/help - Show this help message
/list [status] - List your items (status: active, new, in_progress, completed, deleted, all).
/memory - Show a summary of your current in-memory agent state.
/clear - !! DANGER !! Mark all non-deleted items as 'deleted'.
/morning - Manually trigger your Morning Muster.
/evening - Manually trigger your Evening Reflection."""}

def _handle_list(user_id: str, args: List[str]) -> Dict:
    """Lists items from the user's current agent state."""
    agent_state = user_manager.get_agent(user_id)
    if not agent_state or "items" not in agent_state:
        return {"type": "message", "content": "Error: Could not retrieve your items."}

    all_items = agent_state.get("items", [])
    status_filter = args[0].lower() if args else 'active'
    active_statuses = {"new", "in_progress"}
    
    if status_filter == 'all':
        filtered_items = all_items
    elif status_filter == 'active':
        filtered_items = [item for item in all_items if item.get('status') in active_statuses]
    else:
        filtered_items = [item for item in all_items if item.get('status') == status_filter]

    if not filtered_items:
        return {"type": "message", "content": f"No items found with status '{status_filter}'."}

    lines = [f"Items with status '{status_filter}':", "---"]
    for item in filtered_items:
        desc = item.get('description', '(No Description)')
        item_type = item.get('type', 'item')
        lines.append(f"({item_type}) {desc}")
    return {"type": "message", "content": "\n".join(lines)}

def _handle_memory(user_id: str) -> Dict:
    """Shows a summary of the agent's in-memory state."""
    agent_state = user_manager.get_agent(user_id)
    if not agent_state:
        return {"type": "message", "content": "Error: Agent state not found."}
        
    state_summary = {k: v for k, v in agent_state.items() if k != "conversation_history"}
    state_summary["history_count"] = len(agent_state.get("conversation_history", []))
    return {"type": "message", "content": f"Agent Memory Summary:\n```json\n{json.dumps(state_summary, indent=2, default=str)}\n```"}

def _handle_clear(user_id: str) -> Dict:
    """Marks all non-deleted items as 'deleted'."""
    from services.task_manager import update_item # Local import to avoid loops
    agent_state = user_manager.get_agent(user_id)
    if not agent_state: return {"type": "message", "content": "Error: Could not find user to clear items."}
        
    cleared_count = 0
    for item in agent_state.get("items", []):
        if item.get("status") != "deleted" and item.get("item_id"):
            update_item(user_id, item["item_id"], {"status": "deleted"})
            cleared_count += 1
    return {"type": "message", "content": f"Marked {cleared_count} item(s) as 'deleted'."}

def _handle_routines(routine_type: str) -> Dict:
    """Returns a special dictionary instructing the router to trigger a system event."""
    log_info("cheats", "_handle_routines", f"Cheat command is requesting a '{routine_type}' trigger.")
    return {"type": "system_event", "trigger_type": routine_type}

def handle_cheat_command(user_id: str, command: str, args: List[str]) -> Dict[str, Any]:
    """Main router for all cheat commands. Returns a dictionary specifying the action."""
    command_map = {
        "/help": _handle_help,
        "/list": lambda: _handle_list(user_id, args),
        "/memory": lambda: _handle_memory(user_id),
        "/clear": lambda: _handle_clear(user_id),
        "/morning": lambda: _handle_routines("morning_muster"),
        "/evening": lambda: _handle_routines("evening_reflection")
    }
    handler = command_map.get(command.lower())
    return handler() if handler else {"type": "message", "content": f"Unknown command: '{command}'. Try /help."}
# --- END OF FILE services/cheats.py ---


================================================================================ðŸ“„ services/llm_interface.py================================================================================
# --- START OF FILE services/llm_interface.py ---
# llm_interface.py
import os
import openai
import instructor
import threading
from tools.logger import log_info, log_error

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
_client = None
_client_lock = threading.Lock()

def get_instructor_client():
    """Initializes and returns a singleton, instructor-patched OpenAI client."""
    global _client
    if not OPENAI_API_KEY:
        log_error("llm_interface", "get_instructor_client", "OPENAI_API_KEY not found in environment.")
        return None

    with _client_lock:
        if _client is None:
            try:
                log_info("llm_interface", "get_instructor_client", "Initializing instructor-patched OpenAI client...")
                # Initialize the OpenAI client
                base_client = openai.OpenAI(api_key=OPENAI_API_KEY)
                # Patch it with Instructor
                _client = instructor.patch(base_client)
                log_info("llm_interface", "get_instructor_client", "Instructor-patched OpenAI client initialized.")
            except Exception as e:
                log_error("llm_interface", "get_instructor_client", f"Failed to initialize OpenAI client: {e}", e)
                _client = None # Ensure it remains None on failure
    return _client

# --- END OF FILE services/llm_interface.py ---


================================================================================ðŸ“„ services/notification_service.py================================================================================
# --- START OF FILE services/notification_service.py ---
# services/notification_service.py
from datetime import datetime, timezone, timedelta
from tools.logger import log_info, log_error, log_warning
from users.user_manager import get_all_user_data
from bridge.request_router import send_message
import tools.activity_db as db  # Use the database directly
import services.task_manager as task_manager # For updating the item status

NOTIFICATION_TRANSLATIONS = {
    "en": {"reminder_alert": "ðŸ”” Reminder: {description}"},
    "he": {"reminder_alert": "ðŸ”” ×ª×–×›×•×¨×ª: {description}"}
}

def _get_notification_translation(lang: str, key: str) -> str:
    """Fetches a translation string for notifications."""
    return NOTIFICATION_TRANSLATIONS.get(lang, {}).get(key, "{description}")

def check_and_send_reminders():
    """
    Scheduled job that iterates through all users, checks for due reminders
    in the database, and sends notifications.
    """
    fn_name = "check_and_send_reminders"
    now_utc = datetime.now(timezone.utc)
    all_user_prefs = get_all_user_data()

    for user_id, prefs in all_user_prefs.items():
        if prefs.get("status") != "active":
            continue

        try:
            # Fetch 'new' reminders for this specific user from the database
            reminders_to_check = db.list_items_for_user(user_id, status_filter=["new"])
            
            for item in reminders_to_check:
                if item.get("type") != "reminder" or not item.get("remind_at"):
                    continue

                item_id = item.get("item_id")
                remind_at_utc = datetime.fromisoformat(item["remind_at"].replace('Z', '+00:00'))
                
                # Send notification if the reminder time is in the past or within the next minute
                if remind_at_utc <= (now_utc + timedelta(minutes=1)):
                    user_lang = prefs.get("language", "en")
                    description = item.get("description", "(No Title)")
                    
                    template = _get_notification_translation(user_lang, "reminder_alert")
                    message = template.format(description=description)
                    
                    log_info(fn_name, "notification_service", f"Sending reminder '{item_id}' to user {user_id}")
                    send_message(user_id, message)
                    
                    # Mark the reminder as complete in the database
                    task_manager.update_item(user_id, item_id, {"status": "completed"})

        except (ValueError, TypeError) as e:
            log_warning(fn_name, "notification_service", f"Could not parse date for a reminder for user {user_id}. Error: {e}")
        except Exception as e:
            log_error(fn_name, "notification_service", f"Error processing reminders for user {user_id}", e)
# --- END OF FILE services/notification_service.py ---


================================================================================ðŸ“„ services/scheduler_service.py================================================================================
# --- START OF FILE services/scheduler_service.py ---
# services/scheduler_service.py
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.events import EVENT_JOB_ERROR
import pytz
from datetime import datetime

from tools.logger import log_info, log_error
import users.user_manager as user_manager
from bridge.request_router import handle_internal_system_event

scheduler: BackgroundScheduler | None = None
ROUTINE_CHECK_INTERVAL_MINUTES = 1

def _job_listener(event):
    if event.exception:
        log_error("scheduler_service", "_job_listener", f"Job crashed: {event.job_id}", event.exception)

def _check_and_trigger_routines():
    all_users_prefs = user_manager.get_all_user_data()
    for user_id, prefs in all_users_prefs.items():
        if prefs.get("status") != "active" or not prefs.get("timezone"):
            continue
        try:
            # --- START OF FIX: Handle 'work_days' and check for null times ---
            ritual_days = prefs.get("ritual_days", prefs.get("work_days", [])) # Backward compatibility
            morning_time = prefs.get("morning_muster_time")
            evening_time = prefs.get("evening_reflection_time")

            user_tz = pytz.timezone(prefs["timezone"])
            now_local = datetime.now(user_tz)
            
            if now_local.strftime("%A") not in ritual_days:
                continue

            current_local_hm = now_local.strftime("%H:%M")
            today_str = now_local.strftime("%Y-%m-%d")

            if morning_time and current_local_hm == morning_time and prefs.get("last_morning_trigger_date") != today_str:
                handle_internal_system_event({"user_id": user_id, "trigger_type": "morning_muster"})
                user_manager.update_user_preferences(user_id, {"last_morning_trigger_date": today_str})

            if evening_time and current_local_hm == evening_time and prefs.get("last_evening_trigger_date") != today_str:
                handle_internal_system_event({"user_id": user_id, "trigger_type": "evening_reflection"})
                user_manager.update_user_preferences(user_id, {"last_evening_trigger_date": today_str})
            # --- END OF FIX ---
        except Exception as e:
            log_error("scheduler_service", "_check_routines", f"Error processing routines for user {user_id}", e)

def _check_and_send_reminders():
    try:
        from services.notification_service import check_and_send_reminders as send_reminders_func
        send_reminders_func()
    except Exception as e:
        log_error("scheduler_service", "_check_reminders", "Error during reminder check", e)

def start_scheduler() -> bool:
    global scheduler
    if scheduler and scheduler.running: return True
    try:
        scheduler = BackgroundScheduler(timezone="UTC")
        scheduler.add_job(_check_and_trigger_routines, 'interval', minutes=ROUTINE_CHECK_INTERVAL_MINUTES, id='kairo_ritual_check')
        scheduler.add_job(_check_and_send_reminders, 'interval', minutes=ROUTINE_CHECK_INTERVAL_MINUTES, id='kairo_reminder_check')
        scheduler.add_listener(_job_listener, EVENT_JOB_ERROR)
        scheduler.start()
        log_info("scheduler_service", "start", "Scheduler started successfully.")
        return True
    except Exception as e:
        log_error("scheduler_service", "start", "Failed to start APScheduler", e)
        return False

def shutdown_scheduler():
    if scheduler and scheduler.running:
        scheduler.shutdown(wait=False)
        log_info("scheduler_service", "shutdown", "Scheduler has been shut down.")
# --- END OF FILE services/scheduler_service.py ---


================================================================================ðŸ“„ services/shared_resources.py================================================================================
# --- START OF FILE services/shared_resources.py ---
# services/shared_resources.py
import yaml
import os
from tools.logger import log_error, log_info

_PROMPTS = {}
_MESSAGES = {}
_PROJECT_SETTINGS = {}

def load_resources():
    """Loads all YAML files into memory."""
    global _PROMPTS, _MESSAGES, _PROJECT_SETTINGS
    
    try:
        with open("config/prompts.yaml", 'r', encoding="utf-8") as f:
            _PROMPTS = yaml.safe_load(f) or {}
    except Exception as e:
        log_error("shared_resources", "load_resources", f"Failed to load prompts.yaml: {e}")

    try:
        with open("config/messages.yaml", 'r', encoding="utf-8") as f:
            _MESSAGES = yaml.safe_load(f) or {}
    except Exception as e:
        log_error("shared_resources", "load_resources", f"Failed to load messages.yaml: {e}")

    try:
        with open("config/settings.yaml", 'r', encoding="utf-8") as f:
            _PROJECT_SETTINGS = yaml.safe_load(f) or {}
    except Exception as e:
        log_error("shared_resources", "load_resources", f"Failed to load settings.yaml: {e}")
        
    log_info("shared_resources", "load_resources", "Shared prompts, messages, and settings have been loaded.")

def get_prompt(key: str) -> str | None:
    return _PROMPTS.get(key)

def get_message_templates(key: str) -> dict | None:
    return _MESSAGES.get(key)

# --- START OF REFACTORED LOGIC ---

def _get_current_project_config() -> dict:
    """Internal helper to get the full config block for the current project."""
    project_name = os.getenv("PROJECT_NAME", "kairo")
    log_info("shared_resources", "get_project_config", f"Loading config for project: {project_name}.")
    
    project_configs = _PROJECT_SETTINGS.get("projects", {})
    # Return the specific project config, or fall back to the default config block
    return project_configs.get(project_name, _PROJECT_SETTINGS.get("default_config", {}))

def get_default_preferences() -> dict:
    """Gets the default_preferences dictionary for the current project."""
    config = _get_current_project_config()
    preferences = config.get("default_preferences", {})
    if not preferences:
        log_error("shared_resources", "get_defaults", "CRITICAL: Could not find 'default_preferences' in config for current project.")
        # Return a hardcoded safe fallback
        return {"name": None, "timezone": None, "language": "en", "status": "new"}
    return preferences

def get_welcome_message_key() -> str:
    """Gets the welcome_message_key for the current project."""
    config = _get_current_project_config()
    # Fall back to the standard key if not found
    return config.get("welcome_message_key", "initial_welcome_message")

# --- END OF REFACTORED LOGIC ---

load_resources()
# --- END OF FILE services/shared_resources.py ---


================================================================================ðŸ“„ services/task_manager.py================================================================================
# --- START OF FILE services/task_manager.py ---
# services/task_manager.py
import uuid
from datetime import datetime, timezone
from typing import Dict

import tools.activity_db as db
from tools.logger import log_info

def create_item(user_id: str, item_type: str, item_params: Dict) -> Dict:
    """Creates a new task or reminder in the database."""
    now_iso = datetime.now(timezone.utc).isoformat()
    new_item_data = {
        "item_id": str(uuid.uuid4()),
        "user_id": user_id,
        "type": item_type,
        "status": "new",
        "created_at": now_iso,
        "updated_at": now_iso,
        **item_params
    }
    
    # Ensure a description exists, as it's a required field in the database
    if 'description' not in new_item_data:
        new_item_data['description'] = 'No description provided'
    
    success = db.add_or_update_item(new_item_data)
    if success:
        log_info("task_manager", "create_item", f"Created {item_type} '{new_item_data['item_id']}' for {user_id}.")
        return {"success": True, "item_id": new_item_data["item_id"]}
    else:
        return {"success": False, "error": f"Failed to create {item_type}."}

def update_item(user_id: str, item_id: str, updates: Dict) -> Dict:
    """
    Updates an existing item in the database by fetching the full record,
    merging the changes, and saving it back.
    """
    # 1. Fetch the complete existing item from the database.
    existing_item = db.get_item(item_id)
    if not existing_item or existing_item.get("user_id") != user_id:
        return {"success": False, "error": "Item not found."}
    
    # --- THIS IS THE FIX ---
    # 2. Merge the original item's data with the new updates.
    #    This ensures all required fields (like 'user_id', 'type') are preserved.
    final_payload = {
        **existing_item,
        **updates,
        "updated_at": datetime.now(timezone.utc).isoformat()
    }
    # --- END OF THE FIX ---
    
    # 3. Save the complete, valid object back to the database.
    success = db.add_or_update_item(final_payload)
    if success:
        log_info("task_manager", "update_item", f"Updated item '{item_id}' for user {user_id}.")
        return {"success": True, "item_id": item_id}
    else:
        # The database layer will log the specific SQLite error.
        return {"success": False, "error": "Failed to update item."}
# --- END OF FILE services/task_manager.py ---


================================================================================ðŸ“„ session_viewer.py================================================================================
# --- START OF FILE session_viewer.py ---
# session_viewer.py
import sqlite3
import json
import argparse
from datetime import datetime, timezone
import pytz
from typing import List, Dict

# --- Configuration ---
DB_DIR = "data"
# This allows the script to work with both _cli and non-suffixed DBs
DB_SUFFIX = "_cli" # Set to "" for production, or pass as an argument
DB_FILE_PATH = "" # Will be set by arguments

# --- Helper Functions ---
def _format_timestamp(ts_str: str, local_tz: pytz.BaseTzInfo) -> str:
    """Converts a UTC ISO string to a user-friendly local time string."""
    if not ts_str:
        return " " * 19
    try:
        utc_dt = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
        local_dt = utc_dt.astimezone(local_tz)
        return local_dt.strftime('%Y-%m-%d %H:%M:%S')
    except (ValueError, TypeError):
        return ts_str[:19] # Fallback to show raw timestamp

def _pretty_print_json(json_str: str) -> str:
    """Formats a JSON string with indentation for readability."""
    try:
        obj = json.loads(json_str)
        return json.dumps(obj, indent=2, ensure_ascii=False)
    except (json.JSONDecodeError, TypeError):
        return json_str # Return as is if not valid JSON

# --- Main Logic ---
def get_user_session(db_path: str, user_id: str, local_tz: pytz.BaseTzInfo) -> None:
    """Queries all relevant tables for a user's session and prints a chronological log."""
    
    all_events = []
    
    try:
        with sqlite3.connect(f"file:{db_path}?mode=ro", uri=True) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # 1. Fetch messages
            cursor.execute("SELECT * FROM messages WHERE user_id = ?", (user_id,))
            for row in cursor.fetchall():
                all_events.append({
                    "timestamp": row["timestamp"],
                    "type": "MESSAGE",
                    "data": dict(row)
                })

            # 2. Fetch LLM tool activity
            cursor.execute("SELECT * FROM llm_activity WHERE user_id = ?", (user_id,))
            for row in cursor.fetchall():
                all_events.append({
                    "timestamp": row["timestamp"],
                    "type": "TOOL_CALL",
                    "data": dict(row)
                })

            # 3. Fetch system logs (errors/warnings)
            cursor.execute("SELECT * FROM system_logs") # Get all, then we'll filter
            for row in cursor.fetchall():
                 # For system logs, we can't always guarantee a user_id context, so we show all for now
                 # A more advanced version could try to correlate by timestamp
                 all_events.append({
                    "timestamp": row["timestamp"],
                    "type": f"SYS_{row['level']}",
                    "data": dict(row)
                })

    except sqlite3.Error as e:
        print(f"âŒ Database Error: Could not connect to or query '{db_path}'.\n   Reason: {e}")
        return

    if not all_events:
        print(f"No activity found for user ID: {user_id}")
        return

    # Sort all collected events chronologically
    all_events.sorted_events = sorted(all_events, key=lambda x: x["timestamp"])

    # --- Print the formatted session log ---
    print("\n" + "="*80)
    print(f"Kairo Session Log for User: {user_id}")
    print(f"Timezone: {local_tz.zone}")
    print("="*80 + "\n")

    for event in all_events.sorted_events:
        ts = _format_timestamp(event["timestamp"], local_tz)
        event_type = event["type"]
        data = event["data"]

        if event_type == "MESSAGE":
            role = data['role'].upper()
            content = data['content']
            if role == 'USER':
                print(f"[{ts}] ðŸ‘¤ \033[92m{role}:\033[0m {content}") # Green
            else: # ASSISTANT
                print(f"[{ts}] ðŸ¤– \033[94m{role}:\033[0m {content}") # Blue

        elif event_type == "TOOL_CALL":
            tool_name = data['tool_name']
            print(f"[{ts}] âš™ï¸  \033[93mTOOL CALL: {tool_name}\033[0m")
            print("   â–¶ï¸  Args:")
            print(_pretty_print_json(data['tool_args_json']))
            print("   â—€ï¸  Result:")
            print(_pretty_print_json(data['tool_result_json']))
        
        elif event_type.startswith("SYS_"):
            level = data['level']
            color = '\033[91m' if level == 'ERROR' else '\033[93m' # Red for Error, Yellow for Warning
            print(f"[{ts}] âš ï¸  {color}{level} in {data['module']}:{data['function']}\033[0m")
            print(f"   - {data['message']}")
            if data['traceback']:
                print(f"   - Traceback: {data['traceback']}")

    print("\n" + "="*80)
    print("End of session log.")
    print("="*80)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="View a user's chronological session from the Kairo database.")
    parser.add_argument("user_id", type=str, help="The user ID to retrieve the session for.")
    parser.add_argument("--mode", type=str, choices=['cli', 'prod'], default='cli', help="The database mode ('cli' or 'prod'). Defaults to 'cli'.")
    parser.add_argument("--tz", type=str, default="Asia/Jerusalem", help="Your local timezone for displaying timestamps, e.g., 'America/New_York'. Defaults to 'Asia/Jerusalem'.")
    
    args = parser.parse_args()
    
    db_suffix = "_cli" if args.mode == 'cli' else ""
    db_path = os.path.join(DB_DIR, f"kairo_activity{db_suffix}.db")
    
    try:
        local_timezone = pytz.timezone(args.tz)
    except pytz.UnknownTimeZoneError:
        print(f"âŒ Unknown timezone '{args.tz}'. Please use a valid TZ database name.")
        exit(1)

    get_user_session(db_path, args.user_id, local_timezone)
# --- END OF FILE session_viewer.py ---


================================================================================ðŸ“„ tests/mock_browser_chat.py================================================================================
# --- START OF FILE tests/mock_browser_chat.py ---
# tests/mock_browser_chat.py
import os
import requests
import json
import time
import threading
from flask import Flask, render_template, request, jsonify
from collections import deque
from datetime import datetime
from dotenv import load_dotenv
import logging

# --- Configuration ---
load_dotenv()
VIEWER_PORT = int(os.getenv("VIEWER_PORT", "5001"))
MAX_MESSAGES = 100
MAIN_BACKEND_PORT = os.getenv("PORT", "8001")
MAIN_BACKEND_BASE_URL = f"http://localhost:{MAIN_BACKEND_PORT}"
MAIN_BACKEND_OUTGOING_URL = f"{MAIN_BACKEND_BASE_URL}/outgoing"
MAIN_BACKEND_ACK_URL = f"{MAIN_BACKEND_BASE_URL}/ack"
MOCK_USER_ID = "1234"

# --- State ---
message_store_bot = deque(maxlen=MAX_MESSAGES)
message_lock = threading.Lock()
_stop_polling_event = threading.Event()

# --- Flask App Setup ---
app = Flask(__name__, template_folder=os.path.join(os.path.dirname(__file__), 'templates'))
app.secret_key = os.getenv("FLASK_SECRET_KEY", os.urandom(24))

def mock_log(level, component, message):
    """Custom logger to print formatted messages to the console."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level.upper()}] [MockChat:{component}] {message}")

# --- START OF FIX: Refactored Polling Function ---
def poll_main_backend():
    """Polls the Kairo backend for outgoing messages."""
    session = requests.Session()
    while not _stop_polling_event.is_set():
        try:
            res = session.get(MAIN_BACKEND_OUTGOING_URL, timeout=5)
            res.raise_for_status()
            data = res.json()
            
            messages_from_backend = data.get("messages", [])
            
            if not messages_from_backend:
                time.sleep(1) # Wait a second if the queue is empty
                continue

            # If we get here, messages were found.
            mock_log("info", "PollingThread", f"Found {len(messages_from_backend)} message(s) in payload from Kairo.")
            
            for msg_data in messages_from_backend:
                # Log every message received, regardless of user ID for debugging
                mock_log("info", "PollingThread", f"RECEIVED: User='{msg_data.get('user_id')}', Msg='{msg_data.get('message', '')[:70]}...'")
                
                # Process only messages for our simulated user
                if msg_data.get('user_id') == MOCK_USER_ID:
                    with message_lock:
                        message_store_bot.appendleft({
                            "sender": "bot",
                            "timestamp": datetime.now().strftime("%H:%M:%S"),
                            "content": msg_data.get('message'),
                            "id": msg_data.get('message_id')
                        })
                    
                    # Acknowledge the message was processed
                    session.post(MAIN_BACKEND_ACK_URL, json={"message_id": msg_data.get('message_id'), "user_id": MOCK_USER_ID}, timeout=3)
        
        except requests.exceptions.RequestException:
            # This happens if the backend is down, wait before retrying.
            time.sleep(2)
        except Exception as e:
            mock_log("error", "PollingThread", f"An unexpected error occurred in polling loop: {e}")
            time.sleep(5)
# --- END OF FIX ---

# --- Flask Routes ---
@app.route('/')
def index():
    return render_template('browser_chat.html', title=f"Kairo Mock Chat (User: {MOCK_USER_ID})")

@app.route('/send_message', methods=['POST'])
def send_message_route():
    data = request.get_json()
    message_text = data.get('message')
    if not message_text:
        return jsonify({"status": "error", "message": "No message"}), 400

    backend_payload = {"user_id": MOCK_USER_ID, "message": message_text}
    mock_log("info", "SendRoute", f"SENDING to Kairo backend: '{message_text}'")
    try:
        requests.post(f"{MAIN_BACKEND_BASE_URL}/incoming", json=backend_payload, timeout=120)
        return jsonify({"status": "ok"}), 200
    except requests.exceptions.RequestException:
        return jsonify({"status": "error", "message": "Could not connect to Kairo backend."}), 503

@app.route('/get_messages')
def get_messages_route():
    with message_lock:
        return jsonify({"messages": list(message_store_bot)})

@app.route('/clear_messages', methods=['POST'])
def clear_messages_route():
    with message_lock:
        message_store_bot.clear()
    return jsonify({"status": "ok"})

# --- Main Execution ---
if __name__ == '__main__':
    mock_log("info", "Main", "--- Starting Kairo Mock Browser Chat ---")
    user_input_id_raw = input(f"Enter User ID to simulate (leave blank for '{MOCK_USER_ID}'): ").strip()
    if user_input_id_raw: MOCK_USER_ID = user_input_id_raw
    mock_log("info", "Main", f"Simulating as User ID: {MOCK_USER_ID}")
    
    polling_thread = threading.Thread(target=poll_main_backend, daemon=True)
    polling_thread.start()
    
    log = logging.getLogger('werkzeug')
    log.setLevel(logging.ERROR)
    
    app.run(host='0.0.0.0', port=VIEWER_PORT, debug=False, use_reloader=False)
# --- END OF FILE tests/mock_browser_chat.py ---


================================================================================ðŸ“„ tests/templates/browser_chat.html================================================================================
# --- START OF FILE tests/templates/browser_chat.html ---
<!-- tests/templates/browser_chat.html -->
<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>{{ title }}</title>
    <style>
        /* Styles remain the same */
        body { font-family: sans-serif; margin: 0; padding: 0; display: flex; flex-direction: column; height: 100vh; background-color: #f4f4f4; }
        h1 { text-align: center; color: #333; margin: 10px 0; }
        #chat-container { flex-grow: 1; border: 1px solid #ccc; background-color: #fff; margin: 0 10px 10px 10px; overflow-y: auto; padding: 10px; }
        #messages { list-style-type: none; padding: 0; margin: 0; }
        #messages li { margin-bottom: 10px; padding: 8px; border-radius: 5px; word-wrap: break-word; max-width: 80%; clear: both; }
        #messages li.user { background-color: #dcf8c6; margin-left: auto; float: right; text-align: right; }
        #messages li.bot { background-color: #e0e0e0; margin-right: auto; float: left; text-align: left; }
        #messages li.system { background-color: #f0e68c; margin-left: auto; margin-right: auto; text-align: center; font-style: italic; color: #555; max-width: 90%; float: none; font-size: 0.9em;}
        #messages li[dir="rtl"] { text-align: right; }
        #messages li[dir="ltr"] { text-align: left; }
        .msg-meta { font-size: 0.8em; color: #888; display: block; margin-top: 4px; }
        .msg-content { white-space: pre-wrap; }
        #input-area { display: flex; padding: 10px; border-top: 1px solid #ccc; background-color: #eee; }
        #messageInput { flex-grow: 1; padding: 10px; border: 1px solid #ccc; border-radius: 3px; margin-right: 5px;}
        #sendButton { padding: 10px 15px; cursor: pointer; }
        #controls { text-align: right; padding: 0 10px 5px 0; font-size: 0.8em; }
    </style>
</head>
<body>

    <h1>{{ title }}</h1>
    <div id="controls">
        <button id="clearButton" title="Clear messages displayed in this browser window">Clear Display</button>
    </div>

    <div id="chat-container">
        <ul id="messages">
            <!-- Messages will be added dynamically -->
        </ul>
    </div>

    <div id="input-area">
        <input type="text" id="messageInput" placeholder="Type your message..." autocomplete="off">
        <button id="sendButton">Send</button>
    </div>

    <script>
        const messagesContainer = document.getElementById('messages');
        const messageInput = document.getElementById('messageInput');
        const sendButton = document.getElementById('sendButton');
        const clearButton = document.getElementById('clearButton');

        let displayedMessageIds = new Set(); // Track IDs shown in browser
        let isSending = false;
        let isFetching = false;

        function containsHebrew(text) {
            if (!text) return false;
            return /[\u0590-\u05FF]/.test(text);
        }

        // Function to add a single message object to the display UL
        function addMessageToDisplay(msg) {
             if (!msg || !msg.id || displayedMessageIds.has(msg.id)) {
                 return false; // Don't add if no message, no ID, or already displayed
             }

             const li = document.createElement('li');
             const senderClass = msg.sender || 'system';
             li.classList.add(senderClass);

             const isRtl = containsHebrew(msg.content);
             li.setAttribute('dir', isRtl ? 'rtl' : 'ltr');

             const contentSpan = document.createElement('span');
             contentSpan.className = 'msg-content';
             contentSpan.textContent = msg.content;

             const metaSpan = document.createElement('span');
             metaSpan.className = 'msg-meta';
             // Use sender from message object now
             metaSpan.textContent = `[${msg.timestamp}] ${senderClass.toUpperCase()}`;

             li.appendChild(contentSpan);
             li.appendChild(metaSpan);

             messagesContainer.appendChild(li);
             displayedMessageIds.add(msg.id); // Mark as displayed
             return true;
        }

        // Fetches ONLY BOT messages and adds them if not already displayed
        async function fetchAndUpdateMessages() {
            if (isFetching) return;
            isFetching = true;
            let addedNew = false;
             try {
                const response = await fetch('/get_messages'); // Fetches BOT messages from server store
                if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
                const result = await response.json();
                const botMessages = result.messages || [];

                botMessages.forEach(msg => {
                    // addMessageToDisplay checks displayedMessageIds
                    if(addMessageToDisplay(msg)) {
                        addedNew = true;
                    }
                });

            } catch (error) {
                console.error('Error fetching messages:', error);
            } finally {
                 isFetching = false;
                 if (addedNew) {
                     messagesContainer.scrollTop = messagesContainer.scrollHeight;
                 }
             }
        }

       async function sendMessage() {
            const messageText = messageInput.value.trim();
            if (!messageText || isSending) return;
            isSending = true;
            sendButton.disabled = true;
            messageInput.disabled = true;

            // 1. Create and display user message OBJECT immediately
             const userTimestamp = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
             const localUserId = `user-${Date.now()}`;
             const userMsg = {
                 sender: 'user',
                 timestamp: userTimestamp,
                 content: messageText,
                 id: localUserId
             };
             if(addMessageToDisplay(userMsg)){ // Add user message to display
                 messagesContainer.scrollTop = messagesContainer.scrollHeight;
             }
             messageInput.value = '';

            // 2. Send message to viewer backend to forward to main backend
            try {
                const response = await fetch('/send_message', { // Send to viewer backend
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ message: messageText })
                });
                if (!response.ok) {
                    const errorData = await response.json().catch(() => ({ message: response.statusText }));
                    console.error('Error sending message via viewer:', errorData.message);
                    // Add error message to display
                    addMessageToDisplay({ sender: 'system', timestamp: new Date().toLocaleTimeString(), content: `Error sending: ${errorData.message}`, id:`err-${Date.now()}`});
                    messagesContainer.scrollTop = messagesContainer.scrollHeight;
                }
                 // Bot response will arrive via the fetchAndUpdateMessages polling
            } catch (error) {
                console.error('Network error sending message via viewer:', error);
                 addMessageToDisplay({ sender: 'system', timestamp: new Date().toLocaleTimeString(), content: `Network Error: ${error}`, id:`neterr-${Date.now()}`});
                 messagesContainer.scrollTop = messagesContainer.scrollHeight;
            } finally {
                 isSending = false;
                 sendButton.disabled = false;
                 messageInput.disabled = false;
                 messageInput.focus();
            }
        }

       async function clearMessages() {
             displayedMessageIds.clear(); // Clear JS tracking
             messagesContainer.innerHTML = '<li>Clearing...</li>'; // Update display
            try {
                await fetch('/clear_messages', { method: 'POST' }); // Tell server to clear its bot store
                 messagesContainer.innerHTML = '<li>Messages cleared.</li>';
            } catch (error) {
                console.error('Error signaling viewer to clear messages:', error);
                messagesContainer.innerHTML = '<li>Error clearing messages.</li>';
            }
        }

        // Event Listeners
        sendButton.addEventListener('click', sendMessage);
        messageInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') { sendMessage(); }
        });
        clearButton.addEventListener('click', clearMessages);

        // Fetch messages periodically
        setInterval(fetchAndUpdateMessages, 1500);

        // Initial fetch
        // No initial fetch needed, or fetch then clear display?
        // Let's start clean
        messagesContainer.innerHTML = '<li>Connecting...</li>'; // Initial message

    </script>

</body>
</html>
# --- END OF FILE tests/templates/browser_chat.html ---


================================================================================ðŸ“„ tools/activity_db.py================================================================================
# --- START OF FILE tools/activity_db.py ---
# tools/activity_db.py
import sqlite3
import os
import json
import threading
from datetime import datetime, timezone
from typing import Dict, List, Any

from tools.logger import log_info, log_error

# Configuration
DATA_SUFFIX = os.getenv("DATA_SUFFIX", "")
DB_DIR = "data"
DB_FILE = os.path.join(DB_DIR, f"kairo_activity{DATA_SUFFIX}.db")
DB_LOCK = threading.Lock()

def init_db():
    """Initializes the database and creates tables if they don't exist."""
    os.makedirs(DB_DIR, exist_ok=True)
    with DB_LOCK, sqlite3.connect(DB_FILE, check_same_thread=False, timeout=10) as conn:
        cursor = conn.cursor()
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS users_tasks (
            item_id TEXT PRIMARY KEY NOT NULL, user_id TEXT NOT NULL, type TEXT NOT NULL,
            status TEXT NOT NULL, description TEXT NOT NULL, project TEXT, due_date TEXT,
            remind_at TEXT, created_at TEXT NOT NULL, updated_at TEXT NOT NULL
        )""")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_tasks_user_id_status ON users_tasks (user_id, status)")
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT NOT NULL, user_id TEXT NOT NULL,
            role TEXT NOT NULL, message_type TEXT NOT NULL, content TEXT
        )""")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_messages_user_id_ts ON messages (user_id, timestamp)")

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS llm_activity (
            id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT NOT NULL, user_id TEXT NOT NULL,
            tool_name TEXT NOT NULL, tool_args_json TEXT NOT NULL, tool_result_json TEXT NOT NULL
        )""")

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS system_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT NOT NULL, level TEXT NOT NULL,
            module TEXT NOT NULL, function TEXT NOT NULL, message TEXT NOT NULL, traceback TEXT
        )""")
        conn.commit()
    log_info("activity_db", "init_db", f"Database initialized at {DB_FILE}")

def _dict_factory(cursor, row):
    fields = [column[0] for column in cursor.description]
    return {key: value for key, value in zip(fields, row)}

def add_or_update_item(item_data: Dict) -> bool:
    item_id = item_data.get("item_id")
    if not item_id: return False
    columns = list(item_data.keys()); placeholders = ', '.join('?'*len(columns))
    update_setters = ', '.join([f"{col}=excluded.{col}" for col in columns if col != 'item_id'])
    sql = f"INSERT INTO users_tasks ({','.join(columns)}) VALUES ({placeholders}) ON CONFLICT(item_id) DO UPDATE SET {update_setters}"
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE) as conn:
            conn.execute(sql, list(item_data.values())); conn.commit()
        return True
    except sqlite3.Error as e:
        log_error("activity_db", "add_or_update_item", f"DB error for item {item_id}", e); return False

def get_item(item_id: str) -> Dict | None:
    try:
        with sqlite3.connect(DB_FILE) as conn:
            conn.row_factory = _dict_factory
            return conn.execute("SELECT * FROM users_tasks WHERE item_id = ?", (item_id,)).fetchone()
    except sqlite3.Error as e:
        log_error("activity_db", "get_item", f"DB error for item {item_id}", e); return None

def list_items_for_user(user_id: str, status_filter: List[str] | None = None) -> List[Dict]:
    sql = "SELECT * FROM users_tasks WHERE user_id = ?"; params: List[Any] = [user_id]
    if status_filter:
        placeholders = ','.join('?'*len(status_filter)); sql += f" AND status IN ({placeholders})"; params.extend(status_filter)
    sql += " ORDER BY created_at DESC"
    try:
        with sqlite3.connect(DB_FILE) as conn:
            conn.row_factory = _dict_factory; return conn.execute(sql, params).fetchall()
    except sqlite3.Error as e:
        log_error("activity_db", "list_items_for_user", f"DB error for {user_id}", e); return []

def get_recent_messages(user_id: str, limit: int = 10) -> List[Dict]:
    """Fetches the most recent messages for a user to provide conversation history."""
    sql = """
        SELECT role, content FROM messages
        WHERE user_id = ? AND message_type IN ('user_text', 'agent_text_response')
        ORDER BY timestamp DESC
        LIMIT ?
    """
    try:
        with sqlite3.connect(DB_FILE) as conn:
            conn.row_factory = _dict_factory
            messages = conn.execute(sql, (user_id, limit)).fetchall()
            return list(reversed(messages))
    except sqlite3.Error as e:
        log_error("activity_db", "get_recent_messages", f"DB error for {user_id}", e)
        return []

def log_message(user_id: str, role: str, message_type: str, content: str):
    ts = datetime.now(timezone.utc).isoformat()
    sql = "INSERT INTO messages (timestamp, user_id, role, message_type, content) VALUES (?, ?, ?, ?, ?)"
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE) as conn:
            conn.execute(sql, (ts, user_id, role, message_type, content)); conn.commit()
    except sqlite3.Error as e:
        log_error("activity_db", "log_message", f"DB error for {user_id}", e)

def log_llm_activity(user_id: str, tool_name: str, tool_args: Dict, tool_result: Dict):
    ts = datetime.now(timezone.utc).isoformat()
    sql = "INSERT INTO llm_activity (timestamp, user_id, tool_name, tool_args_json, tool_result_json) VALUES (?, ?, ?, ?, ?)"
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE) as conn:
            conn.execute(sql, (ts, user_id, tool_name, json.dumps(tool_args), json.dumps(tool_result))); conn.commit()
    except sqlite3.Error as e:
        log_error("activity_db", "log_llm_activity", f"DB error for {user_id}", e)

def log_system_event(level: str, module: str, function: str, message: str, traceback_str: str | None = None, timestamp: str | None = None):
    ts = timestamp or datetime.now(timezone.utc).isoformat()
    params = (ts, level.upper(), module, function, message, traceback_str)
    sql = "INSERT INTO system_logs (timestamp, level, module, function, message, traceback) VALUES (?, ?, ?, ?, ?, ?)"
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE, check_same_thread=False, timeout=10) as conn:
            conn.execute(sql, params); conn.commit()
    except sqlite3.Error as e:
        print(f"CRITICAL DB LOGGING FAILED: {ts} [{level.upper()}] {module}:{function} - {message}\n{e}")
# --- END OF FILE tools/activity_db.py ---


================================================================================ðŸ“„ tools/logger.py================================================================================
# --- START OF FILE tools/logger.py ---
# tools/logger.py
import os
import pytz
from datetime import datetime, timezone
import traceback

# This module will now attempt to import the DB logging function when first used.
_activity_db_log_func = None
ACTIVITY_DB_IMPORTED = False

# --- Configuration ---
DEBUG_MODE = os.getenv("DEBUG_MODE", "True").lower() in ('true', '1', 't')
LOG_DIR = "logs"
LOG_FILE = os.path.join(LOG_DIR, "kairo_app.log")
LOG_TIMEZONE_STR = "Asia/Jerusalem"

try:
    LOG_TIMEZONE_PYTZ = pytz.timezone(LOG_TIMEZONE_STR)
except pytz.UnknownTimeZoneError:
    print(f"[ERROR] [logger:init] Unknown Timezone '{LOG_TIMEZONE_STR}'. Defaulting to UTC.")
    LOG_TIMEZONE_PYTZ = pytz.utc

try:
    os.makedirs(LOG_DIR, exist_ok=True)
except OSError as e:
    print(f"[{datetime.now(timezone.utc).isoformat()}] [ERROR] [logger:init] Failed to create log directory '{LOG_DIR}': {e}")

# --- Helper Functions ---
def _timestamp_utc_iso():
    """Returns current time in UTC ISO format for DB logging."""
    return datetime.now(timezone.utc).isoformat()

def _format_log_entry(level: str, module: str, func: str, message: str):
    """Formats a log entry with the configured local timezone."""
    ts_aware = datetime.now(LOG_TIMEZONE_PYTZ)
    ts_formatted = ts_aware.strftime("%Y-%m-%d %H:%M:%S %Z")
    return f"[{ts_formatted}] [{level.upper()}] [{module}:{func}] {message}"

def _try_log_to_db(level: str, module: str, function: str, message: str, traceback_str: str | None = None, timestamp_utc_iso: str | None = None):
    """Internal helper to dynamically import and call the DB logging function."""
    global _activity_db_log_func, ACTIVITY_DB_IMPORTED
    if not ACTIVITY_DB_IMPORTED:
        try:
            from tools.activity_db import log_system_event
            _activity_db_log_func = log_system_event
            ACTIVITY_DB_IMPORTED = True
        except ImportError:
            _activity_db_log_func = None

    if _activity_db_log_func:
        try:
            db_ts = timestamp_utc_iso or _timestamp_utc_iso()
            _activity_db_log_func(
                level=level.upper(),
                module=module,
                function=function,
                message=message,
                traceback_str=traceback_str,
                timestamp=db_ts
            )
        except Exception as db_log_err:
            print(f"CRITICAL DB LOG FAIL: {db_log_err} | Original Msg: {message}")

# --- Public Logging Functions ---
def log_info(module: str, func: str, message: str):
    """Logs informational messages to the console in debug mode."""
    if DEBUG_MODE:
        print(_format_log_entry("INFO", module, func, message))

def log_error(module: str, func: str, message: str, exception: Exception | None = None):
    """Logs error messages to console/file and attempts to log to the database."""
    level = "ERROR"
    traceback_str = traceback.format_exc() if exception else None
    entry = _format_log_entry(level, module, func, message)
    
    print(entry)
    if traceback_str:
        print(traceback_str)
    
    _try_log_to_db(level, module, func, message, traceback_str, _timestamp_utc_iso())

def log_warning(module: str, func: str, message: str):
    """Logs warning messages to console/file and attempts to log to the database."""
    level = "WARNING"
    entry = _format_log_entry(level, module, func, message)
    print(entry)
    _try_log_to_db(level, module, func, message, None, _timestamp_utc_iso())
# --- END OF FILE tools/logger.py ---


================================================================================ðŸ“„ users/user_manager.py================================================================================
# --- START OF FILE users/user_manager.py ---
# users/user_manager.py
import json
import os
import threading
from typing import Dict, Any, List
from datetime import datetime, timezone
from tools.logger import log_info, log_error
import tools.activity_db as db
from services.shared_resources import get_default_preferences

# Configuration
USER_DATA_PATH = os.path.join("data", f"kairo_users{os.getenv('DATA_SUFFIX', '')}.json")
_user_prefs_store: Dict[str, Dict[str, Any]] = {}
_prefs_lock = threading.Lock()

def _load_user_preferences():
    global _user_prefs_store
    try:
        os.makedirs(os.path.dirname(USER_DATA_PATH), exist_ok=True)
        if os.path.exists(USER_DATA_PATH):
            with open(USER_DATA_PATH, "r", encoding="utf-8") as f:
                full_data = json.loads(f.read() or "{}")
                for user_id, data in full_data.items():
                    if "preferences" in data: _user_prefs_store[user_id] = data["preferences"]
    except Exception as e:
        log_error("user_manager", "load_prefs", "Failed to load preferences file", e)

def _save_user_preferences():
    try:
        data_to_save = {uid: {"preferences": p} for uid, p in _user_prefs_store.items()}
        with open(USER_DATA_PATH + ".tmp", "w", encoding="utf-8") as f:
            json.dump(data_to_save, f, indent=2, ensure_ascii=False)
        os.replace(USER_DATA_PATH + ".tmp", USER_DATA_PATH)
    except Exception as e:
        log_error("user_manager", "save_prefs", "Failed to write preferences", e)

def init_all_agents():
    _load_user_preferences()

def get_agent(user_id: str) -> Dict[str, Any]:
    with _prefs_lock:
        if user_id not in _user_prefs_store:
            log_info("user_manager", "get_agent", f"Creating new user preferences for {user_id}")
            _user_prefs_store[user_id] = get_default_preferences()
            _save_user_preferences()
        preferences = _user_prefs_store.get(user_id, get_default_preferences())

    # --- START OF FIX: Handle 'work_days' to 'ritual_days' migration ---
    if "ritual_days" not in preferences and "work_days" in preferences:
        preferences["ritual_days"] = preferences["work_days"]
    # --- END OF FIX ---

    today_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    all_active_items = db.list_items_for_user(user_id, status_filter=["new", "in_progress"])
    non_overdue_items = [item for item in all_active_items if not item.get("due_date") or item.get("due_date") >= today_str]
    conversation_history = db.get_recent_messages(user_id, limit=10)
    preferences['current_utc_date'] = today_str
    
    return {
        "user_id": user_id, "preferences": preferences,
        "items": non_overdue_items, "conversation_history": conversation_history
    }

def get_all_user_data() -> Dict[str, Dict[str, Any]]:
    with _prefs_lock: return json.loads(json.dumps(_user_prefs_store))

def add_message_to_user_history(user_id: str, role: str, message_type: str, content: str | None = None, **kwargs):
    db.log_message(user_id=user_id, role=role, message_type=message_type, content=content)

def update_user_preferences(user_id: str, updates: Dict) -> bool:
    with _prefs_lock:
        if user_id not in _user_prefs_store: _user_prefs_store[user_id] = get_default_preferences()
        
        # --- START OF FIX: Handle 'work_days' to 'ritual_days' migration during update ---
        if "work_days" in updates:
            updates["ritual_days"] = updates.pop("work_days")
        # --- END OF FIX ---
        
        _user_prefs_store[user_id].update(updates)
        _save_user_preferences()
    return True
# --- END OF FILE users/user_manager.py ---


