# Kairo Project Code Dump (v1.0 MVP)
# Generated: 2025-07-14 12:13:15


================================================================================
📄 requirements.txt
================================================================================

# --- START OF FILE requirements.txt ---

# Web Framework & Server
fastapi>=0.110.0,<0.112.0
uvicorn[standard]>=0.29.0,<0.30.0
python-multipart==0.0.9 # Added for Twilio form data

# Langchain Core & OpenAI Integration
langchain>=0.1.16,<0.2.0
langchain-core>=0.1.40,<0.2.0
langchain-openai>=0.1.3,<0.2.0

# Google API Libraries
google-api-python-client>=2.120.0,<3.0.0
google-auth-oauthlib>=1.2.0,<2.0.0
google-auth>=2.29.0,<3.0.0

# Configuration & Environment
python-dotenv>=1.0.1,<2.0.0
PyYAML>=6.0.1,<7.0.0

# Utilities
requests>=2.31.0,<3.0.0
pytz>=2024.1
cryptography>=42.0.0,<43.0.0
PyJWT>=2.8.0,<3.0.0

# Pydantic (Core dependency for FastAPI & Langchain)
pydantic>=2.7.0,<3.0.0

# --- ADDED FOR SCHEDULING ---
APScheduler>=3.10.0,<4.0.0
# --------------------------
instructor>=0.5.2,<1.0.0
openai>=1.0.0,<2.0.0
twilio>=7.0.0,<8.0.0 # For Twilio API integration

# --- END OF FILE requirements.txt ---



================================================================================
📄 .gitignore
================================================================================

# --- START OF FILE .gitignore ---

# --- Python ---
# Virtual environments
venv/
.venv/
env/
ENV/

# Compiled files
__pycache__/
*.pyc

# Packaging
*.egg-info/
*.egg
build/
dist/
*.manifest
*.spec
MANIFEST

# PyInstaller logs
pip-log.txt
pip-delete-this-directory.txt

# Testing and coverage
.tox/
.nox/
.pytest_cache/
.hypothesis/
.coverage*
.cache
nosetests.xml
coverage.xml
htmlcov/
*.cover
*.py,cover
cover/

# Jupyter
.ipynb_checkpoints

# --- Node.js ---
node_modules/
jspm_packages/
web_modules/

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

# Diagnostic reports
report.*.json

# Build outputs
build/
dist/
*.tgz

# TypeScript / Lint
*.tsbuildinfo
.eslintcache
.stylelintcache

# --- WhatsApp Web JS ---
.wwebjs_auth/
.wwebjs_cache/

# --- Project-Specific ---
.env
data/
logs/
startup_error.log
mock_output.txt
*.dump*.txt
viewer_messages.db
*.tmp
project_v0.8_dump.txt

# --- Editors/IDE ---
# VS Code
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json

# JetBrains / PyCharm
.idea/
*.iml
.history/

# --- OS ---
.DS_Store
Thumbs.db
ehthumbs.db
Desktop.ini
last_*.txt
project_v0.8_dump.txt
project_v0.8_dump.txt
env.example


# --- END OF FILE .gitignore ---



================================================================================
📄 main.py
================================================================================

# --- START OF FILE main.py ---

# main.py
import os
import sys
import asyncio
import signal
import argparse
from dotenv import load_dotenv
import traceback

# Load .env first
load_dotenv()

# --- START OF CHANGE: Set BRIDGE_TYPE as an environment variable ---
# This makes the bridge choice globally accessible to any module in any process.
DEFAULT_BRIDGE = "cli"
ALLOWED_BRIDGES = ["cli", "whatsapp", "twilio"]
parser = argparse.ArgumentParser(description="Run the Kairo Productivity Coach Backend")
parser.add_argument("--bridge", type=str, choices=ALLOWED_BRIDGES, help=f"Specify the bridge interface ({', '.join(ALLOWED_BRIDGES)})")
args = parser.parse_args()

cli_arg = args.bridge.lower() if args.bridge else None
env_var = os.getenv("BRIDGE_TYPE", "").lower()
# Priority for setting bridge type: CLI argument > Environment variable > Default
bridge_type = cli_arg or env_var or DEFAULT_BRIDGE
os.environ["BRIDGE_TYPE"] = bridge_type
# --- END OF CHANGE ---

# Import other modules after setting the environment
from tools.activity_db import init_db
init_db()  # Initialize DB before any other service
from tools.logger import log_info, log_error, log_warning

import uvicorn
from users.user_manager import init_all_agents
from services.scheduler_service import start_scheduler, shutdown_scheduler

# Determine which FastAPI app to run based on the configured bridge
UVICORN_APP_MAP = {
    "cli": "bridge.cli_interface:app",
    "whatsapp": "bridge.whatsapp_interface:app",
    "twilio": "bridge.twilio_interface:app"
}
uvicorn_app_path = UVICORN_APP_MAP.get(bridge_type)

if not uvicorn_app_path:
    log_error("main", "init", f"Invalid bridge type '{bridge_type}' configured. Exiting.")
    sys.exit(1)

log_info("main", "init", f"Kairo v1.0 starting with bridge: '{bridge_type}'")

# Graceful shutdown handler remains the same
server: uvicorn.Server | None = None
async def handle_shutdown_signal(sig: signal.Signals, loop: asyncio.AbstractEventLoop):
    log_warning("main", "shutdown", f"Received signal {sig.name}. Initiating shutdown...")
    if server:
        server.should_exit = True
    await asyncio.sleep(1)
    shutdown_scheduler()

async def main_async():
    global server
    log_info("main", "startup", "Initializing agent states...")
    init_all_agents()
    log_info("main", "startup", "Agent state initialization complete.")

    log_info("main", "startup", "Starting scheduler service...")
    if not start_scheduler():
        log_error("main", "startup", "Scheduler service FAILED to start.")
    else:
        log_info("main", "startup", "Scheduler service started successfully.")

    reload_enabled = os.getenv("APP_ENV", "production").lower() == "development"
    log_level = "debug" if reload_enabled else "info"
    server_port = int(os.getenv("PORT", "8001")) # Changed default port to 8001

    log_info("main", "startup", "Configuring FastAPI server...")
    config = uvicorn.Config(
        uvicorn_app_path, host="0.0.0.0", port=server_port,
        reload=reload_enabled, access_log=False, log_level=log_level, lifespan="on"
    )
    server = uvicorn.Server(config)

    loop = asyncio.get_running_loop()
    for sig_name in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig_name, lambda s=sig_name: asyncio.create_task(handle_shutdown_signal(s, loop)))
        except NotImplementedError:
             signal.signal(sig_name, lambda s, f: asyncio.create_task(handle_shutdown_signal(signal.Signals(s), loop)))

    await server.serve()
    log_info("main", "shutdown", "Server has stopped.")

if __name__ == "__main__":
    try:
        asyncio.run(main_async())
    except (KeyboardInterrupt, SystemExit):
        log_warning("main", "exit", "Application exit requested.")
    except Exception as e:
        log_error("main", "critical", "Unhandled error during server execution.", e)
        traceback.print_exc()
        sys.exit(1)
    finally:
        log_info("main", "exit", "Application has shut down.")

# --- END OF FILE main.py ---



================================================================================
📄 agents/kairo_agent.py
================================================================================

# --- START OF FILE agents/kairo_agent.py ---

# agents/kairo_agent.py
import json
from typing import Dict, List, Any

from services.llm_interface import get_instructor_client
from .tool_definitions import AVAILABLE_TOOLS, TOOL_PARAM_MODELS
from tools.logger import log_info, log_error
from services.shared_resources import get_message_templates
import tools.activity_db as db

ERROR_TEMPLATES = get_message_templates("generic_error_message") or {}
GENERIC_ERROR_MSG = ERROR_TEMPLATES.get("en", "Sorry, an error occurred.")

def _reconstruct_llm_history(history: List[Dict]) -> List[Dict]:
    """
    Formats the conversation history from our DB into the format OpenAI API expects.
    It only includes 'user' and 'assistant' text messages.
    """
    api_history = []
    for entry in history:
        role = entry.get("role")
        content = entry.get("content")
        # Ensure we only pass valid roles and non-empty content to the API
        if role in ["user", "assistant"] and content:
            api_history.append({"role": role, "content": content})
    return api_history

def handle_user_request(user_id: str, message: str, full_context: Dict, system_prompt: str) -> str:
    """Handles all incoming requests using the provided system_prompt."""
    fn_name = "handle_user_request"
    client = get_instructor_client()
    if not client: return GENERIC_ERROR_MSG

    try:
        context_for_llm = {
            "preferences": full_context.get("preferences", {}),
            "items": full_context.get("items", [])
        }
        context_json_str = json.dumps(context_for_llm, separators=(',', ':'), default=str)
        system_message = f"{system_prompt}\n\n--- CURRENT USER CONTEXT ---\n{context_json_str}"
        
        # Format the short-term conversation history for the LLM
        llm_history = _reconstruct_llm_history(full_context.get("conversation_history", []))
        
        messages_for_api = [{"role": "system", "content": system_message}]
        messages_for_api.extend(llm_history) # Add the formatted history
        
        if message:
            messages_for_api.append({"role": "user", "content": message})
            
    except Exception as e:
        log_error("kairo_agent", "prepare_context", f"Error for {user_id}", e)
        return GENERIC_ERROR_MSG

    try:
        log_info("kairo_agent", fn_name, f"Calling LLM for user {user_id}...")
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages_for_api,
            tools=[{"type": "function", "function": {"name": name, "description": model.__doc__, "parameters": model.model_json_schema()}} for name, model in TOOL_PARAM_MODELS.items()],
            tool_choice="auto",
            max_retries=1,
            temperature=0.2,
        )

        message_from_llm = response.choices[0].message

        if message_from_llm.tool_calls:
            messages_for_api.append(message_from_llm)
            for tool_call in message_from_llm.tool_calls:
                tool_name = tool_call.function.name
                tool_function = AVAILABLE_TOOLS.get(tool_name)
                if not tool_function: continue

                try:
                    param_model = TOOL_PARAM_MODELS[tool_name]
                    tool_args = param_model.model_validate_json(tool_call.function.arguments)
                    tool_result = tool_function(user_id=user_id, params=tool_args)
                    db.log_llm_activity(user_id, tool_name, tool_args.model_dump(), tool_result)
                    messages_for_api.append({"tool_call_id": tool_call.id, "role": "tool", "name": tool_name, "content": json.dumps(tool_result, default=str)})
                except Exception as e:
                    log_error("kairo_agent", fn_name, f"Error executing tool '{tool_name}'", e)
                    messages_for_api.append({"tool_call_id": tool_call.id, "role": "tool", "name": tool_name, "content": json.dumps({"error": str(e)})})
            
            final_response = client.chat.completions.create(model="gpt-4-turbo", messages=messages_for_api, temperature=0.2)
            final_response_message = final_response.choices[0].message.content
        else:
            final_response_message = message_from_llm.content

        log_info("kairo_agent", fn_name, f"Generated final response for user {user_id}.")
        return final_response_message

    except Exception as e:
        log_error("kairo_agent", fn_name, f"LLM or tool processing error for {user_id}", e)
        return GENERIC_ERROR_MSG

# --- END OF FILE agents/kairo_agent.py ---



================================================================================
📄 agents/tool_definitions.py
================================================================================

# --- START OF FILE agents/tool_definitions.py ---

# agents/tool_definitions.py
from pydantic import BaseModel, Field
from typing import Dict, Optional, List

# The tools now interact with our high-level service managers
import services.task_manager as kairo_core
import users.user_manager as user_manager

# ===================================================================
# == 1. Pydantic Models for Tool Parameters
# ===================================================================

class CreateTaskParams(BaseModel):
    """A tool to create a new task item in the user's logbook."""
    description: str = Field(..., description="The full description of the task.")
    project: Optional[str] = Field(None, description="Optional: A project tag, e.g., '#work'.")
    due_date: Optional[str] = Field(None, description="Optional: A due date in 'YYYY-MM-DD' format.")
    size: Optional[str] = Field(None, description="The estimated size of the task, e.g., 'small', 'medium', 'large'.")
    worktime: Optional[int] = Field(None, description="The estimated work time in minutes required for the task.")
    priority: Optional[int] = Field(None, description="The priority of the task, e.g., 1 (highest) to 5 (lowest).")
    urgency: Optional[int] = Field(None, description="The urgency of the task, e.g., 1 (highest) to 5 (lowest).")
    main_task_id: Optional[str] = Field(None, description="If this is a sub-task, the item_id of the main parent task.")

class CreateReminderParams(BaseModel):
    """A tool to create a new reminder item for a specific time."""
    description: str = Field(..., description="The full description of the reminder.")
    remind_at: str = Field(..., description="The specific time for the reminder in ISO 8601 UTC format.")
    duration: Optional[int] = Field(None, description="The duration of the event in minutes, for creating a calendar event.")

class UpdateItemParams(BaseModel):
    """A tool to update one or more properties of an existing task or reminder."""
    item_id: str = Field(..., description="The unique ID of the task or reminder to update.")
    updates: Dict = Field(..., description="A dictionary of fields to update, e.g., {'description': 'new text', 'status': 'completed'}.")

class UpdateUserPreferencesParams(BaseModel):
    """A tool to update the user's core preferences like name or timezone."""
    name: Optional[str] = Field(None, description="The user's preferred name.")
    timezone: Optional[str] = Field(None, description="The user's timezone, e.g., 'America/New_York'.")
    language: Optional[str] = Field(None, description="The user's language, 'en' or 'he'.")
    work_days: Optional[List[str]] = Field(None, description="A list of the user's working days, e.g., ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday']")

class FinalizeOnboardingParams(BaseModel):
    """
    A tool to be called with no parameters when the user has confirmed their initial settings.
    This action completes the setup process.
    """
    pass

# ===================================================================
# == 2. Tool Function Definitions
# ===================================================================

def create_task(user_id: str, params: CreateTaskParams) -> Dict:
    """Creates a new task item and returns its data."""
    # Pass all optional params by excluding None values
    created_item = kairo_core.create_item(user_id, "task", params.model_dump(exclude_none=True))
    if created_item.get("success"):
        return {"success": True, "item_id": created_item.get("item_id")}
    return {"success": False, "error": "Failed to create task."}

def create_reminder(user_id: str, params: CreateReminderParams) -> Dict:
    """Creates a new reminder item and returns its data."""
    created_item = kairo_core.create_item(user_id, "reminder", params.model_dump(exclude_none=True))
    if created_item.get("success"):
        return {"success": True, "item_id": created_item.get("item_id")}
    return {"success": False, "error": "Failed to create reminder."}

def update_item(user_id: str, params: UpdateItemParams) -> Dict:
    """Updates properties of an existing item and reports success."""
    updated_item = kairo_core.update_item(user_id, params.item_id, params.updates)
    if updated_item.get("success"):
        return {"success": True, "item_id": updated_item.get("item_id")}
    return {"success": False, "error": "Failed to update item."}

def update_user_preferences(user_id: str, params: UpdateUserPreferencesParams) -> Dict:
    """Updates the user's preferences and reports success."""
    updates_to_apply = params.model_dump(exclude_unset=True, exclude_none=True)
    if not updates_to_apply:
        return {"success": False, "error": "No preferences were provided to update."}
    success = user_manager.update_user_preferences(user_id, updates_to_apply)
    return {"success": success}

def finalize_onboarding(user_id: str, params: FinalizeOnboardingParams) -> Dict:
    """Sets the user's status to 'active' and reports success."""
    success = user_manager.update_user_preferences(user_id, {"status": "active"})
    return {"success": success}

# ===================================================================
# == 3. Tool Dictionaries for the Agent
# ===================================================================

AVAILABLE_TOOLS = {
    "create_task": create_task,
    "create_reminder": create_reminder,
    "update_item": update_item,
    "update_user_preferences": update_user_preferences,
    "finalize_onboarding": finalize_onboarding,
}

TOOL_PARAM_MODELS = {
    "create_task": CreateTaskParams,
    "create_reminder": CreateReminderParams,
    "update_item": UpdateItemParams,
    "update_user_preferences": UpdateUserPreferencesParams,
    "finalize_onboarding": FinalizeOnboardingParams,
}

# --- END OF FILE agents/tool_definitions.py ---



================================================================================
📄 bridge/request_router.py
================================================================================

# --- START OF FILE bridge/request_router.py ---

# bridge/request_router.py
import re
import os
import json
import threading
from typing import Dict, Any
from datetime import datetime, timezone

from tools.logger import log_info, log_error
import users.user_manager as user_manager
from agents.kairo_agent import handle_user_request
from services.cheats import handle_cheat_command
from services.shared_resources import get_message_templates, get_prompt, get_welcome_message_key

ERROR_TEMPLATES = get_message_templates("generic_error_message") or {}
GENERIC_ERROR_MSG_ROUTER = ERROR_TEMPLATES.get("en", "Sorry, an error occurred.")

_bridge_instance: Any = None
_bridge_lock = threading.Lock()

def get_bridge() -> Any:
    """Lazily initializes and returns the singleton bridge instance."""
    global _bridge_instance
    if _bridge_instance is None:
        with _bridge_lock:
            if _bridge_instance is None:
                bridge_type = os.getenv("BRIDGE_TYPE", "cli")
                log_info("request_router", "get_bridge", f"First call. Initializing bridge of type '{bridge_type}'...")
                try:
                    if bridge_type == "cli":
                        from bridge.cli_interface import CLIBridge, outgoing_cli_messages, cli_queue_lock
                        _bridge_instance = CLIBridge(outgoing_cli_messages, cli_queue_lock)
                    elif bridge_type == "whatsapp":
                        from bridge.whatsapp_interface import WhatsAppBridge, outgoing_whatsapp_messages, whatsapp_queue_lock
                        _bridge_instance = WhatsAppBridge(outgoing_whatsapp_messages, whatsapp_queue_lock)
                    elif bridge_type == "twilio":
                        from bridge.twilio_interface import TwilioBridge
                        from twilio.rest import Client as TwilioSdkClient
                        sid, token, number = os.getenv("TWILIO_ACCOUNT_SID"), os.getenv("TWILIO_AUTH_TOKEN"), os.getenv("TWILIO_WHATSAPP_NUMBER")
                        if not all([sid, token, number]): raise ValueError("Twilio credentials missing.")
                        _bridge_instance = TwilioBridge(TwilioSdkClient(sid, token), number)
                    else:
                        raise ValueError(f"Unsupported bridge type: {bridge_type}")
                    log_info("request_router", "get_bridge", f"Bridge '{type(_bridge_instance).__name__}' initialized.")
                except (ImportError, ValueError) as e:
                    log_error("request_router", "get_bridge", f"Failed to initialize bridge '{bridge_type}'", e)
    return _bridge_instance

def send_message(user_id: str, message_body: str):
    """Sends a message to a user via the configured bridge."""
    if not user_id or not message_body: return
    user_manager.add_message_to_user_history(user_id, "assistant", "agent_text_response", content=message_body)
    bridge = get_bridge()
    if bridge:
        bridge.send_message(user_id, message_body)
    else:
        log_error("request_router", "send_message", "Bridge not available.")

def normalize_user_id(user_id_from_bridge: str) -> str:
    """Removes non-digit characters from a user ID."""
    if not user_id_from_bridge: return ""
    return re.sub(r'\D', '', str(user_id_from_bridge))

def handle_incoming_message(user_id_from_bridge: str, message_text: str):
    """Main entry point for routing all incoming user messages."""
    norm_user_id = normalize_user_id(user_id_from_bridge)
    if not norm_user_id: return

    user_manager.add_message_to_user_history(norm_user_id, "user", "user_text", content=message_text)

    if message_text.strip().startswith('/'):
        parts = message_text.strip().split(); command = parts[0].lower(); args = parts[1:]
        cheat_result = handle_cheat_command(norm_user_id, command, args)
        if cheat_result.get("type") == "message":
            send_message(norm_user_id, cheat_result.get("content", "OK."))
        elif cheat_result.get("type") == "system_event":
            handle_internal_system_event({"user_id": norm_user_id, "trigger_type": cheat_result.get("trigger_type")})
        return

    agent_state = user_manager.get_agent(norm_user_id)
    agent_state['preferences']['current_utc_date'] = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    user_prefs = agent_state.get("preferences", {})
    user_status = user_prefs.get("status")
    
    if user_status == "new":
        welcome_message_key = get_welcome_message_key()
        welcome_templates = get_message_templates(welcome_message_key) or {}
        user_lang = user_prefs.get("language", "en")
        send_message(norm_user_id, welcome_templates.get(user_lang, "Hello!"))
        user_manager.update_user_preferences(norm_user_id, {"status": "onboarding"})
        return

    prompt_key = 'kairo_onboarding_system_prompt' if user_status == 'onboarding' else 'kairo_agent_system_prompt'
    system_prompt = get_prompt(prompt_key)

    if not system_prompt:
        log_error("request_router", "handle_incoming", f"Could not load system prompt for status '{user_status}'.")
        send_message(norm_user_id, GENERIC_ERROR_MSG_ROUTER)
        return

    try:
        response = handle_user_request(
            user_id=norm_user_id, message=message_text, full_context=agent_state, system_prompt=system_prompt
        )
        if response:
            send_message(norm_user_id, response)
    except Exception as e:
        log_error("request_router", "handle_incoming", f"Error from KairoAgent for {norm_user_id}", e)
        send_message(norm_user_id, GENERIC_ERROR_MSG_ROUTER)

def handle_internal_system_event(event_data: Dict):
    """Handles internally generated events like scheduled rituals."""
    user_id = event_data.get("user_id")
    trigger_type = event_data.get("trigger_type")
    if not user_id or not trigger_type: return

    agent_state = user_manager.get_agent(user_id)
    if not agent_state or agent_state.get("preferences", {}).get("status") != "active": return
    
    agent_state['preferences']['current_utc_date'] = datetime.now(timezone.utc).strftime('%Y-%m-%d')

    system_prompt = get_prompt('kairo_agent_system_prompt')
    if not system_prompt:
        log_error("request_router", "handle_internal", "Could not load main system prompt for internal event.")
        return

    try:
        trigger_as_message = json.dumps({"trigger": trigger_type})
        response = handle_user_request(
            user_id=user_id, message=trigger_as_message, full_context=agent_state, system_prompt=system_prompt
        )
        if response:
            send_message(user_id, response)
    except Exception as e:
        log_error("request_router", "handle_internal", f"Error routing internal event '{trigger_type}' for {user_id}", e)

# --- END OF FILE bridge/request_router.py ---



================================================================================
📄 services/llm_interface.py
================================================================================

# --- START OF FILE services/llm_interface.py ---

# llm_interface.py
import os
import openai
import instructor
import threading
from tools.logger import log_info, log_error

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
_client = None
_client_lock = threading.Lock()

def get_instructor_client():
    """Initializes and returns a singleton, instructor-patched OpenAI client."""
    global _client
    if not OPENAI_API_KEY:
        log_error("llm_interface", "get_instructor_client", "OPENAI_API_KEY not found in environment.")
        return None

    with _client_lock:
        if _client is None:
            try:
                log_info("llm_interface", "get_instructor_client", "Initializing instructor-patched OpenAI client...")
                # Initialize the OpenAI client
                base_client = openai.OpenAI(api_key=OPENAI_API_KEY)
                # Patch it with Instructor
                _client = instructor.patch(base_client)
                log_info("llm_interface", "get_instructor_client", "Instructor-patched OpenAI client initialized.")
            except Exception as e:
                log_error("llm_interface", "get_instructor_client", f"Failed to initialize OpenAI client: {e}", e)
                _client = None # Ensure it remains None on failure
    return _client


# --- END OF FILE services/llm_interface.py ---



================================================================================
📄 services/notification_service.py
================================================================================

# --- START OF FILE services/notification_service.py ---

# services/notification_service.py
from datetime import datetime, timezone, timedelta
from tools.logger import log_info, log_error, log_warning
from users.user_manager import get_all_user_data
from bridge.request_router import send_message
import tools.activity_db as db  # Use the database directly
import services.task_manager as task_manager # For updating the item status

NOTIFICATION_TRANSLATIONS = {
    "en": {"reminder_alert": "🔔 Reminder: {description}"},
    "he": {"reminder_alert": "🔔 תזכורת: {description}"}
}

def _get_notification_translation(lang: str, key: str) -> str:
    """Fetches a translation string for notifications."""
    return NOTIFICATION_TRANSLATIONS.get(lang, {}).get(key, "{description}")

def check_and_send_reminders():
    """
    Scheduled job that iterates through all users, checks for due reminders
    in the database, and sends notifications.
    """
    fn_name = "check_and_send_reminders"
    now_utc = datetime.now(timezone.utc)
    all_user_prefs = get_all_user_data()

    for user_id, prefs in all_user_prefs.items():
        if prefs.get("status") != "active":
            continue

        try:
            # Fetch 'new' reminders for this specific user from the database
            reminders_to_check = db.list_items_for_user(user_id, status_filter=["new"])
            
            for item in reminders_to_check:
                if item.get("type") != "reminder" or not item.get("remind_at"):
                    continue

                item_id = item.get("item_id")
                remind_at_utc = datetime.fromisoformat(item["remind_at"].replace('Z', '+00:00'))
                
                # Send notification if the reminder time is in the past or within the next minute
                if remind_at_utc <= (now_utc + timedelta(minutes=1)):
                    user_lang = prefs.get("language", "en")
                    description = item.get("description", "(No Title)")
                    
                    template = _get_notification_translation(user_lang, "reminder_alert")
                    message = template.format(description=description)
                    
                    log_info(fn_name, "notification_service", f"Sending reminder '{item_id}' to user {user_id}")
                    send_message(user_id, message)
                    
                    # Mark the reminder as complete in the database
                    task_manager.update_item(user_id, item_id, {"status": "completed"})

        except (ValueError, TypeError) as e:
            log_warning(fn_name, "notification_service", f"Could not parse date for a reminder for user {user_id}. Error: {e}")
        except Exception as e:
            log_error(fn_name, "notification_service", f"Error processing reminders for user {user_id}", e)

# --- END OF FILE services/notification_service.py ---



================================================================================
📄 services/scheduler_service.py
================================================================================

# --- START OF FILE services/scheduler_service.py ---

# services/scheduler_service.py
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.executors.pool import ThreadPoolExecutor
from apscheduler.events import EVENT_JOB_ERROR
import pytz
from datetime import datetime

from tools.logger import log_info, log_error, log_warning
# Correctly import from the new data manager
import users.user_manager as user_manager
from bridge.request_router import handle_internal_system_event

scheduler: BackgroundScheduler | None = None
ROUTINE_CHECK_INTERVAL_MINUTES = 1

def _job_listener(event):
    if event.exception:
        log_error("scheduler_service", "_job_listener", f"Job crashed: {event.job_id}", event.exception)

def _check_and_trigger_routines():
    """Scheduled job that triggers daily rituals for active users on their workdays."""
    all_users_records = user_manager.get_all_user_data()
    for user_id, user_data in all_users_records.items():
        prefs = user_data.get("preferences", {})
        if prefs.get("status") != "active": continue
        try:
            user_tz = pytz.timezone(prefs.get("timezone", "UTC"))
            now_local = datetime.now(user_tz)
            if now_local.strftime("%A") not in prefs.get("work_days", []): continue
            
            current_local_hm = now_local.strftime("%H:%M")
            today_str = now_local.strftime("%Y-%m-%d")

            if current_local_hm == prefs.get("morning_muster_time") and prefs.get("last_morning_trigger_date") != today_str:
                handle_internal_system_event({"user_id": user_id, "trigger_type": "morning_muster"})
                user_manager.update_user_preferences(user_id, {"last_morning_trigger_date": today_str})

            if current_local_hm == prefs.get("evening_reflection_time") and prefs.get("last_evening_trigger_date") != today_str:
                handle_internal_system_event({"user_id": user_id, "trigger_type": "evening_reflection"})
                user_manager.update_user_preferences(user_id, {"last_evening_trigger_date": today_str})
        except Exception as e:
            log_error("scheduler_service", "_check_routines", f"Error processing routines for user {user_id}", e)

def _check_and_send_reminders():
    """Scheduled job to check for and send time-based reminders."""
    try:
        from services.notification_service import check_and_send_reminders as send_reminders_func
        send_reminders_func()
    except ImportError:
        log_warning("scheduler_service", "_check_reminders", "Could not import notification_service.")
    except Exception as e:
        log_error("scheduler_service", "_check_reminders", "Error during reminder check", e)

def start_scheduler() -> bool:
    """Initializes and starts the background scheduler with all required jobs."""
    global scheduler
    if scheduler and scheduler.running: return True
    try:
        scheduler = BackgroundScheduler(timezone="UTC")
        scheduler.add_job(_check_and_trigger_routines, 'interval', minutes=ROUTINE_CHECK_INTERVAL_MINUTES, id='kairo_ritual_check')
        scheduler.add_job(_check_and_send_reminders, 'interval', minutes=ROUTINE_CHECK_INTERVAL_MINUTES, id='kairo_reminder_check')
        scheduler.add_listener(_job_listener, EVENT_JOB_ERROR)
        scheduler.start()
        log_info("scheduler_service", "start", "Scheduler started successfully.")
        return True
    except Exception as e:
        log_error("scheduler_service", "start", "Failed to start APScheduler", e)
        return False

def shutdown_scheduler():
    if scheduler and scheduler.running:
        scheduler.shutdown(wait=False)

# --- END OF FILE services/scheduler_service.py ---



================================================================================
📄 services/task_manager.py
================================================================================

# --- START OF FILE services/task_manager.py ---

# services/task_manager.py
import uuid
from datetime import datetime, timezone
from typing import Dict

import tools.activity_db as db
from tools.logger import log_info

def create_item(user_id: str, item_type: str, item_params: Dict) -> Dict:
    """Creates a new task or reminder in the database."""
    now_iso = datetime.now(timezone.utc).isoformat()
    # The 'description' is a required field for the DB, ensure it has a default
    if 'description' not in item_params:
        item_params['description'] = 'No description'
        
    new_item_data = {
        "item_id": str(uuid.uuid4()),
        "user_id": user_id,
        "type": item_type,
        "status": "new",
        "created_at": now_iso,
        "updated_at": now_iso,
        **item_params
    }
    
    success = db.add_or_update_item(new_item_data)
    if success:
        log_info("task_manager", "create_item", f"Created {item_type} '{new_item_data['item_id']}' for {user_id}.")
        return {"success": True, "item_id": new_item_data["item_id"]}
    else:
        return {"success": False, "error": f"Failed to create {item_type}."}

def update_item(user_id: str, item_id: str, updates: Dict) -> Dict:
    """Updates an existing item in the database."""
    existing_item = db.get_item(item_id)
    if not existing_item or existing_item.get("user_id") != user_id:
        return {"success": False, "error": "Item not found."}
    
    # --- START OF THE FINAL FIX ---
    # Merge the original item's data with the new updates.
    # This ensures all NOT NULL fields (like 'type', 'description') are preserved.
    final_payload = {
        **existing_item,
        **updates,
        "updated_at": datetime.now(timezone.utc).isoformat()
    }
    # --- END OF THE FINAL FIX ---
    
    success = db.add_or_update_item(final_payload)
    if success:
        log_info("task_manager", "update_item", f"Updated item '{item_id}' for user {user_id}.")
        return {"success": True, "item_id": item_id}
    else:
        return {"success": False, "error": "Failed to update item."}

# --- END OF FILE services/task_manager.py ---



================================================================================
📄 services/cheats.py
================================================================================

# --- START OF FILE services/cheats.py ---

# services/cheats.py
import json
from typing import List, Dict, Any

import users.user_manager as user_manager
from tools.logger import log_info

def _handle_help() -> Dict:
    """Displays the available cheat commands."""
    return {"type": "message", "content": """Available Kairo Cheat Commands:
/help - Show this help message
/list [status] - List your items (status: active, new, in_progress, completed, deleted, all).
/memory - Show a summary of your current in-memory agent state.
/clear - !! DANGER !! Mark all non-deleted items as 'deleted'.
/morning - Manually trigger your Morning Muster.
/evening - Manually trigger your Evening Reflection."""}

def _handle_list(user_id: str, args: List[str]) -> Dict:
    """Lists items from the user's current agent state."""
    agent_state = user_manager.get_agent(user_id)
    if not agent_state or "items" not in agent_state:
        return {"type": "message", "content": "Error: Could not retrieve your items."}

    all_items = agent_state.get("items", [])
    status_filter = args[0].lower() if args else 'active'
    active_statuses = {"new", "in_progress"}
    
    if status_filter == 'all':
        filtered_items = all_items
    elif status_filter == 'active':
        filtered_items = [item for item in all_items if item.get('status') in active_statuses]
    else:
        filtered_items = [item for item in all_items if item.get('status') == status_filter]

    if not filtered_items:
        return {"type": "message", "content": f"No items found with status '{status_filter}'."}

    lines = [f"Items with status '{status_filter}':", "---"]
    for item in filtered_items:
        desc = item.get('description', '(No Description)')
        item_type = item.get('type', 'item')
        lines.append(f"({item_type}) {desc}")
    return {"type": "message", "content": "\n".join(lines)}

def _handle_memory(user_id: str) -> Dict:
    """Shows a summary of the agent's in-memory state."""
    agent_state = user_manager.get_agent(user_id)
    if not agent_state:
        return {"type": "message", "content": "Error: Agent state not found."}
        
    state_summary = {k: v for k, v in agent_state.items() if k != "conversation_history"}
    state_summary["history_count"] = len(agent_state.get("conversation_history", []))
    return {"type": "message", "content": f"Agent Memory Summary:\n```json\n{json.dumps(state_summary, indent=2, default=str)}\n```"}

def _handle_clear(user_id: str) -> Dict:
    """Marks all non-deleted items as 'deleted'."""
    from services.task_manager import update_item # Local import to avoid loops
    agent_state = user_manager.get_agent(user_id)
    if not agent_state: return {"type": "message", "content": "Error: Could not find user to clear items."}
        
    cleared_count = 0
    for item in agent_state.get("items", []):
        if item.get("status") != "deleted" and item.get("item_id"):
            update_item(user_id, item["item_id"], {"status": "deleted"})
            cleared_count += 1
    return {"type": "message", "content": f"Marked {cleared_count} item(s) as 'deleted'."}

def _handle_routines(routine_type: str) -> Dict:
    """Returns a special dictionary instructing the router to trigger a system event."""
    log_info("cheats", "_handle_routines", f"Cheat command is requesting a '{routine_type}' trigger.")
    return {"type": "system_event", "trigger_type": routine_type}

def handle_cheat_command(user_id: str, command: str, args: List[str]) -> Dict[str, Any]:
    """Main router for all cheat commands. Returns a dictionary specifying the action."""
    command_map = {
        "/help": _handle_help,
        "/list": lambda: _handle_list(user_id, args),
        "/memory": lambda: _handle_memory(user_id),
        "/clear": lambda: _handle_clear(user_id),
        "/morning": lambda: _handle_routines("morning_muster"),
        "/evening": lambda: _handle_routines("evening_reflection")
    }
    handler = command_map.get(command.lower())
    return handler() if handler else {"type": "message", "content": f"Unknown command: '{command}'. Try /help."}

# --- END OF FILE services/cheats.py ---



================================================================================
📄 services/shared_resources.py
================================================================================

# --- START OF FILE services/shared_resources.py ---

# services/shared_resources.py
import yaml
import os
from tools.logger import log_error, log_info

_PROMPTS = {}
_MESSAGES = {}
_PROJECT_SETTINGS = {}

def load_resources():
    """Loads all YAML files into memory."""
    global _PROMPTS, _MESSAGES, _PROJECT_SETTINGS
    
    try:
        with open("config/prompts.yaml", 'r', encoding="utf-8") as f:
            _PROMPTS = yaml.safe_load(f) or {}
    except Exception as e:
        log_error("shared_resources", "load_resources", f"Failed to load prompts.yaml: {e}")

    try:
        with open("config/messages.yaml", 'r', encoding="utf-8") as f:
            _MESSAGES = yaml.safe_load(f) or {}
    except Exception as e:
        log_error("shared_resources", "load_resources", f"Failed to load messages.yaml: {e}")

    try:
        with open("config/settings.yaml", 'r', encoding="utf-8") as f:
            _PROJECT_SETTINGS = yaml.safe_load(f) or {}
    except Exception as e:
        log_error("shared_resources", "load_resources", f"Failed to load settings.yaml: {e}")
        
    log_info("shared_resources", "load_resources", "Shared prompts, messages, and settings have been loaded.")

def get_prompt(key: str) -> str | None:
    return _PROMPTS.get(key)

def get_message_templates(key: str) -> dict | None:
    return _MESSAGES.get(key)

# --- START OF REFACTORED LOGIC ---

def _get_current_project_config() -> dict:
    """Internal helper to get the full config block for the current project."""
    project_name = os.getenv("PROJECT_NAME", "kairo")
    log_info("shared_resources", "get_project_config", f"Loading config for project: {project_name}.")
    
    project_configs = _PROJECT_SETTINGS.get("projects", {})
    # Return the specific project config, or fall back to the default config block
    return project_configs.get(project_name, _PROJECT_SETTINGS.get("default_config", {}))

def get_default_preferences() -> dict:
    """Gets the default_preferences dictionary for the current project."""
    config = _get_current_project_config()
    preferences = config.get("default_preferences", {})
    if not preferences:
        log_error("shared_resources", "get_defaults", "CRITICAL: Could not find 'default_preferences' in config for current project.")
        # Return a hardcoded safe fallback
        return {"name": None, "timezone": None, "language": "en", "status": "new"}
    return preferences

def get_welcome_message_key() -> str:
    """Gets the welcome_message_key for the current project."""
    config = _get_current_project_config()
    # Fall back to the standard key if not found
    return config.get("welcome_message_key", "initial_welcome_message")

# --- END OF REFACTORED LOGIC ---

load_resources()

# --- END OF FILE services/shared_resources.py ---



================================================================================
📄 tools/activity_db.py
================================================================================

# --- START OF FILE tools/activity_db.py ---

# tools/activity_db.py
import sqlite3
import os
import json
import threading
from datetime import datetime, timezone
from typing import Dict, List, Any

from tools.logger import log_info, log_error

# --- Configuration ---
DATA_SUFFIX = os.getenv("DATA_SUFFIX", "")
DB_DIR = "data"
DB_FILE = os.path.join(DB_DIR, f"kairo_activity{DATA_SUFFIX}.db")
DB_LOCK = threading.Lock()


# --- Database Initialization & Migration ---
def init_db():
    """Initializes the database and runs a safe migration to add new columns if they don't exist."""
    os.makedirs(DB_DIR, exist_ok=True)
    with DB_LOCK, sqlite3.connect(DB_FILE, check_same_thread=False, timeout=10) as conn:
        cursor = conn.cursor()
        
        # 1. Create the table with the full, final schema. This works for new databases.
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS users_tasks (
            item_id TEXT PRIMARY KEY NOT NULL,
            user_id TEXT NOT NULL,
            type TEXT NOT NULL CHECK(type IN ('task', 'reminder')),
            status TEXT NOT NULL CHECK(status IN ('new', 'in_progress', 'completed', 'deleted')),
            description TEXT NOT NULL,
            project TEXT,
            due_date TEXT,
            remind_at TEXT,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            size TEXT,
            worktime INTEGER,
            priority INTEGER,
            urgency INTEGER,
            main_task_id TEXT,
            duration INTEGER,
            calendar_id TEXT
        )""")
        
        # 2. --- MIGRATION LOGIC ---
        # This handles existing databases by adding columns one by one if they are missing.
        log_info("activity_db", "migration_check", "Checking for database schema updates...")
        cursor.execute("PRAGMA table_info(users_tasks)")
        existing_columns = [row[1] for row in cursor.fetchall()]
        
        columns_to_add = {
            "size": "TEXT",
            "worktime": "INTEGER",
            "priority": "INTEGER",
            "urgency": "INTEGER",
            "main_task_id": "TEXT",
            "duration": "INTEGER",
            "calendar_id": "TEXT"
        }
        
        for col_name, col_type in columns_to_add.items():
            if col_name not in existing_columns:
                try:
                    cursor.execute(f"ALTER TABLE users_tasks ADD COLUMN {col_name} {col_type}")
                    log_info("activity_db", "migration_apply", f"Added missing column '{col_name}' to users_tasks table.")
                except sqlite3.Error as e:
                    log_error("activity_db", "migration_apply", f"Failed to add column '{col_name}': {e}")
        # --- END OF MIGRATION LOGIC ---

        # The other tables are for logging and don't need migration in this case.
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT NOT NULL, user_id TEXT NOT NULL,
            role TEXT NOT NULL, message_type TEXT NOT NULL, content TEXT
        )""")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_messages_user_id_ts ON messages (user_id, timestamp)")
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS llm_activity (
            id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT NOT NULL, user_id TEXT NOT NULL,
            tool_name TEXT NOT NULL, tool_args_json TEXT NOT NULL, tool_result_json TEXT NOT NULL
        )""")
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS system_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT NOT NULL, level TEXT NOT NULL,
            module TEXT NOT NULL, function TEXT NOT NULL, message TEXT NOT NULL, traceback TEXT
        )""")
        
        conn.commit()
    log_info("activity_db", "init_db", f"Database initialized and schema verified at {DB_FILE}")

def _dict_factory(cursor, row):
    fields = [column[0] for column in cursor.description]
    return {key: value for key, value in zip(fields, row)}

# --- Core Item Functions (Tasks/Reminders) ---
def add_or_update_item(item_data: Dict) -> bool:
    item_id = item_data.get("item_id")
    if not item_id: return False
    
    columns = list(item_data.keys())
    placeholders = ', '.join('?' * len(columns))
    update_setters = ', '.join([f"{col} = excluded.{col}" for col in columns if col != 'item_id'])
    
    sql = f"""
        INSERT INTO users_tasks ({', '.join(columns)})
        VALUES ({placeholders})
        ON CONFLICT(item_id) DO UPDATE SET {update_setters}
    """
    params = list(item_data.values())
    
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE) as conn:
            conn.execute(sql, params)
            conn.commit()
        return True
    except sqlite3.Error as e:
        log_error("activity_db", "add_or_update_item", f"DB error for item {item_id}", e)
        return False

def get_item(item_id: str) -> Dict | None:
    try:
        with sqlite3.connect(DB_FILE) as conn:
            conn.row_factory = _dict_factory
            return conn.execute("SELECT * FROM users_tasks WHERE item_id = ?", (item_id,)).fetchone()
    except sqlite3.Error as e:
        log_error("activity_db", "get_item", f"DB error getting item {item_id}", e)
        return None

def list_items_for_user(user_id: str, status_filter: List[str] | None = None) -> List[Dict]:
    sql = "SELECT * FROM users_tasks WHERE user_id = ?"
    params: List[Any] = [user_id]
    if status_filter:
        placeholders = ','.join('?' * len(status_filter))
        sql += f" AND status IN ({placeholders})"
        params.extend(status_filter)
    sql += " ORDER BY created_at DESC"
    try:
        with sqlite3.connect(DB_FILE) as conn:
            conn.row_factory = _dict_factory
            return conn.execute(sql, params).fetchall()
    except sqlite3.Error as e:
        log_error("activity_db", "list_items_for_user", f"DB error for {user_id}", e)
        return []

def list_messages_for_user(user_id: str, limit: int = 10) -> List[Dict]:
    sql = "SELECT role, content FROM messages WHERE user_id = ? ORDER BY timestamp DESC LIMIT ?"
    params = [user_id, limit]
    messages = []
    try:
        with sqlite3.connect(DB_FILE) as conn:
            conn.row_factory = _dict_factory
            messages = conn.execute(sql, params).fetchall()
        return messages[::-1]
    except sqlite3.Error as e:
        log_error("activity_db", "list_messages_for_user", f"DB error for {user_id}", e)
        return []

# --- Logging Functions ---
def log_message(user_id: str, role: str, message_type: str, content: str):
    ts = datetime.now(timezone.utc).isoformat()
    sql = "INSERT INTO messages (timestamp, user_id, role, message_type, content) VALUES (?, ?, ?, ?, ?)"
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE) as conn:
            conn.execute(sql, (ts, user_id, role, message_type, content))
            conn.commit()
    except sqlite3.Error as e:
        log_error("activity_db", "log_message", f"DB error logging message for {user_id}", e)

def log_llm_activity(user_id: str, tool_name: str, tool_args: Dict, tool_result: Dict):
    ts = datetime.now(timezone.utc).isoformat()
    sql = "INSERT INTO llm_activity (timestamp, user_id, tool_name, tool_args_json, tool_result_json) VALUES (?, ?, ?, ?, ?)"
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE) as conn:
            conn.execute(sql, (ts, user_id, tool_name, json.dumps(tool_args), json.dumps(tool_result)))
            conn.commit()
    except sqlite3.Error as e:
        log_error("activity_db", "log_llm_activity", f"DB error logging LLM activity for {user_id}", e)

def log_system_event(level: str, module: str, function: str, message: str, traceback_str: str | None = None, timestamp: str | None = None):
    sql = "INSERT INTO system_logs (timestamp, level, module, function, message, traceback) VALUES (?, ?, ?, ?, ?, ?)"
    ts = timestamp or datetime.now(timezone.utc).isoformat()
    params = (ts, level.upper(), module, function, message, traceback_str)
    try:
        with DB_LOCK, sqlite3.connect(DB_FILE, check_same_thread=False, timeout=10) as conn:
            conn.execute(sql, params)
            conn.commit()
    except sqlite3.Error as e:
        print(f"CRITICAL DB LOGGING FAILED: {ts} [{level.upper()}] {module}:{function} - {message}\n{e}")

# --- END OF FILE tools/activity_db.py ---



================================================================================
📄 users/user_manager.py
================================================================================

# --- START OF FILE users/user_manager.py ---

# users/user_manager.py
import json
import os
import threading
from typing import Dict, Any, List
from tools.logger import log_info, log_error
import tools.activity_db as db
from services.shared_resources import get_default_preferences # Import the new, direct function

# --- Configuration ---
USER_DATA_PATH = os.path.join("data", f"kairo_users{os.getenv('DATA_SUFFIX', '')}.json")
_user_prefs_store: Dict[str, Dict[str, Any]] = {}
_prefs_lock = threading.Lock()

# --- START OF SIMPLIFIED LOGIC ---
# Directly get the correct default preferences for the current project.
DEFAULT_PREFERENCES = get_default_preferences()
if not DEFAULT_PREFERENCES:
    log_error("user_manager", "init", "CRITICAL: Could not load default preferences from settings.yaml.")
    DEFAULT_PREFERENCES = {"name": None, "timezone": None, "language": "en", "status": "new"}

# --- Preference Management Functions ---
def _load_user_preferences():
    global _user_prefs_store
    try:
        os.makedirs(os.path.dirname(USER_DATA_PATH), exist_ok=True)
        if os.path.exists(USER_DATA_PATH):
            with open(USER_DATA_PATH, "r", encoding="utf-8") as f:
                content = f.read()
                full_data = json.loads(content) if content.strip() else {}
                for user_id, data in full_data.items():
                    if "preferences" in data:
                        _user_prefs_store[user_id] = data["preferences"]
        else:
            _user_prefs_store = {}
        log_info("user_manager", "load_prefs", f"Loaded preferences for {len(_user_prefs_store)} users.")
    except Exception as e:
        log_error("user_manager", "load_prefs", "Failed to load preferences file", e)
        _user_prefs_store = {}

def _save_user_preferences():
    data_to_save = {user_id: {"preferences": prefs} for user_id, prefs in _user_prefs_store.items()}
    try:
        temp_path = USER_DATA_PATH + ".tmp"
        with open(temp_path, "w", encoding="utf-8") as f:
            json.dump(data_to_save, f, indent=2, ensure_ascii=False)
        os.replace(temp_path, USER_DATA_PATH)
    except Exception as e:
        log_error("user_manager", "save_prefs", "Failed to write preferences to file", e)

# --- Public API for Application ---
def init_all_agents():
    _load_user_preferences()

def get_agent(user_id: str) -> Dict[str, Any]:
    with _prefs_lock:
        if user_id not in _user_prefs_store:
            log_info("user_manager", "get_agent", f"Creating new user preferences for {user_id}")
            _user_prefs_store[user_id] = DEFAULT_PREFERENCES.copy()
            _save_user_preferences()
        preferences = _user_prefs_store.get(user_id, DEFAULT_PREFERENCES.copy())
    active_items = db.list_items_for_user(user_id, status_filter=["new", "in_progress"])
    conversation_history = db.list_messages_for_user(user_id, limit=10)
    return {
        "user_id": user_id, "preferences": preferences, "items": active_items, "conversation_history": conversation_history 
    }

def get_all_user_data() -> Dict[str, Dict[str, Any]]:
    with _prefs_lock:
        return json.loads(json.dumps(_user_prefs_store))

def add_message_to_user_history(user_id: str, role: str, message_type: str, content: str | None = None, **kwargs):
    db.log_message(user_id=user_id, role=role, message_type=message_type, content=content)

def update_user_preferences(user_id: str, updates: Dict) -> bool:
    with _prefs_lock:
        if user_id not in _user_prefs_store:
            _user_prefs_store[user_id] = DEFAULT_PREFERENCES.copy()
        _user_prefs_store[user_id].update(updates)
        _save_user_preferences()
    return True

# --- END OF FILE users/user_manager.py ---



================================================================================
📄 bridge/cli_interface.py
================================================================================

# --- START OF FILE bridge/cli_interface.py ---

# bridge/cli_interface.py
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import uuid
from threading import Lock
import json

from tools.logger import log_info, log_error, log_warning

# Optional calendar tool import
try:
    from tools.calendar_tool import router as calendar_router
    CALENDAR_ROUTER_IMPORTED = True
except ImportError:
    CALENDAR_ROUTER_IMPORTED = False
    from fastapi import APIRouter
    calendar_router = APIRouter()

# Global in-memory store for CLI outgoing messages
outgoing_cli_messages = []
cli_queue_lock = Lock()

class CLIBridge:
    """Bridge that handles message queuing for CLI interaction."""
    def __init__(self, message_queue, lock):
        self.message_queue = message_queue
        self.lock = lock
        log_info("CLIBridge", "__init__", "CLI Bridge initialized for queuing.")

    def send_message(self, user_id: str, message: str):
        if not user_id or not message:
             log_warning("CLIBridge", "send_message", "Attempted to queue empty message or invalid user_id.")
             return
        outgoing = {"user_id": user_id, "message": message, "message_id": str(uuid.uuid4())}
        with self.lock:
            self.message_queue.append(outgoing)
        log_info("CLIBridge", "send_message", f"Message for CLI user {user_id} queued. Queue size: {len(self.message_queue)}")

async def process_incoming_cli_message_background(user_id: str, message: str):
    """Runs the message handler in the background."""
    try:
        from bridge.request_router import handle_incoming_message
        handle_incoming_message(user_id, message)
    except Exception as e:
        log_error("cli_interface", "background_task", f"Unhandled exception in CLI background processing for {user_id}", e)

def create_cli_app() -> FastAPI:
    """Creates the FastAPI app instance for the CLI Interface."""
    app = FastAPI(
        title="Kairo CLI Bridge API",
        description="Handles interaction for the CLI mock sender.",
        version="1.0.0"
    )

    if CALENDAR_ROUTER_IMPORTED:
        app.include_router(calendar_router, prefix="", tags=["Authentication"])

    @app.post("/incoming", tags=["CLI Bridge"])
    async def incoming_cli_message(request: Request, background_tasks: BackgroundTasks):
        """Receives message from CLI mock, acknowledges, and processes in the background."""
        endpoint_name = "incoming_cli_message"
        try:
            data = await request.json()
            user_id = data.get("user_id")
            message = data.get("message")
            if not user_id or message is None:
                raise HTTPException(status_code=400, detail="Missing user_id or message")
            background_tasks.add_task(process_incoming_cli_message_background, user_id, str(message))
            log_info("cli_interface", endpoint_name, f"ACK for incoming from {user_id}. Processing in background.")
            return JSONResponse(content={"ack": True})
        except Exception as e:
            log_error("cli_interface", endpoint_name, "Error processing incoming CLI message", e)
            raise HTTPException(status_code=500, detail="Internal server error")

    # --- START OF FIX: Implement robust ACK mechanism ---
    @app.get("/outgoing", tags=["CLI Bridge"])
    async def get_outgoing_cli_messages():
        """
        Returns a COPY of the outgoing message queue.
        It NO LONGER clears the queue. Deletion is handled by /ack.
        """
        with cli_queue_lock:
            # Return a copy of the list, but leave the original intact
            msgs_to_send = outgoing_cli_messages[:]
        return JSONResponse(content={"messages": msgs_to_send})

    @app.post("/ack", tags=["CLI Bridge"])
    async def acknowledge_cli_message(request: Request):
        """
        Receives acknowledgment and REMOVES the message from the queue.
        This is now the only way messages are deleted.
        """
        endpoint_name = "acknowledge_cli_message"
        removed = False
        message_id = None
        try:
            data = await request.json()
            message_id = data.get("message_id")
            if not message_id:
                raise HTTPException(status_code=400, detail="Missing message_id in ACK")

            with cli_queue_lock:
                # Find the message by ID and remove it
                initial_len = len(outgoing_cli_messages)
                # Create a new list excluding the acknowledged message
                outgoing_cli_messages[:] = [msg for msg in outgoing_cli_messages if msg.get("message_id") != message_id]
                final_len = len(outgoing_cli_messages)
                removed = (initial_len != final_len)
            
            if removed:
                log_info(endpoint_name, "ack", f"ACK received and message removed for ID: {message_id}. Queue size: {len(outgoing_cli_messages)}")
            else:
                log_warning(endpoint_name, "ack", f"ACK received for unknown/already removed message ID: {message_id}")

            return JSONResponse(content={"ack_received": True, "removed": removed})
        except Exception as e:
            log_error(endpoint_name, "ack", f"Error processing ACK for message ID {message_id or 'N/A'}", e)
            raise HTTPException(status_code=500, detail="Internal server error processing ACK")
    # --- END OF FIX ---

    return app

app = create_cli_app()

# --- END OF FILE bridge/cli_interface.py ---



================================================================================
📄 bridge/twilio_interface.py
================================================================================

# --- START OF FILE bridge/twilio_interface.py ---

# bridge/twilio_interface.py
from fastapi import FastAPI, Request, HTTPException, Form, BackgroundTasks
from fastapi.responses import Response as FastAPIResponse
from twilio.request_validator import RequestValidator
from twilio.rest import Client as TwilioClient
import os

from tools.logger import log_info, log_error, log_warning
# --- START OF FIX: Removed 'set_bridge' from the import ---
from bridge.request_router import handle_incoming_message
# --- END OF FIX ---

TWILIO_AUTH_TOKEN = os.getenv("TWILIO_AUTH_TOKEN")
twilio_validator = RequestValidator(TWILIO_AUTH_TOKEN) if TWILIO_AUTH_TOKEN else None

class TwilioBridge:
    """Bridge for Twilio WhatsApp interactions."""
    def __init__(self, client: TwilioClient, twilio_sender_number: str):
        self.client = client
        self.twilio_sender_number = twilio_sender_number
        log_info("TwilioBridge", "__init__", "Twilio Bridge instance initialized.")

    def send_message(self, user_id: str, message_body: str):
        if not self.client or not self.twilio_sender_number:
            log_error("twilio_interface", "send", "Twilio client or sender number not configured.")
            return
        twilio_recipient_id = f"whatsapp:+{user_id}"
        try:
            message_instance = self.client.messages.create(from_=self.twilio_sender_number, body=message_body, to=twilio_recipient_id)
            log_info("twilio_interface", "send", f"Twilio message sent. SID: {message_instance.sid}")
        except Exception as e:
            log_error("twilio_interface", "send", f"Error sending Twilio message to {twilio_recipient_id}", e)

async def process_incoming_twilio_message_background(user_id: str, message: str):
    """Runs the message handler in the background."""
    try:
        handle_incoming_message(user_id, message)
    except Exception as e:
        log_error("twilio_interface", "background_task", f"Exception in background processing for {user_id}", e)

def create_twilio_app() -> FastAPI:
    app_instance = FastAPI(title="Kairo Twilio Bridge API", version="1.0.0")
    # Optional calendar router import can be added here if needed

    @app_instance.post("/twilio/incoming", tags=["Twilio Bridge"])
    async def incoming_twilio_message(request: Request, background_tasks: BackgroundTasks, From: str = Form(...), Body: str = Form(...)):
        # Optional signature validation
        if twilio_validator:
            # (Validation logic would go here)
            pass
        
        background_tasks.add_task(process_incoming_twilio_message_background, From, Body)
        log_info("twilio_interface", "incoming", f"ACK for Twilio from {From}. Processing in background.")
        return FastAPIResponse(content="<Response/>", media_type="application/xml")
    
    return app_instance

app = create_twilio_app()

# --- END OF FILE bridge/twilio_interface.py ---



================================================================================
📄 bridge/whatsapp_interface.py
================================================================================

# --- START OF FILE bridge/whatsapp_interface.py ---

# bridge/whatsapp_interface.py
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import uuid
from threading import Lock
import json
import re

from tools.logger import log_info, log_error, log_warning
# --- START OF FIX: Removed 'set_bridge' from the import ---
from bridge.request_router import handle_incoming_message
# --- END OF FIX ---

try:
    from tools.calendar_tool import router as calendar_router
    CALENDAR_ROUTER_IMPORTED = True
except ImportError:
    CALENDAR_ROUTER_IMPORTED = False
    from fastapi import APIRouter
    calendar_router = APIRouter()

# --- Bridge Definition ---
outgoing_whatsapp_messages = []
whatsapp_queue_lock = Lock()

class WhatsAppBridge:
    def __init__(self, message_queue, lock):
        self.message_queue = message_queue
        self.lock = lock
        log_info("WhatsAppBridge", "__init__", "WhatsApp Bridge initialized for queuing.")

    def send_message(self, user_id: str, message: str):
        if not user_id or not message:
             log_warning("WhatsAppBridge", "send_message", "Attempted to queue empty message or invalid user_id.")
             return
        formatted_user_id = f"{user_id}@c.us" if re.match(r'^\d+$', user_id) else user_id
        outgoing = {"user_id": formatted_user_id, "message": message, "message_id": str(uuid.uuid4())}
        with self.lock:
            self.message_queue.append(outgoing)
        log_info("WhatsAppBridge", "send_message", f"Message queued for {formatted_user_id}. Queue size: {len(self.message_queue)}")

async def process_incoming_message_background(user_id: str, message: str):
    """Runs the message handler in the background."""
    try:
        handle_incoming_message(user_id, message)
    except Exception as e:
        log_error("whatsapp_interface", "background_task", f"Exception in background processing for {user_id}", e)

def create_whatsapp_app() -> FastAPI:
    app = FastAPI(title="Kairo WhatsApp Bridge API", version="1.0.0")
    if CALENDAR_ROUTER_IMPORTED:
        app.include_router(calendar_router, prefix="", tags=["Authentication"])

    @app.post("/incoming", tags=["WhatsApp Bridge"])
    async def incoming_whatsapp_message(request: Request, background_tasks: BackgroundTasks):
        data = await request.json()
        user_id, message_body = data.get("user_id"), data.get("message")
        if not user_id or message_body is None:
            raise HTTPException(status_code=400, detail="Missing user_id or message")
        background_tasks.add_task(process_incoming_message_background, user_id, str(message_body))
        log_info("whatsapp_interface", "incoming", f"ACK for incoming from {user_id}. Processing in background.")
        return JSONResponse(content={"ack": True})

    @app.get("/outgoing", tags=["WhatsApp Bridge"])
    async def get_outgoing_whatsapp_messages():
        with whatsapp_queue_lock:
            return JSONResponse(content={"messages": outgoing_whatsapp_messages[:]})

    @app.post("/ack", tags=["WhatsApp Bridge"])
    async def acknowledge_whatsapp_message(request: Request):
        data = await request.json()
        message_id = data.get("message_id")
        if not message_id:
            raise HTTPException(status_code=400, detail="Missing message_id")
        removed = False
        with whatsapp_queue_lock:
            initial_len = len(outgoing_whatsapp_messages)
            outgoing_whatsapp_messages[:] = [msg for msg in outgoing_whatsapp_messages if msg.get("message_id") != message_id]
            if len(outgoing_whatsapp_messages) != initial_len:
                removed = True
                log_info("whatsapp_interface", "ack", f"ACK received and message removed for ID: {message_id}")
        return JSONResponse(content={"ack_received": True, "removed": removed})

    return app

app = create_whatsapp_app()

# --- END OF FILE bridge/whatsapp_interface.py ---



================================================================================
📄 WA/wa_bridge.js
================================================================================

# --- START OF FILE WA/wa_bridge.js ---

// wa_bridge.js

// --- Dependencies ---
const { Client, LocalAuth } = require('whatsapp-web.js');
const qrcode = require('qrcode-terminal');
const axios = require('axios');
const winston = require('winston');

// --- Configuration ---
const FASTAPI_BASE_URL = process.env.FASTAPI_BASE_URL || 'http://localhost:8001';
const FAST_POLLING_INTERVAL_MS = 1500; // Poll quickly when connected
const SLOW_POLLING_INTERVAL_MS = 10000; // Poll slowly when backend is down
const MAX_SEND_RETRIES = 3;
const SEND_RETRY_DELAY_MS = 2000;
const MAX_ACK_RETRIES = 3;
const ACK_RETRY_DELAY_MS = 3000;
const FAILED_ACK_QUARANTINE_CLEAR_MS = 3600000; // 1 hour
const RESTART_INTERVAL_MS = 21600000; // Periodically restart every 6 hours

// --- Winston Logger ---
const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.printf(({ timestamp, level, message }) => `${timestamp} [${level.toUpperCase()}] [wa_bridge] ${message}`)
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'logs/kairo_wa_bridge_error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/kairo_wa_bridge_combined.log' }),
  ],
});

// --- State Variables ---
let isClientReady = false;
let clientInstance;
let _stopPollingFlag = false;
const failedAckStore = new Set();
let isBackendConnected = true; // Assume backend is up at the start

// Periodically clear the ACK quarantine to give messages another chance
setInterval(() => {
    if (failedAckStore.size > 0) {
        logger.info(`Clearing ACK failure quarantine. ${failedAckStore.size} items are now retryable.`);
        failedAckStore.clear();
    }
}, FAILED_ACK_QUARANTINE_CLEAR_MS);

// Periodically restart the script for long-term stability
setTimeout(() => {
    logger.warn('Initiating scheduled periodic restart for stability.');
    shutdownBridge('PERIODIC_RESTART');
}, RESTART_INTERVAL_MS);


// --- Utility: Sleep Function ---
function sleep(ms) { return new Promise(resolve => setTimeout(resolve, ms)); }

// --- Initialize the WhatsApp client ---
const client = new Client({
    authStrategy: new LocalAuth({ dataPath: '.wwebjs_auth' }),
    puppeteer: {
        headless: true,
        args: ['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
    }
});
clientInstance = client;

// --- Event Handlers ---
client.on('qr', qr => { qrcode.generate(qr, { small: true }); });
client.on('ready', () => {
    logger.info('WhatsApp client is ready!');
    isClientReady = true;
    pollForOutgoingMessages();
});
client.on('auth_failure', msg => {
    logger.error(`AUTHENTICATION FAILURE: ${msg}. Shutting down.`);
    shutdownBridge('AUTH_FAILURE', 1);
});
client.on('disconnected', reason => {
    logger.error(`Client disconnected: ${reason}. Shutting down.`);
    shutdownBridge('DISCONNECTED', 1);
});
client.on('error', err => {
    logger.error(`Unhandled WhatsApp client error: ${err.message}`);
});

client.on('message', async (message) => {
    const chat = await message.getChat();
    if (message.isStatus || chat.isGroup) return; // Ignore status updates and group chats

    logger.info(`Received message from ${message.from}: "${message.body.substring(0, 50)}..."`);
    try {
        await axios.post(`${FASTAPI_BASE_URL}/incoming`, {
            user_id: message.from,
            message: message.body
        }, { timeout: 10000 });
    } catch (error) {
        logger.error(`Failed to send incoming message to backend: ${error.message}`);
    }
});

// --- Main Polling Function ---
async function pollForOutgoingMessages() {
    if (_stopPollingFlag) return;
    if (!isClientReady) {
        setTimeout(pollForOutgoingMessages, 5000); // Wait if client isn't ready
        return;
    }

    try {
        const response = await axios.get(`${FASTAPI_BASE_URL}/outgoing`, { timeout: 5000 });
        
        if (!isBackendConnected) {
            logger.info('Connection to Kairo backend RESTORED. Resuming normal polling.');
            isBackendConnected = true;
        }

        const messages = response.data.messages;
        if (messages && messages.length > 0) {
            for (const msg of messages) {
                if (failedAckStore.has(msg.message_id)) continue;

                let sentSuccessfully = false;
                for (let attempt = 1; attempt <= MAX_SEND_RETRIES; attempt++) {
                    try {
                        await client.sendMessage(msg.user_id, msg.message);
                        sentSuccessfully = true;
                        logger.info(`Message sent to ${msg.user_id} (ID: ${msg.message_id})`);
                        break;
                    } catch (sendError) {
                        logger.error(`Send attempt ${attempt} failed for ID ${msg.message_id}: ${sendError.message}`);
                        if (attempt < MAX_SEND_RETRIES) await sleep(SEND_RETRY_DELAY_MS);
                    }
                }

                if (sentSuccessfully) {
                    let ackSentSuccessfully = false;
                    for (let ackAttempt = 1; ackAttempt <= MAX_ACK_RETRIES; ackAttempt++) {
                        try {
                            await axios.post(`${FASTAPI_BASE_URL}/ack`, { message_id: msg.message_id }, { timeout: 3000 });
                            ackSentSuccessfully = true;
                            break;
                        } catch (ackError) {
                            logger.error(`ACK attempt ${ackAttempt} failed for ID ${msg.message_id}: ${ackError.message}`);
                            if (ackAttempt < MAX_ACK_RETRIES) await sleep(ACK_RETRY_DELAY_MS);
                        }
                    }

                    if (!ackSentSuccessfully) {
                        logger.error(`All ACK attempts failed for message ID: ${msg.message_id}. Quarantining.`);
                        failedAckStore.add(msg.message_id);
                    }
                }
            }
        }
    } catch (error) {
        if (isBackendConnected) {
            let detail = (error.code) ? `(${error.code})` : `(${error.message})`;
            logger.error(`Connection to Kairo backend LOST. Is the Python server running? ${detail}. Switching to slow poll mode.`);
            isBackendConnected = false;
        }
    } finally {
        if (!_stopPollingFlag) {
            const nextPollDelay = isBackendConnected ? FAST_POLLING_INTERVAL_MS : SLOW_POLLING_INTERVAL_MS;
            setTimeout(pollForOutgoingMessages, nextPollDelay);
        }
    }
}

// --- Shutdown and Initialization ---
async function shutdownBridge(signal, exitCode = 0) {
    if (_stopPollingFlag) return;
    _stopPollingFlag = true;
    logger.warn(`Received ${signal}, initiating graceful shutdown...`);
    if (clientInstance) {
        try {
            await clientInstance.destroy();
            logger.info('WhatsApp client destroyed.');
        } catch (e) {
            logger.error(`Error destroying client during shutdown: ${e.message}`);
        }
    }
    logger.warn('Bridge shutdown complete.');
    process.exit(exitCode);
}

process.on('SIGINT', () => shutdownBridge('SIGINT'));
process.on('SIGTERM', () => shutdownBridge('SIGTERM'));

client.initialize().catch(err => {
    logger.error(`CRITICAL: Client initialization failed: ${err.message}. Exiting.`);
    process.exit(1);
});

# --- END OF FILE WA/wa_bridge.js ---



================================================================================
📄 config/prompts.yaml
================================================================================

# --- START OF FILE config/prompts.yaml ---

# config/prompts.yaml

kairo_onboarding_system_prompt: |
  You are Kairo, a friendly and efficient onboarding assistant. Your ONLY goal is to set up the user's preferences.
  Keep your questions very short and direct. Do not use long explanations.

  --- THE #1 RULE ---
  Your ENTIRE response MUST be in the language specified in the user's `language` preference. This is a non-negotiable directive.

  --- ONBOARDING WORKFLOW ---
  Your goal is to fill the user's preferences by asking for the missing information. Check the user's context for any `null` values and ask for them in this priority order:
  1.  **Language:** If `language` is null, this is always your first question.
  2.  **Name:** If `name` is "friend", ask for their name.
  3.  **Timezone:** If `timezone` is null, ask for their city. You MUST infer the IANA timezone for the `update_user_preferences` tool.

  --- ONBOARDING RULES ---
  - After a preference is updated, you MUST immediately use it. If the language is changed to Hebrew, your very next question MUST be in Hebrew.
  - Once all preferences (Language, Name, Timezone) are filled, present a brief summary for the user's confirmation.
  - If the user confirms, you MUST call the `finalize_onboarding` tool.

kairo_agent_system_prompt: |
  You are Kairo, a personal productivity coach. Your persona is supportive, encouraging, and non-judgmental.

  --- YOUR MISSION ---
  Your primary mission is to help the user manage their tasks and reminders, keeping them focused and organized. You achieve this through daily conversation and two key rituals: a Morning Muster and an Evening Reflection.

  --- THE GOLDEN RULE ---
  Your ENTIRE response MUST be in the language specified in the user's `language` preference. This is a non-negotiable directive and overrides all other instructions.

  --- CORE CAPABILITIES ---
  You have the following abilities:
  1.  **Item Management:** You can create, update, and delete items for the user.
      - A **Reminder** is an item with a specific time (e.g., "at 5pm", "tomorrow 10:00"). Use the `create_reminder` tool.
      - A **Task** is an item without a specific time. Use the `create_task` tool.
      - To modify an item, use `update_item`. Remember to nest the changes in an `updates` dictionary, like this: `update_item(item_id='...', updates={'status': 'completed'})`.
  2.  **Preference Management:** You can update the user's settings with `update_user_preferences`.
      - **Be Proactive:** If the user expresses dissatisfaction (e.g., "the evening ritual is too late"), ask them what they'd prefer and update the setting for them.
  3.  **Information Retrieval:** When asked to list items or settings, DO NOT use a tool. All the necessary information is in the user's context. Read it and formulate a natural language response.

  --- RITUALS AND WORKFLOWS ---
  When you receive a system trigger, you must follow these specific workflows:

  **Morning Muster (`morning_muster`):**
  1.  Start with a short, engaging greeting like, "Good morning! Ready to plan your day?"
  2.  When the user replies affirmatively, present their tasks. First, list tasks due "today" (based on `current_utc_date`), then list tasks that have no due date.
  3.  Ask for confirmation and if they want to make changes. Use your own words, for example: "Does this plan look right for today?"
  4.  The primary goal is to establish focus. Ask: "What is your single Most Important Task (MIT) for today?"
  5.  Acknowledge their choice and end with encouragement.

  **Evening Reflection (`evening_reflection`):**
  1.  Start with a friendly greeting, for example: "Good evening! Ready to wrap up your day?"
  2.  On their reply, review the day's tasks. List the tasks that were due today.
  3.  For each task, ask if it was completed. If a task is **completed**, offer positive reinforcement ("Great job on that!"). If a task is **incomplete**, offer to reschedule it for tomorrow using the `update_item` tool.
  4.  **Look Ahead:** After reviewing today, help the user prepare for tomorrow. Present a preview of tasks that are due tomorrow by saying something like, "Looking ahead to tomorrow, here's what's on your plate:"
  5.  **Brain Dump:** As the final step, prompt for a "brain dump" to capture any new thoughts. Ask: "Anything else to add for tomorrow or the days ahead? Let's get it down so you can rest."

# --- END OF FILE config/prompts.yaml ---



================================================================================
📄 config/messages.yaml
================================================================================

# --- START OF FILE config/messages.yaml ---

# config/messages.yaml

# --- Message for Kairo Project ---
initial_welcome_message:
  en: |
    Hello! 👋 I'm Kairo, your personal productivity coach.
    Ready to get set up in under a minute? 
  he: |
    שלום! 👋 אני קאירו, מאמן הפרודוקטיביות האישי שלך.
    שנתחיל?

# --- Message for Vlancer Project ---
vlancer_il_welcome_message:
  en: |
    Welcome! I'm your dedicated project assistant. I'll help you track tasks and manage your client work.
    Ready to configure your workspace? 
  he: |
    ברוך הבא! אני העוזר האישי שלך. אני אעזור לך לנהל את המשימות שלך ולנהל את הזמן שלך בצורה יותר פרודוקטיבית.
    שנתחיל לעבוד?

# --- Onboarding Completion (Used by both) ---
onboarding_completion_message:
  en: |
    Great, you're all set! ✅

    Here’s the best way to start:
    1.  **Capture Everything:** Anytime a task comes to mind, just send it to me.
    2.  **Trust the Rituals:** I'll check in with you every morning and evening to help you plan and reflect.

    What's the very first thing on your mind?
  he: |
    מעולה, הכל מוכן! ✅

    הנה הדרך הכי טובה להתחיל:
    1.  **תפוס/י הכל:** בכל פעם שמשימה עולה לך לראש, פשוט שלח/י לי אותה.
    2.  **סמוך/י על התהליך:** אני אצור איתך קשר כל בוקר וערב כדי לעזור לך לתכנן ולסכם את היום.

    רוצה להוסיף את המשימה הראשונה שיש לך?

# --- Other System Messages ---
generic_error_message:
  en: "Sorry, something went wrong on my end. Please try again."
  he: "מצטער, משהו השתבש בצד שלי. אנא נסה/י שוב."

intent_clarify_message:
  en: "Sorry, I didn't quite understand that. Could you please rephrase?"
  he: "מצטער, לא כל כך הבנתי. אפשר לנסח מחדש?"

# --- END OF FILE config/messages.yaml ---



================================================================================
📄 config/settings.yaml
================================================================================

# --- START OF FILE config/settings.yaml ---

# config/settings.yaml
# This file defines brand-specific configurations for different project deployments.

# A fallback default configuration in case a project name is not found.
default_config:
  default_preferences:
    name: null
    timezone: null
    language: "en"
    status: "new"
    morning_muster_time: "09:00"
    evening_reflection_time: "18:00"
    projects: ["general", "work", "personal"]
    work_days: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday"]
    last_morning_trigger_date: ""
    last_evening_trigger_date: ""
  welcome_message_key: "initial_welcome_message"

# All project-specific configurations must be indented under this "projects" key.
projects:
  kairo:
    default_preferences:
      name: null
      timezone: null
      language: "he"
      status: "new"
      morning_muster_time: "08:00"
      evening_reflection_time: "18:30"
      projects: ["general", "work", "personal"]
      work_days: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday"]
      last_morning_trigger_date: ""
      last_evening_trigger_date: ""
    welcome_message_key: "initial_welcome_message"

  # This section MUST be indented by two spaces to be under "projects".
  vlancer_il:
    default_preferences:
      name: null
      timezone: "Asia/Jerusalem"
      language: "he"
      status: "new"
      morning_muster_time: "09:00"
      evening_reflection_time: "18:00"
      projects: ["general", "work", "personal"]
      work_days: ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday"]
      last_morning_trigger_date: ""
      last_evening_trigger_date: ""
    welcome_message_key: "vlancer_il_welcome_message"

# --- END OF FILE config/settings.yaml ---



================================================================================
📄 tools/logger.py
================================================================================

# --- START OF FILE tools/logger.py ---

# tools/logger.py
import os
import pytz
from datetime import datetime, timezone
import traceback

# This module will now attempt to import the DB logging function when first used.
_activity_db_log_func = None
ACTIVITY_DB_IMPORTED = False

# --- Configuration ---
DEBUG_MODE = os.getenv("DEBUG_MODE", "True").lower() in ('true', '1', 't')
LOG_DIR = "logs"
LOG_FILE = os.path.join(LOG_DIR, "kairo_app.log")
LOG_TIMEZONE_STR = "Asia/Jerusalem"

try:
    LOG_TIMEZONE_PYTZ = pytz.timezone(LOG_TIMEZONE_STR)
except pytz.UnknownTimeZoneError:
    print(f"[ERROR] [logger:init] Unknown Timezone '{LOG_TIMEZONE_STR}'. Defaulting to UTC.")
    LOG_TIMEZONE_PYTZ = pytz.utc

try:
    os.makedirs(LOG_DIR, exist_ok=True)
except OSError as e:
    print(f"[{datetime.now(timezone.utc).isoformat()}] [ERROR] [logger:init] Failed to create log directory '{LOG_DIR}': {e}")

# --- Helper Functions ---
def _timestamp_utc_iso():
    """Returns current time in UTC ISO format for DB logging."""
    return datetime.now(timezone.utc).isoformat()

def _format_log_entry(level: str, module: str, func: str, message: str):
    """Formats a log entry with the configured local timezone."""
    ts_aware = datetime.now(LOG_TIMEZONE_PYTZ)
    ts_formatted = ts_aware.strftime("%Y-%m-%d %H:%M:%S %Z")
    return f"[{ts_formatted}] [{level.upper()}] [{module}:{func}] {message}"

def _try_log_to_db(level: str, module: str, function: str, message: str, traceback_str: str | None = None, timestamp_utc_iso: str | None = None):
    """Internal helper to dynamically import and call the DB logging function."""
    global _activity_db_log_func, ACTIVITY_DB_IMPORTED
    if not ACTIVITY_DB_IMPORTED:
        try:
            from tools.activity_db import log_system_event
            _activity_db_log_func = log_system_event
            ACTIVITY_DB_IMPORTED = True
        except ImportError:
            _activity_db_log_func = None

    if _activity_db_log_func:
        try:
            db_ts = timestamp_utc_iso or _timestamp_utc_iso()
            _activity_db_log_func(
                level=level.upper(),
                module=module,
                function=function,
                message=message,
                traceback_str=traceback_str,
                timestamp=db_ts
            )
        except Exception as db_log_err:
            print(f"CRITICAL DB LOG FAIL: {db_log_err} | Original Msg: {message}")

# --- Public Logging Functions ---
def log_info(module: str, func: str, message: str):
    """Logs informational messages to the console in debug mode."""
    if DEBUG_MODE:
        print(_format_log_entry("INFO", module, func, message))

def log_error(module: str, func: str, message: str, exception: Exception | None = None):
    """Logs error messages to console/file and attempts to log to the database."""
    level = "ERROR"
    traceback_str = traceback.format_exc() if exception else None
    entry = _format_log_entry(level, module, func, message)
    
    print(entry)
    if traceback_str:
        print(traceback_str)
    
    _try_log_to_db(level, module, func, message, traceback_str, _timestamp_utc_iso())

def log_warning(module: str, func: str, message: str):
    """Logs warning messages to console/file and attempts to log to the database."""
    level = "WARNING"
    entry = _format_log_entry(level, module, func, message)
    print(entry)
    _try_log_to_db(level, module, func, message, None, _timestamp_utc_iso())

# --- END OF FILE tools/logger.py ---



================================================================================
📄 gps.py
================================================================================

# --- START OF FILE gps.py ---

# gps.py - Generate Project Snapshot for Kairo
import os
from datetime import datetime
from pathlib import Path

# --- Configuration ---
# This list contains only the files required for the final Kairo MVP.
# Obsolete files have been removed.
FILES_TO_DUMP = [
    # Root Files
    "requirements.txt",
    "package.json",
    ".gitignore",

    # Core Application & Logic
    "main.py",
    "agents/kairo_agent.py",
    "agents/tool_definitions.py",
    "bridge/request_router.py",
    "services/llm_interface.py",
    "services/notification_service.py",
    "services/scheduler_service.py",
    "services/task_manager.py",
    "services/cheats.py",
    "services/shared_resources.py",

    # Data & User Management (The new single source of truth)
    "tools/activity_db.py",
    "users/user_manager.py",

    # Bridge Interfaces
    "bridge/cli_interface.py",
    "bridge/twilio_interface.py",
    "bridge/whatsapp_interface.py",
    "WA/wa_bridge.js",

    # Configuration Files
    "config/prompts.yaml",
    "config/messages.yaml",
    "config/settings.yaml",

    # Utilities & Scripts
    "tools/logger.py",
    "gps.py", # The script itself
    "session_viewer.py", # The debug tool

    # Testing
    "tests/mock_browser_chat.py",
    "tests/templates/browser_chat.html",
]

OUTPUT_FILENAME_PATTERN = "kairo_mvp_snapshot.txt"
SEPARATOR = "=" * 80
# --- End Configuration ---

def generate_dump(output_filename: str, files_to_include: list):
    """Generates the project dump file."""
    project_root = Path(__file__).parent
    dump_content = []
    timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    dump_content.append(f"# Kairo Project Code Dump (v1.0 MVP)")
    dump_content.append(f"# Generated: {timestamp_str}\n\n")

    for relative_path_str in files_to_include:
        full_path = project_root / Path(relative_path_str)
        if full_path.is_file():
            try:
                content = full_path.read_text(encoding='utf-8', errors='replace')
                header_path = Path(relative_path_str).as_posix()
                dump_content.append(SEPARATOR)
                dump_content.append(f"📄 {header_path}")
                dump_content.append(SEPARATOR)
                dump_content.append(f"\n# --- START OF FILE {header_path} ---\n")
                dump_content.append(content)
                dump_content.append(f"\n# --- END OF FILE {header_path} ---\n\n\n")
                print(f"✅ Included: {header_path}")
            except Exception as e:
                print(f"❌ Error reading {relative_path_str}: {e}")
        else:
            print(f"⚠️  Skipped (Not Found): {relative_path_str}")

    try:
        (project_root / output_filename).write_text("\n".join(dump_content), encoding='utf-8')
        print(f"\n✅ Dump generated successfully: {output_filename}")
    except Exception as e:
        print(f"\n❌ Error writing dump file {output_filename}: {e}")

if __name__ == "__main__":
    generate_dump(OUTPUT_FILENAME_PATTERN, FILES_TO_DUMP)

# --- END OF FILE gps.py ---



================================================================================
📄 session_viewer.py
================================================================================

# --- START OF FILE session_viewer.py ---

# session_viewer.py
import sqlite3
import json
import argparse
from datetime import datetime, timezone
import pytz
from typing import List, Dict

# --- Configuration ---
DB_DIR = "data"
# This allows the script to work with both _cli and non-suffixed DBs
DB_SUFFIX = "_cli" # Set to "" for production, or pass as an argument
DB_FILE_PATH = "" # Will be set by arguments

# --- Helper Functions ---
def _format_timestamp(ts_str: str, local_tz: pytz.BaseTzInfo) -> str:
    """Converts a UTC ISO string to a user-friendly local time string."""
    if not ts_str:
        return " " * 19
    try:
        utc_dt = datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
        local_dt = utc_dt.astimezone(local_tz)
        return local_dt.strftime('%Y-%m-%d %H:%M:%S')
    except (ValueError, TypeError):
        return ts_str[:19] # Fallback to show raw timestamp

def _pretty_print_json(json_str: str) -> str:
    """Formats a JSON string with indentation for readability."""
    try:
        obj = json.loads(json_str)
        return json.dumps(obj, indent=2, ensure_ascii=False)
    except (json.JSONDecodeError, TypeError):
        return json_str # Return as is if not valid JSON

# --- Main Logic ---
def get_user_session(db_path: str, user_id: str, local_tz: pytz.BaseTzInfo) -> None:
    """Queries all relevant tables for a user's session and prints a chronological log."""
    
    all_events = []
    
    try:
        with sqlite3.connect(f"file:{db_path}?mode=ro", uri=True) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # 1. Fetch messages
            cursor.execute("SELECT * FROM messages WHERE user_id = ?", (user_id,))
            for row in cursor.fetchall():
                all_events.append({
                    "timestamp": row["timestamp"],
                    "type": "MESSAGE",
                    "data": dict(row)
                })

            # 2. Fetch LLM tool activity
            cursor.execute("SELECT * FROM llm_activity WHERE user_id = ?", (user_id,))
            for row in cursor.fetchall():
                all_events.append({
                    "timestamp": row["timestamp"],
                    "type": "TOOL_CALL",
                    "data": dict(row)
                })

            # 3. Fetch system logs (errors/warnings)
            cursor.execute("SELECT * FROM system_logs") # Get all, then we'll filter
            for row in cursor.fetchall():
                 # For system logs, we can't always guarantee a user_id context, so we show all for now
                 # A more advanced version could try to correlate by timestamp
                 all_events.append({
                    "timestamp": row["timestamp"],
                    "type": f"SYS_{row['level']}",
                    "data": dict(row)
                })

    except sqlite3.Error as e:
        print(f"❌ Database Error: Could not connect to or query '{db_path}'.\n   Reason: {e}")
        return

    if not all_events:
        print(f"No activity found for user ID: {user_id}")
        return

    # Sort all collected events chronologically
    all_events.sorted_events = sorted(all_events, key=lambda x: x["timestamp"])

    # --- Print the formatted session log ---
    print("\n" + "="*80)
    print(f"Kairo Session Log for User: {user_id}")
    print(f"Timezone: {local_tz.zone}")
    print("="*80 + "\n")

    for event in all_events.sorted_events:
        ts = _format_timestamp(event["timestamp"], local_tz)
        event_type = event["type"]
        data = event["data"]

        if event_type == "MESSAGE":
            role = data['role'].upper()
            content = data['content']
            if role == 'USER':
                print(f"[{ts}] 👤 \033[92m{role}:\033[0m {content}") # Green
            else: # ASSISTANT
                print(f"[{ts}] 🤖 \033[94m{role}:\033[0m {content}") # Blue

        elif event_type == "TOOL_CALL":
            tool_name = data['tool_name']
            print(f"[{ts}] ⚙️  \033[93mTOOL CALL: {tool_name}\033[0m")
            print("   ▶️  Args:")
            print(_pretty_print_json(data['tool_args_json']))
            print("   ◀️  Result:")
            print(_pretty_print_json(data['tool_result_json']))
        
        elif event_type.startswith("SYS_"):
            level = data['level']
            color = '\033[91m' if level == 'ERROR' else '\033[93m' # Red for Error, Yellow for Warning
            print(f"[{ts}] ⚠️  {color}{level} in {data['module']}:{data['function']}\033[0m")
            print(f"   - {data['message']}")
            if data['traceback']:
                print(f"   - Traceback: {data['traceback']}")

    print("\n" + "="*80)
    print("End of session log.")
    print("="*80)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="View a user's chronological session from the Kairo database.")
    parser.add_argument("user_id", type=str, help="The user ID to retrieve the session for.")
    parser.add_argument("--mode", type=str, choices=['cli', 'prod'], default='cli', help="The database mode ('cli' or 'prod'). Defaults to 'cli'.")
    parser.add_argument("--tz", type=str, default="Asia/Jerusalem", help="Your local timezone for displaying timestamps, e.g., 'America/New_York'. Defaults to 'Asia/Jerusalem'.")
    
    args = parser.parse_args()
    
    db_suffix = "_cli" if args.mode == 'cli' else ""
    db_path = os.path.join(DB_DIR, f"kairo_activity{db_suffix}.db")
    
    try:
        local_timezone = pytz.timezone(args.tz)
    except pytz.UnknownTimeZoneError:
        print(f"❌ Unknown timezone '{args.tz}'. Please use a valid TZ database name.")
        exit(1)

    get_user_session(db_path, args.user_id, local_timezone)

# --- END OF FILE session_viewer.py ---



================================================================================
📄 tests/mock_browser_chat.py
================================================================================

# --- START OF FILE tests/mock_browser_chat.py ---

# tests/mock_browser_chat.py
import os
import requests
import json
import time
import threading
from flask import Flask, render_template, request, jsonify
from collections import deque
from datetime import datetime
from dotenv import load_dotenv
import logging

# --- Configuration ---
load_dotenv()
VIEWER_PORT = int(os.getenv("VIEWER_PORT", "5001"))
MAX_MESSAGES = 100
MAIN_BACKEND_PORT = os.getenv("PORT", "8001")
MAIN_BACKEND_BASE_URL = f"http://localhost:{MAIN_BACKEND_PORT}"
MAIN_BACKEND_OUTGOING_URL = f"{MAIN_BACKEND_BASE_URL}/outgoing"
MAIN_BACKEND_ACK_URL = f"{MAIN_BACKEND_BASE_URL}/ack"
MOCK_USER_ID = "1234"

# --- State ---
message_store_bot = deque(maxlen=MAX_MESSAGES)
message_lock = threading.Lock()
_stop_polling_event = threading.Event()

# --- Flask App Setup ---
app = Flask(__name__, template_folder=os.path.join(os.path.dirname(__file__), 'templates'))
app.secret_key = os.getenv("FLASK_SECRET_KEY", os.urandom(24))

def mock_log(level, component, message):
    """Custom logger to print formatted messages to the console."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level.upper()}] [MockChat:{component}] {message}")

# --- START OF FIX: Refactored Polling Function ---
def poll_main_backend():
    """Polls the Kairo backend for outgoing messages."""
    session = requests.Session()
    while not _stop_polling_event.is_set():
        try:
            res = session.get(MAIN_BACKEND_OUTGOING_URL, timeout=5)
            res.raise_for_status()
            data = res.json()
            
            messages_from_backend = data.get("messages", [])
            
            if not messages_from_backend:
                time.sleep(1) # Wait a second if the queue is empty
                continue

            # If we get here, messages were found.
            mock_log("info", "PollingThread", f"Found {len(messages_from_backend)} message(s) in payload from Kairo.")
            
            for msg_data in messages_from_backend:
                # Log every message received, regardless of user ID for debugging
                mock_log("info", "PollingThread", f"RECEIVED: User='{msg_data.get('user_id')}', Msg='{msg_data.get('message', '')[:70]}...'")
                
                # Process only messages for our simulated user
                if msg_data.get('user_id') == MOCK_USER_ID:
                    with message_lock:
                        message_store_bot.appendleft({
                            "sender": "bot",
                            "timestamp": datetime.now().strftime("%H:%M:%S"),
                            "content": msg_data.get('message'),
                            "id": msg_data.get('message_id')
                        })
                    
                    # Acknowledge the message was processed
                    session.post(MAIN_BACKEND_ACK_URL, json={"message_id": msg_data.get('message_id'), "user_id": MOCK_USER_ID}, timeout=3)
        
        except requests.exceptions.RequestException:
            # This happens if the backend is down, wait before retrying.
            time.sleep(2)
        except Exception as e:
            mock_log("error", "PollingThread", f"An unexpected error occurred in polling loop: {e}")
            time.sleep(5)
# --- END OF FIX ---

# --- Flask Routes ---
@app.route('/')
def index():
    return render_template('browser_chat.html', title=f"Kairo Mock Chat (User: {MOCK_USER_ID})")

@app.route('/send_message', methods=['POST'])
def send_message_route():
    data = request.get_json()
    message_text = data.get('message')
    if not message_text:
        return jsonify({"status": "error", "message": "No message"}), 400

    backend_payload = {"user_id": MOCK_USER_ID, "message": message_text}
    mock_log("info", "SendRoute", f"SENDING to Kairo backend: '{message_text}'")
    try:
        requests.post(f"{MAIN_BACKEND_BASE_URL}/incoming", json=backend_payload, timeout=120)
        return jsonify({"status": "ok"}), 200
    except requests.exceptions.RequestException:
        return jsonify({"status": "error", "message": "Could not connect to Kairo backend."}), 503

@app.route('/get_messages')
def get_messages_route():
    with message_lock:
        return jsonify({"messages": list(message_store_bot)})

@app.route('/clear_messages', methods=['POST'])
def clear_messages_route():
    with message_lock:
        message_store_bot.clear()
    return jsonify({"status": "ok"})

# --- Main Execution ---
if __name__ == '__main__':
    mock_log("info", "Main", "--- Starting Kairo Mock Browser Chat ---")
    user_input_id_raw = input(f"Enter User ID to simulate (leave blank for '{MOCK_USER_ID}'): ").strip()
    if user_input_id_raw: MOCK_USER_ID = user_input_id_raw
    mock_log("info", "Main", f"Simulating as User ID: {MOCK_USER_ID}")
    
    polling_thread = threading.Thread(target=poll_main_backend, daemon=True)
    polling_thread.start()
    
    log = logging.getLogger('werkzeug')
    log.setLevel(logging.ERROR)
    
    app.run(host='0.0.0.0', port=VIEWER_PORT, debug=False, use_reloader=False)

# --- END OF FILE tests/mock_browser_chat.py ---



================================================================================
📄 tests/templates/browser_chat.html
================================================================================

# --- START OF FILE tests/templates/browser_chat.html ---

<!-- tests/templates/browser_chat.html -->
<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>{{ title }}</title>
    <style>
        /* Styles remain the same */
        body { font-family: sans-serif; margin: 0; padding: 0; display: flex; flex-direction: column; height: 100vh; background-color: #f4f4f4; }
        h1 { text-align: center; color: #333; margin: 10px 0; }
        #chat-container { flex-grow: 1; border: 1px solid #ccc; background-color: #fff; margin: 0 10px 10px 10px; overflow-y: auto; padding: 10px; }
        #messages { list-style-type: none; padding: 0; margin: 0; }
        #messages li { margin-bottom: 10px; padding: 8px; border-radius: 5px; word-wrap: break-word; max-width: 80%; clear: both; }
        #messages li.user { background-color: #dcf8c6; margin-left: auto; float: right; text-align: right; }
        #messages li.bot { background-color: #e0e0e0; margin-right: auto; float: left; text-align: left; }
        #messages li.system { background-color: #f0e68c; margin-left: auto; margin-right: auto; text-align: center; font-style: italic; color: #555; max-width: 90%; float: none; font-size: 0.9em;}
        #messages li[dir="rtl"] { text-align: right; }
        #messages li[dir="ltr"] { text-align: left; }
        .msg-meta { font-size: 0.8em; color: #888; display: block; margin-top: 4px; }
        .msg-content { white-space: pre-wrap; }
        #input-area { display: flex; padding: 10px; border-top: 1px solid #ccc; background-color: #eee; }
        #messageInput { flex-grow: 1; padding: 10px; border: 1px solid #ccc; border-radius: 3px; margin-right: 5px;}
        #sendButton { padding: 10px 15px; cursor: pointer; }
        #controls { text-align: right; padding: 0 10px 5px 0; font-size: 0.8em; }
    </style>
</head>
<body>

    <h1>{{ title }}</h1>
    <div id="controls">
        <button id="clearButton" title="Clear messages displayed in this browser window">Clear Display</button>
    </div>

    <div id="chat-container">
        <ul id="messages">
            <!-- Messages will be added dynamically -->
        </ul>
    </div>

    <div id="input-area">
        <input type="text" id="messageInput" placeholder="Type your message..." autocomplete="off">
        <button id="sendButton">Send</button>
    </div>

    <script>
        const messagesContainer = document.getElementById('messages');
        const messageInput = document.getElementById('messageInput');
        const sendButton = document.getElementById('sendButton');
        const clearButton = document.getElementById('clearButton');

        let displayedMessageIds = new Set(); // Track IDs shown in browser
        let isSending = false;
        let isFetching = false;

        function containsHebrew(text) {
            if (!text) return false;
            return /[\u0590-\u05FF]/.test(text);
        }

        // Function to add a single message object to the display UL
        function addMessageToDisplay(msg) {
             if (!msg || !msg.id || displayedMessageIds.has(msg.id)) {
                 return false; // Don't add if no message, no ID, or already displayed
             }

             const li = document.createElement('li');
             const senderClass = msg.sender || 'system';
             li.classList.add(senderClass);

             const isRtl = containsHebrew(msg.content);
             li.setAttribute('dir', isRtl ? 'rtl' : 'ltr');

             const contentSpan = document.createElement('span');
             contentSpan.className = 'msg-content';
             contentSpan.textContent = msg.content;

             const metaSpan = document.createElement('span');
             metaSpan.className = 'msg-meta';
             // Use sender from message object now
             metaSpan.textContent = `[${msg.timestamp}] ${senderClass.toUpperCase()}`;

             li.appendChild(contentSpan);
             li.appendChild(metaSpan);

             messagesContainer.appendChild(li);
             displayedMessageIds.add(msg.id); // Mark as displayed
             return true;
        }

        // Fetches ONLY BOT messages and adds them if not already displayed
        async function fetchAndUpdateMessages() {
            if (isFetching) return;
            isFetching = true;
            let addedNew = false;
             try {
                const response = await fetch('/get_messages'); // Fetches BOT messages from server store
                if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
                const result = await response.json();
                const botMessages = result.messages || [];

                botMessages.forEach(msg => {
                    // addMessageToDisplay checks displayedMessageIds
                    if(addMessageToDisplay(msg)) {
                        addedNew = true;
                    }
                });

            } catch (error) {
                console.error('Error fetching messages:', error);
            } finally {
                 isFetching = false;
                 if (addedNew) {
                     messagesContainer.scrollTop = messagesContainer.scrollHeight;
                 }
             }
        }

       async function sendMessage() {
            const messageText = messageInput.value.trim();
            if (!messageText || isSending) return;
            isSending = true;
            sendButton.disabled = true;
            messageInput.disabled = true;

            // 1. Create and display user message OBJECT immediately
             const userTimestamp = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
             const localUserId = `user-${Date.now()}`;
             const userMsg = {
                 sender: 'user',
                 timestamp: userTimestamp,
                 content: messageText,
                 id: localUserId
             };
             if(addMessageToDisplay(userMsg)){ // Add user message to display
                 messagesContainer.scrollTop = messagesContainer.scrollHeight;
             }
             messageInput.value = '';

            // 2. Send message to viewer backend to forward to main backend
            try {
                const response = await fetch('/send_message', { // Send to viewer backend
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ message: messageText })
                });
                if (!response.ok) {
                    const errorData = await response.json().catch(() => ({ message: response.statusText }));
                    console.error('Error sending message via viewer:', errorData.message);
                    // Add error message to display
                    addMessageToDisplay({ sender: 'system', timestamp: new Date().toLocaleTimeString(), content: `Error sending: ${errorData.message}`, id:`err-${Date.now()}`});
                    messagesContainer.scrollTop = messagesContainer.scrollHeight;
                }
                 // Bot response will arrive via the fetchAndUpdateMessages polling
            } catch (error) {
                console.error('Network error sending message via viewer:', error);
                 addMessageToDisplay({ sender: 'system', timestamp: new Date().toLocaleTimeString(), content: `Network Error: ${error}`, id:`neterr-${Date.now()}`});
                 messagesContainer.scrollTop = messagesContainer.scrollHeight;
            } finally {
                 isSending = false;
                 sendButton.disabled = false;
                 messageInput.disabled = false;
                 messageInput.focus();
            }
        }

       async function clearMessages() {
             displayedMessageIds.clear(); // Clear JS tracking
             messagesContainer.innerHTML = '<li>Clearing...</li>'; // Update display
            try {
                await fetch('/clear_messages', { method: 'POST' }); // Tell server to clear its bot store
                 messagesContainer.innerHTML = '<li>Messages cleared.</li>';
            } catch (error) {
                console.error('Error signaling viewer to clear messages:', error);
                messagesContainer.innerHTML = '<li>Error clearing messages.</li>';
            }
        }

        // Event Listeners
        sendButton.addEventListener('click', sendMessage);
        messageInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') { sendMessage(); }
        });
        clearButton.addEventListener('click', clearMessages);

        // Fetch messages periodically
        setInterval(fetchAndUpdateMessages, 1500);

        // Initial fetch
        // No initial fetch needed, or fetch then clear display?
        // Let's start clean
        messagesContainer.innerHTML = '<li>Connecting...</li>'; // Initial message

    </script>

</body>
</html>

# --- END OF FILE tests/templates/browser_chat.html ---


